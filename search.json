[{"title":"Java Synchronized锁升级","path":"/2025/01/07/Java Synchronized锁升级/","content":"锁升级流程图 Mark-Word进入锁升级的学习前，必须明确一个概念，所谓的锁，所著的一定是一个对象，实例也好，类也好。先了解Java对象头中的mark-word 为什么无锁&#x2F;偏向锁的标志位是01，而轻量级锁的标志位是00？ 即按理说，无锁是锁状态的初始情况，为什么标志位不是从00开始？ 个人查询到的一个解释，是因为 轻量级锁除了锁标志位外，另外62位都是一个指针地址。 如果将轻量级锁标志位设置为00， 那么在判断标志位为00后， m无需再额外做一次markWord&gt;&gt;2的操作，而是直接将markWord拿来当作地址使用即可！ 哈希code去哪了 我们注意到无锁时的hashcode不见了。 对于偏向锁而言， 一旦在对象头中设置过hashcode， 那么进入同步块时就不会进入偏向锁状态，会直接跳到轻量级锁，毕竟偏向锁里没有存放hashcode的地方（下文的轻量级锁和重量级锁则有存储的地方） 因此凡是做过类似hashmap.put(k,v)操作且没覆写hashcode的k对象， 以后加锁时，都会直接略过偏向锁。 偏向锁偏向锁的意义假设一个场景，一个同步代码块只有一个线程使用，如果使用多次的话，需要重复获取锁和释放锁的操作，这对性能很有影响，而偏向锁在退出同步代码块时，不会释放锁，而是继续占用，下次进入同步代码块时，只需检查锁中的线程id是否是自己的线程id 无锁升级为偏向锁首次进入同步代码块时，会通过cas的方式设置锁中的线程id（采用cas是因为存在同时写的可能的），进入偏向锁，即无锁转为偏向锁（个人认为用升级两个字其实不太妥当，因为无锁根本不涉及到同步代码块） 偏向锁的竞争当一个线程已经持有偏向锁，而另一个线程也想进入该同步代码块时，就会出现竞争， 第二个线程先等程序进入jvm全局安全点（即当前无字节码执行） 判断偏向锁占有线程是否还在执行 如没有执行则退为无锁，第二个线程通过cas尝试获取偏向锁，若还在执行，则进入轻量级锁的升级过程 偏向锁启用延迟 即使你开启了偏向锁，但是这个偏向锁的启用是有延迟，大概 4s左右。即java进程启动的4s内，都会直接跳过偏向锁，有同步代码块时直接使用轻量级锁。 原因是 JVM 初始化的代码有很多地方用到了synchronized，如果直接开启偏向，产生竞争就要有锁升级，会带来额外的性能损耗，jvm团队经过测试和评估， 选择了启动速度最快的方案， 即强制4s内禁用偏向锁，所以就有了这个延迟策略 （当然这个延迟时间也可以通过参数自己调整） 偏向锁的演变历史 偏向锁在JDK6引入, 且默认开启偏向锁优化, 可通过JVM参数-XX:-UseBiasedLocking来禁用偏向锁。但随着时代发展，发现偏向锁带来的维护、撤销成本， 远大于轻量级锁的少许CAS动作。官方说明中有这么一段话: since the introduction of biased locking into HotSpot also change the amount of uncontended operations needed for that relation to remain true。 即随着硬件发展，原子指令成本变化，导致轻量级自旋锁需要的原子指令次数变少，所以自旋锁成本下降，故偏向锁的带来的优势就更小了。于是jdk团队在Jdk15之后， 再次默认关闭了偏向锁。 轻量级锁轻量级锁的意义我们需要先明白一下阻塞线程是一个很消耗性能的操作，我们假设现在多个线程不断的轮着执行同步代码块，会不断的发生获取和释放锁的操作，就会不断地阻塞和唤醒线程，非常消耗性能，而轻量级锁则不阻塞线程，而是通过自旋尝试获取锁来达到类似阻塞的效果（这里需要强调一点，自旋是需要消耗cpu的，如果自旋过久的话，性能消耗反而会超过阻塞线程的性能消耗） 阻塞线程为什么消耗性能因为阻塞线程需要操作系统的介入，导致从用户态切换到内核态，这是一个很消耗性能的过程 偏向锁升级为轻量级锁如果对象进行过获取hashcode的操作，则直接无锁进入轻量级锁 在上文提到了偏向锁升级为轻量级锁的时机，那升级过程究竟是怎样的呢，我们注意到，当进入轻量级锁时，mark-word的一些属性不存在了，其实这些属性被存储到对应线程栈帧中的lockRecord（即轻量级锁）中了 当其他线程将锁升级为轻量级锁后，当前持有锁的线程会升级为轻量级锁，复制对象头中的mark-word到lockRecord中，然后将mark-word中的内容替换为指向当前lockRecord的指针 其他线程通过轻量级锁的机制竞争锁，即自旋的方式，如果自旋的次数超过阈值，则升级为重量级锁 轻量级锁的重入机制首先提一下为什么偏向锁没有重入机制，因为偏向锁的本质是一个线程持有锁，所以无论重入多少次，也只有一个线程访问，也没有重入机制的必要了 线程的lockRecord不是一个单一的lockRecord，而是lockRecord集合，每次重入会添加一个存储null的lockRecord，所以除了第一个（其实应该叫最后一个，因为是最后访问到的）lockRecord存储的是对象的mark-word，其他的lockRecord存储的都是null，每一次退出重入时，删除一个lockRecord（这里是后进先出），计数减一 轻量级锁的加锁过程 每次线程进入同步代码块前，判断mark-word的指针是否指向自己，如果是，则直接走重入机制，添加一个lockRecord 如果指针不是指向自己，则通过cas替换对象mark-word中的指针使指针只想自己，如果cas的次数超过阈值（默认10次），则升级为重量级锁 如果mark-word还没有指向线程，说明还没被占有，复制mark-word到lockRecord，尝试通过cas将mark-record替换为指向lockRecord的指针 如果cas失败，则继续自旋，超出阈值，升级为重量级锁 轻量级锁的解锁过程 退出同步代码块时，获取当前lockRecord的值，如果是null，表示是退出重入，则走退出重入机制 如果不为null，证明是退出锁，通过cas将mark-word复制到对象的mark-word中 如果cas成功，解锁成功 如果cas失败，证明已经被其他线程膨胀到重量级锁，走重量级锁解锁机制 重量级锁objectMonitor每个对象的重量级锁指向一个独有的objectMonitor，这个对象是C++实现的，其内部维护了以下对象 _owner：初始值为null。当有线程获取到该对象锁（即获取到该对象的Monitor对象）时，owner变量便将值置为该线程的ID；当线程释放对象锁时，owner恢复为null。owner是一个临界资源，JVM是通过CAS操作来保证其线程安全； cxq：竞争队列，所有请求对象锁的线程都会首先被放置于这个队列当中（单向）。__cxq 是一个临界资源，JVM通过CAS原子指令来修改cxq队列。新入节点采用头插法，置于队列头部，__cxq指针会指向该新入队的节点。 _EntryList：__cxq队列中有资格成为候选资源的线程会被移动到该队列；该队列主要存放获取锁或者重新获取锁时被阻塞的线程（也存放竞争锁失败的线程）； _WaitSet：调用wait()阻塞的线程会被移动至该等待队列中，等待线程组成双向循环链表，WaitSet所指向的是第一个节点； _recursions：synchronized是一个可重入锁，该变量用于记录锁重入（获取）的次数； 轻量级锁升级为重量级锁升级为重量级锁的条件 轻量级锁状态下，自旋超出阈值（默认10次） 从无锁&#x2F;偏向锁直接升级为重量级锁的条件：调用了object.wait()方法，则会直接升级为重量级锁！ 升级过程当触发轻量级锁升级为重量级锁时，将对象头中的mark-word复制到objectMonitor的对象头中，并将owner属性设置为当前持有锁的线程的id，其他线程便进入阻塞队列中进行阻塞等待，并进入BLOCKED状态； 重量级锁加解锁过程1、当线程第一次调用monitorEntry执行且是重量级锁的情况下，会先进入cxq队列 2、当涉及锁的频繁竞争且需要阻塞时，需要进入entryList队列中。 3、如果线程能CAS竞争到onwer指针，就说明占有同步代码块成功， 如果CAS竞争不到，则block阻塞。 4、monitorExit退出时，会让entryList中block阻塞的线程唤醒重新竞争 5、如果调用了object.wait()方法， onwer线程会进入等待队列（注意，因为竞争失败的线程，不会进入waitSet，waitSet只服务于那些wait()方法引发的线程） 6、当调用的object.notify()或者notifyAll， 等待队列中的线程会根据qmod模式的不同，进入cxq或者进入entryList。 简要版流程如下：","categories":["Java基础"]},{"title":"Mysql主从复制","path":"/2025/01/07/Mysql主从复制/","content":"mysql主从复制主要是通过binlog实现的 主服务器配置1234log-bin=mysql-bin binlog-format=ROW binlog-do-db=demo_ds_masterserver-id=1 log-bin&#x3D;mysql-bin：开启binlog binlog-format&#x3D;ROW：设置binlog复制模式 STATEMENT：只会将会修改数据的sql语句会记录到binlog中，不会存储所有sql语句，也不存储数据变化情况 ROW：不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了，修改成什么样了 MIXED：以上两种模式的混合使用，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog binlog-do-db&#x3D;demo_ds_master：如上图所示，设置需要同步的库 server-id&#x3D;1：设置server-id，mysql服务器server-id不能一样 创建同步用户12345678//创建用户，@&#x27;localhost&#x27;代表仅能通过localhost访问（即只能本机访问），如果想去除ip的限制，配置@&#x27;%&#x27;CREATE USER &#x27;rep&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;123456&#x27;;//授予同步权限，@&#x27;localhost&#x27;代表仅能通过localhost同步（即只能本机同步），with grant option表示给予rep用户授权当前权限给其他用户的权限，这里当前权限就是同步的权限grant replication slave on *.* to &#x27;rep&#x27;@&#x27;localhost&#x27; with grant option;//授予write_read的所有权限给rep用户，以可以让从服务器通过连接此用户同步demo_ds_masterGRANT ALL PRIVILEGES ON `demo_ds_master`.* TO &#x27;rep&#x27;@&#x27;localhost&#x27;;//刷新生效flush privileges; 获取当前bin-log文件以及偏移量1show master status; 这里查询出来当前的bin-log文件名、文件偏移量以及当前会同步的库，bin-log文件名、文件偏移量在后面从服务器需要用到 从服务器配置1234log-bin=mysql-binbinlog-format=ROWreplicate-rewrite-db=demo_ds_master -&gt; demo_ds_slave_0server-id=2 log-bin&#x3D;mysql-bin：开启binlog binlog-format&#x3D;ROW：设置binlog复制模式 replicate-rewrite-db&#x3D;demo_ds_master -&gt; demo_ds_slave_0 设置同步的库，这样配置有一定的问题，就是在执行带有库名的sql语句时，同步会出错，使用replicate-do-db&#x3D;demo_ds_master配置可以解决这个问题，这样配置的话就是主从库的库名相同，这里配置的主数据库的库名一定要在主数据库种有配置同步 server-id&#x3D;2：设置server-id，和主服务器以及其他从服务器不一样 设置主数据库以及开启同步1234567CHANGE MASTER TOMASTER_HOST=&#x27;localhost&#x27;, //主数据库地址，在上面配置的MASTER_PORT=3306, //主数据库端口MASTER_USER=&#x27;rep&#x27;, //同步的用户，在上面配置的MASTER_PASSWORD=&#x27;123456&#x27;, //同步用户的密码MASTER_LOG_FILE=&#x27;mysql-bin.000060&#x27;, //主服务器的bin-log文件MASTER_LOG_POS=16090; //主服务器的bin-log的偏移量，不一定需要当前的偏移量 我们要理解命令的字面意思是修改主服务器，所以如果已经设置主服务器并且需要修改其中一项，则只需在命令后加入一项，这里面需要强调的是MASTER_LOG_POS参数，该参数可以设置主数据库当前bin-log文件偏移量之前的偏移量以达到同步主数据库之前的数据的效果，不过需要注意并不一定成功，因为bin-log文件记录的是sql或者数据变化，如果遇到delete或者drop等命令，而未同步到delete之前的insert语句或者drop之前的create语句，则可能报错，mysql主从同步有个明显的问题就是一旦遇到错误，就会停止同步，所以需要非常注意，不过因为偏移量可以往前设置的特性，及时从服务器出现宕机，恢复之后也可以同步之前未同步的数据 12345stop slave; //关闭同步 start slave; //开启同步show slave status; //查看slave状态 Slave_IO_State: 从服务器的 I&#x2F;O 状态。 Master_Host: 主服务器的主机名或 IP 地址。 Master_User: 与主服务器连接的用户名。 Master_Port: 主服务器的端口号。 Connect_Retry: 从服务器重试连接主服务器的时间间隔（单位：秒）。 Master_Log_File: 主服务器当前正在写入的二进制日志文件的名称。 Read_Master_Log_Pos: 从服务器当前正在读取的二进制日志文件的位置。 Relay_Log_File: 从服务器正在写入的中继日志文件的名称。 Relay_Log_Pos: 从服务器正在写入的中继日志文件的位置。 Relay_Master_Log_File: 从服务器正在复制的最后一个日志文件的名称。 Slave_IO_Running: 从服务器执行的 I&#x2F;O 线程是否正在运行。 Slave_SQL_Running: 从服务器执行的 SQL 线程是否正在运行。 Replicate_Do_DB: 从服务器要复制的数据库名。 Replicate_Ignore_DB: 从服务器忽略复制的数据库名。 Replicate_Do_Table: 从服务器要复制的表名。 Replicate_Ignore_Table: 从服务器忽略复制的表名。 Last_Errno: 当 SQL 线程出现错误时，记录错误号。 Last_Error: 当 SQL 线程出现错误时，记录错误信息。 Slave_SQL_Running_State: SQL 线程的状态信息。 Seconds_Behind_Master: 从服务器库落后主服务器库的秒数。如果该值为 NULL，则表示从服务器正在初始化。 其中需要注意的是Slave_IO_Running以及Slave_SQL_Running配置，当这两个配置都为yes的时候，代表正常同步，否则为不正常，需要查看日志 日志查看 可以查看mysql my.ini的该配置，该文件在mysql datadir目录下，可以查看该文件确定同步情况","categories":["Mysql分库分表"]},{"title":"Mycat分库分表以及读写分离","path":"/2025/01/07/Mycat分库分表以及读写分离/","content":"Mycat下载地址：https://github.com/MyCATApache/Mycat-download Mycat介绍目录介绍 bin mycat使用命令 catlet 它是mycat的一个扩展功能 conf mycat的配置信息 【重点】 lib mycat的引用jar包 ，mycat是由java开发的【mysql驱动可直接在这里更换】 logs 日志目录 mycat启动日志文件 —&gt;wrapper.log mycat的运行日志文件 —-&gt;mycat.log 配置文件介绍 server.xml mycat的 配置文件 配置连接mycat的账号、密码、和数据库的名称 schema.xml 配置mycat的物理数据库和数据库中的逻辑表 rule.xml 配置mycat的分片(分库分表) 规则 mod-log 关于Mysql版本问题如果驱动版本不符合mysql的版本，直接将mycat下的低版本驱动替换成高版本的驱动就行了，mysql8以上的版本都需要更换驱动版本 分库分表配置1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mycat:server SYSTEM &quot;server.dtd&quot;&gt;&lt;mycat:server xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;system&gt; //system配置，此处不贴出 &lt;/system&gt; &lt;user name=&quot;root&quot; defaultAccount=&quot;true&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;sharding_db&lt;/property&gt; &lt;/user&gt; &lt;user name=&quot;user&quot;&gt; &lt;property name=&quot;password&quot;&gt;user&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;test&lt;/property&gt; //如果使用user用户连接，则不可写 &lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt; &lt;/user&gt;&lt;/mycat:server&gt; 1234567891011121314151617181920212223242526272829&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;schema name=&quot;sharding_db&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;table name=&quot;t_user_0&quot; dataNode=&quot;dn1,dn2&quot; primaryKey=&quot;id&quot; rule=&quot;mod-long&quot; /&gt; &lt;/schema&gt; &lt;dataNode name=&quot;dn1&quot; dataHost=&quot;localhost1&quot; database=&quot;sharding_db&quot; /&gt; &lt;dataNode name=&quot;dn2&quot; dataHost=&quot;localhost2&quot; database=&quot;sharding_db&quot; /&gt; &lt;dataHost name=&quot;localhost1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;1&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;jdbc:mysql://127.0.0.1:3306?useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;serverTimezone=UTC&amp;amp;allowMultiQueries=true&quot; user=&quot;root&quot; password=&quot;123456&quot;&gt;&lt;/writeHost&gt; &lt;/dataHost&gt; &lt;dataHost name=&quot;localhost2&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;1&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM2&quot; url=&quot;jdbc:mysql://127.0.0.1:3316?useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;serverTimezone=UTC&amp;amp;allowMultiQueries=true&quot; user=&quot;root&quot; password=&quot;123456&quot;&gt;&lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; balance属性，负载均衡类型，目前的取值有3 种： balance&#x3D;”0”, 不开启读写分离机制，所有读操作都发送到当前可用的writeHost 上。 balance&#x3D;”1”，全部的readHost 与stand by writeHost 参与select 语句的负载均衡，简单的说，当双主双从模式(M1-&gt;S1，M2-&gt;S2，并且M1 与M2 互为主备)，正常情况下，M2,S1,S2 都参与select 语句的负载均衡。 balance&#x3D;”2”，所有读操作都随机的在writeHost、readhost 上分发。 balance&#x3D;”3”，所有读请求随机的分发到wiriterHost 对应的readhost 执行，writerHost 不负担读压力，注意balance&#x3D;3 只在1.4 及其以后版本有，1.3 没有。 writeType 属性，负载均衡类型，目前的取值有3 种： writeType&#x3D;”0”, 所有写操作发送到配置的第一个writeHost，第一个挂了切到还生存的第二个，writeHost，重新启动后已切换后的为准，切换记录在配置文件中:dnindex.properties writeType&#x3D;”1”，所有写操作都随机的发送到配置的writeHost，1.5 以后废弃不推荐 12345678910111213141516&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mycat:rule SYSTEM &quot;rule.dtd&quot;&gt;&lt;mycat:rule xmlns:mycat=&quot;http://io.mycat/&quot;&gt; //columns是分片的列，既分片的依据，algorithm是分片的算法，也会在该文件中配置 &lt;tableRule name=&quot;mod-long&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;mod-long&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; //class 就是代码中的分片算法，property就是算法的传参，这里的算法就是取模算法，count就是取模的除数，这里的count必须和分片数一致，如果想不一致，需要自定义分片算法 &lt;function name=&quot;mod-long&quot; class=&quot;io.mycat.route.function.PartitionByMod&quot;&gt; &lt;!-- how many data nodes --&gt; &lt;property name=&quot;count&quot;&gt;2&lt;/property&gt; &lt;/function&gt;&lt;/mycat:rule&gt; 雪花算法自增idID&#x3D; 64 位二进制 (1(标识)+41(毫秒)+5(机器 ID)+5(业务编码)+12(重复累加) 即换算成十进制为18位数的long类型，每毫秒可以并发12位二进制的累加。 一：修改server.mxl 1&lt;property name=&quot;sequnceHandlerType&quot;&gt;2&lt;/property&gt; sequnceHandlerType: 0：表示使用本地文件方式，即使用sequence_conf.properties文件 1：表示专用数据库方式，即无法自增 2：表示使用本地时间戳，即雪花算法 3：使用zookeeper生成主键id，非递增 4：使用zookeeper生成主键id，递增 本文主要介绍雪花算法生成id：其他方式参考文章： Mycat 分片表全局自增主键实现及测试_mycat集群自增主键原理_if 0 &#x3D; -I can的博客-CSDN博客 二：配置sequence_time_conf.properties文件 123#sequence depend on TIMEWORKID=01DATAACENTERID=01 WORKID&#x3D;01：设置雪花算法中的业务编码（0-31任意整数） DATAACENTERID&#x3D;01：设置雪花算法中的机器编码（0-31任意整数） 多个mycat节点下每个mycat配置的 WORKID，DATAACENTERID不同，组成唯一标识，总共支持32*32&#x3D;1024种组合 三：修改schema.xml配置 123&lt;schema name=&quot;sharding_db&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;table name=&quot;t_user_mycat&quot; dataNode=&quot;dn1,dn2&quot; primaryKey=&quot;id&quot; rule=&quot;mod-long&quot; autoIncrement=&quot;true&quot;/&gt;&lt;/schema&gt; 为虚拟表添加autoIncrement&#x3D;”true”配置 Java端测试12345678910public static void main(String[] args) throws ClassNotFoundException, SQLException &#123; //mysql驱动版本：mysql-connector-java-8.0.15.jar Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;); Connection connection = DriverManager.getConnection(&quot;jdbc:mysql://localhost:8066/sharding_db?serverTimezone=UTC&amp;useSSL=false&quot;, &quot;root&quot;, &quot;123456&quot;); //mycat支持mysql批量插入语法 int i = JdbcUtils.executeUpdate(connection, &quot;insert into t_user_mycat(name,sex) values(&#x27;李四&#x27;,&#x27;男&#x27;),(&#x27;王五&#x27;,&#x27;男&#x27;)&quot;, new ArrayList&lt;&gt;()); System.out.println(i); System.out.println(JSON.toJSONString(JdbcUtils.executeQuery(connection, &quot;select * from t_user_mycat&quot;, new ArrayList&lt;&gt;()))); connection.close();&#125; 从上图可以看出两条记录分表存入了两张物理表 读写分离配置读写分离必须配合mysql的主从同步，具体同步的配置参考mysql主从复制 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt; &lt;schema name=&quot;write_read&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;table name=&quot;t_user_mycat&quot; dataNode=&quot;dn3&quot; primaryKey=&quot;id&quot; rule=&quot;mod-long&quot; autoIncrement=&quot;true&quot;/&gt; &lt;/schema&gt; &lt;dataNode name=&quot;dn3&quot; dataHost=&quot;localhost3&quot; database=&quot;write_read&quot;/&gt; &lt;dataHost name=&quot;localhost3&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;1&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM3&quot; url=&quot;jdbc:mysql://127.0.0.1:3306?useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;serverTimezone=UTC&amp;amp;allowMultiQueries=true&quot; user=&quot;root&quot; password=&quot;123456&quot;&gt; &lt;readHost host=&quot;hostR1&quot; url=&quot;jdbc:mysql://127.0.0.1:3316?useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;serverTimezone=UTC&amp;amp;allowMultiQueries=true&quot; user=&quot;root&quot; password=&quot;123456&quot;&gt; &lt;/readHost&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; 1234&lt;function name=&quot;mod-long&quot; class=&quot;io.mycat.route.function.PartitionByMod&quot;&gt; //将分片算法的分片数修改为1 &lt;property name=&quot;count&quot;&gt;1&lt;/property&gt;&lt;/function&gt; 测试","categories":["Mysql分库分表"]},{"title":"Spring Security 整合 Oauth2","path":"/2025/01/07/Spring Security 整合 Oauth2/","content":"依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.security.oauth.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2-autoconfigure&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt;&lt;/dependency&gt; 现在Spring Cloud的环境下，一般引入以下依赖，spring-cloud-starter-oauth2包括了spring-security-oauth2-autoconfigure 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt; 授权服务器密码编码器1234@Beanpublic PasswordEncoder passwordEncoder() &#123; return new BCryptPasswordEncoder();&#125; 向Spring注册PasswordEncoder，PasswordEncoder就是密码加密器，用来对数据加密以及验证密码等数据是否匹配，主要实现是BCryptPasswordEncoder，Spring Security默认使用的就是BCryptPasswordEncoder，因为可能涉及到循环依赖的问题，所以不能把PasswordEncoder放进Spring Security的配置和Oauth2授权配置中注册 用户服务配置1234567891011121314@Componentpublic class UserDetailsServiceImpl implements UserDetailsService &#123; @Autowired private PasswordEncoder passwordEncoder; @Override public UserDetails loadUserByUsername(String userName) throws UsernameNotFoundException &#123; return User.withUsername(userName) .password(passwordEncoder.encode(&quot;hello&quot;)) .authorities(&quot;ROLE_ADMIN&quot;) .build(); &#125;&#125; 这里我们自己非常简单的实现了一个用户服务，但是Spring Security默认提供了几种实现方式，主要可以参考org.springframework.security.provisioning.JdbcUserDetailsManager类，这个类默认实现了数据库管理用户的方式，如果需要使用该类，使用@Bean自动注入即可 Spring Security的配置123456789101112131415161718192021@Configuration@EnableWebSecurity@RequiredArgsConstructor(onConstructor = @_(@Autowired))public class OAuth2SecurityConfig extends WebSecurityConfigurerAdapter &#123; private final UserDetailsService userDetailsService; private final PasswordEncoder passwordEncoder; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.userDetailsService(userDetailsService).passwordEncoder(passwordEncoder); &#125; @Bean @Override protected AuthenticationManager authenticationManager() throws Exception &#123; return super.authenticationManager(); &#125;&#125; configure(AuthenticationManagerBuilder auth)：通过调用auth相关方法配置用户授权 userDetailsService()：配置用户服务，主要方法是loadUserByUsername，通过用户名获取用户，可以使用Spring Security默认实现的，也可以自己实现 passwordEncoder()：用来配置加密方法，这里的作用校验密码，可以理解为用来加密用户输入的密码来和数据库中用户的密码进行比较，**所以这里配置的加密方法需要和用户密码加密方式一致，**不配置默认为BCryptPasswordEncoder authenticationManager()：将继承获得的AuthenticationManager注册进Spring Oauth2授权配置123456789101112131415161718192021222324252627282930313233343536373839@Configuration@EnableAuthorizationServer@RequiredArgsConstructor(onConstructor = @_(@Autowired))public class OAuth2AuthServerConfig extends AuthorizationServerConfigurerAdapter &#123; private final DataSource dataSource; private final PasswordEncoder passwordEncoder; private final AuthenticationManager authenticationManager; @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &#123; endpoints.tokenStore(tokenStore()).authenticationManager(authenticationManager); &#125; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; clients.jdbc(dataSource).passwordEncoder(passwordEncoder); &#125; @Override public void configure(AuthorizationServerSecurityConfigurer security) throws Exception &#123; security.passwordEncoder(passwordEncoder).checkTokenAccess(&quot;isAuthenticated()&quot;);//这个方法简单来说就是设置访问oauth/check_token的权限 &#125; @Bean public TokenStore tokenStore() &#123;// return new JwtTokenStore(jwtAccessTokenConverter()); return new JdbcTokenStore(dataSource); &#125;// @Bean// public JwtAccessTokenConverter jwtAccessTokenConverter() &#123;// JwtAccessTokenConverter jwtAccessTokenConverter = new JwtAccessTokenConverter();// jwtAccessTokenConverter.setSigningKey(&quot;657ddc02-1fba-461f-ab30-27e2b8b0a2d6&quot;);// return jwtAccessTokenConverter;// &#125;&#125; configure(AuthorizationServerEndpointsConfigurer endpoints)：通过调用endpoints相关方法配置授权 tokenStore()：配置token具体内容存储方式，主要有JdbcTokenStore和JwtTokenStore，使用JwtTokenStore时需要配置JwtAccessTokenConverter，这个决定了资源服务器如何获取授权token具体内容，JdbcTokenStore通过将token具体内容存入数据库，然后传递一个主键id给资源服务器，资源服务器通过这个主键id在数据库中查询数据，JwtTokenStore将token具体内容放在jwt中，利用jwt的特性保证token具体内容的准确性 authenticationManager(authenticationManager)：配置授权管理器，这里的authenticationManager就是在OAuth2SecurityConfig注册的，如果不设置的话，密码模式就无法正常使用 configure(ClientDetailsServiceConfigurer clients)：通过调用clients相关方法配置client（客户端） jdbc()：配置数据源，调用这个方式就决定了将client信息存储在数据库中 inMemory()：调用该方法就决定了将client存储在内存中，具体信息需要在该方法后面进行配置，并且不会持久化，这里我们没有使用，可自行了解 passwordEncoder()：配置client加密方式，主要作用于org.springframework.security.oauth2.provider.client.JdbcClientDetailsService，可以具体查看此类代码了解密码加密器的作用 configure(AuthorizationServerSecurityConfigurer security)：利用security相关方法，进行安全相关配置 passwordEncoder()：配置client授权时的加密方式，可以理解为用来加密用户输入的client密码来和数据库中client的密码进行比较，**所以这里配置的加密方法需要和cleint密码加密方式一致，**不配置默认为BCryptPasswordEncoder checkTokenAccess()：配置check_token接口的访问权限，主要有 permitAll(): 允许所有请求访问访问令牌验证接口，不进行访问控制。 isAuthenticated(): 仅允许经过身份验证的用户访问访问令牌验证接口。 hasAuthority(String authority): 限制仅具有指定权限的用户可以访问访问令牌验证接口。 hasAnyAuthority(String… authorities): 限制仅具有指定权限之一的用户可以访问访问令牌验证接口。 hasRole(String role): 限制仅具有指定角色的用户可以访问访问令牌验证接口。 hasAnyRole(String… roles): 限制仅具有指定角色之一的用户可以访问访问令牌验证接口。 tokenKeyAccess()：配置token_key接口的访问权限，主要配置和checkTokenAccess方法一致 tokenStore()：向spring注册TokenStore，TokenStore的作用可理解为生成和验证token，即token管理，主要有JwtTokenStore、JdbcTokenStore、RedisTokenStore等，分别基于Jwt、数据库、Redis管理Token jwtAccessTokenConverter()：向Spring注册JwtAccessTokenConverter，因为这里我们使用的是JdbcTokenStore，所以被注释掉了，它的作用可以理解为如何生成以及解析Jwt，如果我们使用的是JwtTokenStore，就需要使用到这个类 生成token过程1234567public interface AuthorizationServerTokenServices &#123; OAuth2AccessToken createAccessToken(OAuth2Authentication var1) throws AuthenticationException; OAuth2AccessToken refreshAccessToken(String var1, TokenRequest var2) throws AuthenticationException; OAuth2AccessToken getAccessToken(OAuth2Authentication var1);&#125; Spring Security Oauth2生成依靠AuthorizationServerTokenServices，源码中它只有一个默认实现类org.springframework.security.oauth2.provider.token.DefaultTokenServices，如果需要配置自己实现的AuthorizationServerTokenServices，可以在上面的Oauth2授权配置中的configure(AuthorizationServerEndpointsConfigurer endpoints)，调用endpoints的tokenServices方法进行配置，具体AuthorizationServerTokenServices如何生效的，可以参考org.springframework.security.oauth2.provider.endpoint.TokenEndpoint#postAccessToken方法，也就是对外的&#x2F;oauth&#x2F;token节点 1234567891011121314151617181920212223242526272829303132333435public OAuth2AccessToken createAccessToken(OAuth2Authentication authentication) throws AuthenticationException &#123; OAuth2AccessToken existingAccessToken = this.tokenStore.getAccessToken(authentication); OAuth2RefreshToken refreshToken = null; if (existingAccessToken != null) &#123; if (!existingAccessToken.isExpired()) &#123; this.tokenStore.storeAccessToken(existingAccessToken, authentication); return existingAccessToken; &#125; if (existingAccessToken.getRefreshToken() != null) &#123; refreshToken = existingAccessToken.getRefreshToken(); this.tokenStore.removeRefreshToken(refreshToken); &#125; this.tokenStore.removeAccessToken(existingAccessToken); &#125; if (refreshToken == null) &#123; refreshToken = this.createRefreshToken(authentication); &#125; else if (refreshToken instanceof ExpiringOAuth2RefreshToken) &#123; ExpiringOAuth2RefreshToken expiring = (ExpiringOAuth2RefreshToken)refreshToken; if (System.currentTimeMillis() &gt; expiring.getExpiration().getTime()) &#123; refreshToken = this.createRefreshToken(authentication); &#125; &#125; OAuth2AccessToken accessToken = this.createAccessToken(authentication, refreshToken); this.tokenStore.storeAccessToken(accessToken, authentication); refreshToken = accessToken.getRefreshToken(); if (refreshToken != null) &#123; this.tokenStore.storeRefreshToken(refreshToken, authentication); &#125; return accessToken;&#125; 这是DefaultTokenServices实现的createAccessToken方法，可以看到是依靠TokenStore生成token 总结整个授权服务器主要有两个配置，Spring Security的配置主要就是用户的配置，Oauth2授权配置主要就是配置client以及token 资源服务器Oauth2配置123456789101112131415161718192021222324252627282930313233343536373839404142@Configuration@EnableResourceServer@EnableGlobalMethodSecurity(prePostEnabled=true)public class ResourceServerConfig extends ResourceServerConfigurerAdapter &#123; @Autowired private DataSource dataSource; @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception &#123; resources.resourceId(&quot;resource&quot;).tokenStore(tokenStore());// resources.tokenServices(tokenServices()); &#125; @Override public void configure(HttpSecurity http) throws Exception &#123; http.authorizeRequests().anyRequest().authenticated(); &#125; @Bean public TokenStore tokenStore()&#123;// return new JwtTokenStore(jwtAccessTokenConverter()); return new JdbcTokenStore(dataSource); &#125;// @Bean// public JwtAccessTokenConverter jwtAccessTokenConverter()&#123;// JwtAccessTokenConverter jwtAccessTokenConverter = new JwtAccessTokenConverter();// jwtAccessTokenConverter.setSigningKey(&quot;657ddc02-1fba-461f-ab30-27e2b8b0a2d6&quot;);// return jwtAccessTokenConverter;// &#125;// 不配置TokenStore的情况下，需要配置tokenService，作用是向认证服务器发起请求验证token// @Bean// ResourceServerTokenServices tokenServices() &#123;// RemoteTokenServices services = new RemoteTokenServices();// services.setCheckTokenEndpointUrl(&quot;http://localhost:9000/oauth/check_token&quot;);// services.setClientId(&quot;dev&quot;);// services.setClientSecret(&quot;dev&quot;);// return services;// &#125;&#125; configure(ResourceServerSecurityConfigurer resources)：通过resources配置资源服务相关配置 resourceId()：配置当前资源的id，作用是与client的resource_ids匹配，如果client的resource_ids中不包括当前资源的id，则无法授权 tokenStore()：配置资源服务器的TokenStore，这里配置的需要和授权服务器一致，否则无法授权 tokenServices()：配置token服务，如果不配置默认为org.springframework.security.oauth2.provider.token.DefaultTokenServices，这个类使用TokenStore验证和解析token，如果这里配置了其他tokenServices，那么配置的TokenStore就没用了，如果配置为org.springframework.security.oauth2.provider.token.RemoteTokenServices，这个类使用远程调用授权服务器的接口验证和解析token configure(HttpSecurity http)：配置资源服务器，该类可以进行很多配置，详情参考该类，不同的配置可以and连接 authorizeRequests()：配置接口访问权限 匹配请求 anyRequest()：匹配任何请求 antMatchers(String… antPatterns)：匹配参数中的数据接口 匹配请求的访问权限 authenticated()：已授权的用户可访问 hasAnyRole(String… roles)：已授权并且拥有参数中的角色的用户可访问 exceptionHandling()：配置异常处理程序，和上面的authorizeRequests()同时使用时，使用and()方法连接 tokenStore()：向Spring注入TokenStore，需要和授权服务器一致 jwtAccessTokenConverter()：向Spring注册JwtAccessTokenConverter，因为这里我们使用的是JdbcTokenStore，所以被注释掉了，它的作用可以理解为如何生成以及解析Jwt，如果我们使用的是JwtTokenStore，就需要使用到这个类 tokenServices()：向Spring注册ResourceServerTokenServices，ResourceServerTokenServices是真正验证和解析token的类，TokenStore是在ResourceServerTokenServices的子类中生效的，这里我们使用TokenStore，默认使用DefaultTokenServices，所以不许配置ResourceServerTokenServices 验证和解析token过程123public interface AuthenticationManager &#123; Authentication authenticate(Authentication var1) throws AuthenticationException;&#125; AuthenticationManager是Spring Security身份验证接口，这个接口的authenticate就是整体验证方法，具体验证方法必须实现这个接口 12345678910111213141516171819202122232425262728public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; if (authentication == null) &#123; throw new InvalidTokenException(&quot;Invalid token (token not found)&quot;); &#125; else &#123; String token = (String)authentication.getPrincipal(); OAuth2Authentication auth = this.tokenServices.loadAuthentication(token); if (auth == null) &#123; throw new InvalidTokenException(&quot;Invalid token: &quot; + token); &#125; else &#123; Collection&lt;String&gt; resourceIds = auth.getOAuth2Request().getResourceIds(); if (this.resourceId != null &amp;&amp; resourceIds != null &amp;&amp; !resourceIds.isEmpty() &amp;&amp; !resourceIds.contains(this.resourceId)) &#123; throw new OAuth2AccessDeniedException(&quot;Invalid token does not contain resource id (&quot; + this.resourceId + &quot;)&quot;); &#125; else &#123; this.checkClientDetails(auth); if (authentication.getDetails() instanceof OAuth2AuthenticationDetails) &#123; OAuth2AuthenticationDetails details = (OAuth2AuthenticationDetails)authentication.getDetails(); if (!details.equals(auth.getDetails())) &#123; details.setDecodedDetails(auth.getDetails()); &#125; &#125; auth.setDetails(authentication.getDetails()); auth.setAuthenticated(true); return auth; &#125; &#125; &#125;&#125; OAuth2AuthenticationManager是Spring Security Oauth2实现的AuthenticationManager（身份验证管理器），方法里面使用ResourceServerTokenServices验证和解析token 12345public interface ResourceServerTokenServices &#123; OAuth2Authentication loadAuthentication(String var1) throws AuthenticationException, InvalidTokenException; OAuth2AccessToken readAccessToken(String var1);&#125; ResourceServerTokenServices接口有两个方法，loadAuthentication验证token，readAccessToken获取token内容 1234567891011121314151617181920212223242526public OAuth2Authentication loadAuthentication(String accessTokenValue) throws AuthenticationException, InvalidTokenException &#123; OAuth2AccessToken accessToken = this.tokenStore.readAccessToken(accessTokenValue); if (accessToken == null) &#123; throw new InvalidTokenException(&quot;Invalid access token: &quot; + accessTokenValue); &#125; else if (accessToken.isExpired()) &#123; this.tokenStore.removeAccessToken(accessToken); throw new InvalidTokenException(&quot;Access token expired: &quot; + accessTokenValue); &#125; else &#123; OAuth2Authentication result = this.tokenStore.readAuthentication(accessToken); if (result == null) &#123; throw new InvalidTokenException(&quot;Invalid access token: &quot; + accessTokenValue); &#125; else &#123; if (this.clientDetailsService != null) &#123; String clientId = result.getOAuth2Request().getClientId(); try &#123; this.clientDetailsService.loadClientByClientId(clientId); &#125; catch (ClientRegistrationException var6) &#123; throw new InvalidTokenException(&quot;Client not valid: &quot; + clientId, var6); &#125; &#125; return result; &#125; &#125;&#125; Spring Security Oauth2默认使用的是DefaultTokenServices，DefaultTokenService的loadAuthentication使用TokenStore管理token，我们也可以自己配置ResourceServerTokenServices，比如配置RemoteTokenServices，它通过远程调用授权服务器，验证和解析token 用户管理如果想在资源服务器的代码中管理用户信息，需要根据TokenStore不同编写不同的代码，不过以下代码可以参考 123OAuth2Authentication authentication = (OAuth2Authentication) SecurityContextHolder.getContext().getAuthentication();response.put(&quot;user_name&quot;, authentication.getName());response.put(&quot;authorities&quot;, AuthorityUtils.authorityListToSet(authentication.getAuthorities())); 这样可以获取用户的用户名和角色 Client主要参数介绍 client_id：id，client的标识，相当于用户的用户名 resource_ids：资源id，多个值用逗号隔开，代表当前client可以访问哪些资源 client_secret：client的密码，在访问&#x2F;oauth&#x2F;token接口时，需要提交该参数 scope：可访问的范围，多个值用逗号隔开，可通过@PreAuthorize(“#oauth2.hasScope(‘scope’)”)控制具体接口的权限，scope比resource_ids控制的粒度更细，可以控制到具体的接口，具体控制权限方式参考org.springframework.security.oauth2.provider.expression.OAuth2SecurityExpressionMethods，#oauth2代表的就是OAuth2SecurityExpressionMethods，scope除了配置的外，还可以通过在访问&#x2F;oauth&#x2F;authorize接口时设置scope参数控制scope，但是值必须是配置中有的，另外，如果在访问&#x2F;oauth&#x2F;authorize接口时设置多个scope，使用空格隔开 authorized_grant_types：生成token的模式，多个值用逗号隔开，具体可选值参考org.springframework.security.oauth2.provider.TokenGranter的实现类，可选值如下 authorization_code：授权码模式 implicit：简化模式 password：密码模式 client_credentials：客户端模式 refresh_token：是否允许通过刷新令牌获取授权令牌 web_server_redirect_uri：可重定向路径，即&#x2F;oauth&#x2F;authorize接口中redirect_uri的可选值，多个只用逗号隔开 authorities：授权，多个值用逗号隔开，可通过@PreAuthorize(“#oauth2.clientHasRole(‘authoritie’)”)控制具体接口的权限，具体和scope类似 access_token_validity：授权令牌有效期，即当前client访问一次令牌的时效 refresh_token_validity：刷新令牌有效期 additional_information：client额外的信息，可通过json配置更多的信息 autoapprove：是否自动批准，如果是false，则登录后在浏览器会有一个批准界面 刷新令牌oauth2授权服务器在给应用服务器颁发授权令牌的时候，同时还会颁发一个刷新令牌，如果授权令牌过期，在刷新令牌有效期内可以使用刷新令牌访问&#x2F;oauth&#x2F;token接口，重新获取授权令牌，访问示例：http://127.0.0.1:9000/oauth/token?grant_type&#x3D;refresh_token&amp;refresh_token&#x3D;&lt;刷新令牌&gt;，使用刷新令牌而不是直接将授权令牌的时间加长一点，是因为刷新令牌是可控的，而直接将授权令牌的时间加长是不可控的 Oauth2四种模式授权码模式（Authorization Code Grant）本章将使用Oauth2授权码模式，这也是Oauth2四种模式在第三方登录的情况下最安全的一种模式，适用于具有服务器端的应用程序，例如Web应用。用户在客户端界面上发起授权请求，将被重定向到授权服务器进行身份验证。一旦用户授权，授权服务器将颁发一个授权码，然后客户端使用该授权码在授权服务器上进行验证，并交换访问令牌和刷新令牌。 为什么需要去指定页面登录因为如果在第三方软件页面登录，会造成密码泄漏，所以必须在自己的页面输入密码 为什么请求玩code还需要在请求一个access_token因为登录是在自己的页面完成的，所以没办法将code直接传给第三方，只能通过浏览器重定向实现code的发送，所以code本身是不安全的，故需要利用code再次请求access_token，code请求一次就是失效了，也是为了安全 简图 接口调用过程 浏览器输入http://127.0.0.1:9000/oauth/authorize?client_id&#x3D;dev&amp;redirect_uri&#x3D;&lt;重定向接口，一般就是你应用的接口&gt;&amp;response_type&#x3D;code&amp;scope&#x3D;app，浏览器会弹出账号密码输入界面，输入账号密码，点击登录 登录成功后，浏览器重定向到你设置的重定向的接口，并将生成的code作为参数，请求传到应用服务端，应用服务端收到code后将client的账号密码放进Authorization请求http://127.0.0.1:9000/oauth/token?grant_type&#x3D;authorization_code&amp;code&#x3D;&lt;重定向的code&gt;&amp;redirect_uri&#x3D;&lt;上面写的重定向的地址，只起到验证的效果&gt;，授权服务器验证过code后，返回access_token给应用服务端 简化模式（Implicit Grant）适用于没有服务器端的应用程序，例如纯前端JavaScript应用。与授权码模式类似，用户在客户端界面上发起授权请求，将被重定向到授权服务器进行身份验证。一旦用户授权，授权服务器将直接颁发访问令牌给客户端，不再提供授权码。这种模式下，访问令牌会直接传递给客户端，因此需要确保传输通道的安全性。 简图 接口调用过程 浏览器输入http://127.0.0.1:9000/oauth/authorize?client_id&#x3D;dev&amp;redirect_uri&#x3D;&lt;重定向接口，一般就是你应用的接口&gt;&amp;response_type&#x3D;token&amp;scope&#x3D;app，浏览器会弹出账号密码输入界面，输入账号密码，点击登录 登陆成功后，浏览器重定向到设置的重定向接口，并将生成的access_token作为参数，这里的access_token就是访问令牌，所以不需要像授权码模式一样再经过后台访问授权服务器拿到令牌 密码模式（Password Grant）适用于高度信任的应用程序，例如可信任的原生移动应用。在密码模式下，用户直接向客户端提供其凭据（用户名和密码），客户端将凭证发送到授权服务器进行验证。一旦验证成功，授权服务器直接颁发访问令牌给客户端。这种模式要求客户端存储用户凭证，并且不适用于公共客户端。 简图 接口调用过程 浏览器输入应用服务器登录接口，并且传递用户账号名密码，后台收到用户名账号和密码后，将client的账号密码放进Authorization并携带用户名账号和密码访问授权服务器获取token的接口http://127.0.0.1:9000/oauth/token?grant_type&#x3D;password&amp;username&#x3D;&lt;用户输入的用户名&gt;&amp;password&#x3D;&lt;用户输入的密码&gt; 授权服务器通过验证后，返回access_token给应用服务器，这里不需要像授权码模式一样需要访问授权服务器的授权接口重定向后再访问应用服务器，而是直接访问应用服务器就可以了 客户端模式（Client Credentials Grant）适用于无关用户操作的情况，如何应用服务器后台定时任务需要访问资源，这种不涉及用户的操作不存在用户验证，可以直接通过client信息获取token。在客户端模式下，客户端使用自己的凭据向授权服务器发起授权请求，授权服务器对客户端进行验证，并直接颁发访问令牌。这种模式下，不涉及用户的身份验证。 简图 接口调用过程 应用后台将client的账号密码放进Authorization并访问授权服务器获取token接口http://127.0.0.1:9000/oauth/token?grant_type&#x3D;client_credentials，授权服务器收到并且验证通过后，直接返回access_token JWT结构JWT分为三部分 头部（Header）：头部通常由两部分组成，类型和算法。类型是固定的，表示令牌的类型为JWT。算法用于签名验证和生成签名。常见的算法包括HMAC SHA256和RSA。头部会被Base64编码。 载荷（Payload）：载荷是JWT的主要部分，包含了一些声明（Claims），用于描述身份信息、用户权限等相关内容。它可以是预定义的声明，如过期时间（exp）、发布时间（iat），也可以是自定义的声明。载荷也会被Base64编码。 签名（Signature）：签名是使用私钥对头部和载荷进行加密生成的一段字符串。签名的目的是验证令牌的真实性和完整性。接收到JWT后，服务器使用相同的算法和密钥对头部和载荷进行解密，并验证签名是否与解密后的内容匹配。 作用在单机的情况下，web应用一般使用cookie存储用户信息，但是在分布式的情况下就不实用了，比如A应用存储了当前用户的信息，当前用户可以访问，但是B应用没有存储，则不能访问，这样就出现问题了，在这种情况下，一般会引入分布式缓存（如Redis）用来存储用户信息，不过引入分布式缓存，提升了系统复杂性，并且查询和写入缓存也是一笔性能开销，对服务端性能会造成损耗，为了减少服务端的压力，JWT的出现将信息直接存储到客户端（每一个用户对应一个客户端，对于客户端的压力可以忽略不计），利用客户端存储用户信息，在非必要对用户信息加密的情况下，JWT使用签名保证用户信息的真实性（如果需要对用户信息加密，可以使用JWE，可以理解为JWT对载荷加密的版本，但是对载荷加密，生成的token会更大，而且加密解密也会增加性能的开销），不过虽然JWT对客户端没有压力，但是每次需要在请求中携带JWT token，增加了网络的开销，所以用户信息比较大时，使用分布式缓存可能更合适 对接口控制如何生效的HttpSecurity对接口控制HttpSecurity可以通过authorizeRequests()方法控制具体接口的访问权限，示例：http.authorizeRequests().antMatchers(“&#x2F;order&#x2F;**”).access(“#oauth2.hasScope(‘scope’)”); 控制&#x2F;order&#x2F;开头的接口，如果访问此类接口，client必须具有”scope”的scope 主要通过org.springframework.security.config.annotation.web.configurers.ExpressionUrlAuthorizationConfigurer#expressionHandler控制的，expressionHandler的定义是SecurityExpressionHandler类 12345public interface SecurityExpressionHandler&lt;T&gt; extends AopInfrastructureBean &#123; ExpressionParser getExpressionParser(); EvaluationContext createEvaluationContext(Authentication var1, T var2);&#125; SecurityExpressionHandler有两个实现类 12345678910111213141516171819202122232425public class DefaultWebSecurityExpressionHandler extends AbstractSecurityExpressionHandler&lt;FilterInvocation&gt; implements SecurityExpressionHandler&lt;FilterInvocation&gt; &#123; private AuthenticationTrustResolver trustResolver = new AuthenticationTrustResolverImpl(); private String defaultRolePrefix = &quot;ROLE_&quot;; public DefaultWebSecurityExpressionHandler() &#123; &#125; protected SecurityExpressionOperations createSecurityExpressionRoot(Authentication authentication, FilterInvocation fi) &#123; WebSecurityExpressionRoot root = new WebSecurityExpressionRoot(authentication, fi); root.setPermissionEvaluator(this.getPermissionEvaluator()); root.setTrustResolver(this.trustResolver); root.setRoleHierarchy(this.getRoleHierarchy()); root.setDefaultRolePrefix(this.defaultRolePrefix); return root; &#125; public void setTrustResolver(AuthenticationTrustResolver trustResolver) &#123; Assert.notNull(trustResolver, &quot;trustResolver cannot be null&quot;); this.trustResolver = trustResolver; &#125; public void setDefaultRolePrefix(String defaultRolePrefix) &#123; this.defaultRolePrefix = defaultRolePrefix; &#125;&#125; createSecurityExpressionRoot方法实际返回的WebSecurityExpressionRoot对象就是真正控制访问权限的方法，例如http.authorizeRequests().antMatchers(“&#x2F;order&#x2F;**”).access(“hasRole(‘role’)”)中access中配置的hasRole方法来自于WebSecurityExpressionRoot，具体有哪些方法，参考WebSecurityExpressionRoot对象 1234567891011public class OAuth2WebSecurityExpressionHandler extends DefaultWebSecurityExpressionHandler &#123; public OAuth2WebSecurityExpressionHandler() &#123; this.setExpressionParser(new OAuth2ExpressionParser(this.getExpressionParser())); &#125; protected StandardEvaluationContext createEvaluationContextInternal(Authentication authentication, FilterInvocation invocation) &#123; StandardEvaluationContext ec = super.createEvaluationContextInternal(authentication, invocation); ec.setVariable(&quot;oauth2&quot;, new OAuth2SecurityExpressionMethods(authentication)); return ec; &#125;&#125; createEvaluationContextInternal返回的StandardEvaluationContext中的OAuth2SecurityExpressionMethods对象就是真正控制访问权限的方法，即http.authorizeRequests().antMatchers(“&#x2F;order&#x2F;**”).access(“#oauth2.hasScope(‘scope’)”)中access中配置的hasScope方法来自于OAuth2SecurityExpressionMethods，但是和WebSecurityExpressionRoot不一样的事，使用OAuth2SecurityExpressionMethods的方法需要写上#oauth2，#oauth2代表的就是OAuth2SecurityExpressionMethods，具体有哪些方法，参考OAuth2SecurityExpressionMethods对象 @PreAuthorize对方法控制@PreAuthorize(“@rs.ok()”)，@PreAuthorize主要依靠org.springframework.security.access.expression.method.ExpressionBasedPreInvocationAdvice#expressionHandler，expressionHandler的定义是MethodSecurityExpressionHandler 12345public interface MethodSecurityExpressionHandler extends SecurityExpressionHandler&lt;MethodInvocation&gt; &#123; Object filter(Object var1, Expression var2, EvaluationContext var3); void setReturnObject(Object var1, EvaluationContext var2);&#125; 可以看到MethodSecurityExpressionHandler是上面说的SecurityExpressionHandler的实现类，但是只定义拦截方法，SecurityExpressionHandler介意拦截方法，也可以定义拦截具体接口 所以@PreAuthorize对方法控制和HttpSecurity对接口控制使用的底层方法都是一样，依靠的就是SecurityExpressionHandler的实现类，所以它们参数中的方法也是一样的 @和#的区别12345@GetMapping(&quot;/hello&quot;)@PreAuthorize(&quot;#rs.ok()&quot;)public String hello(TestController rs) &#123;return JSON.toJSONString(UserManager.getUser());&#125; 12345@GetMapping(&quot;/hello&quot;)@PreAuthorize(&quot;@rs.ok()&quot;)public String hello() &#123;return JSON.toJSONString(UserManager.getUser());&#125; # 占位符： 用于引用方法参数：如果你想要在权限表达式中引用方法的参数，可以使用 # 占位符。例如，@PreAuthorize(“hasRole(#role)”) 表示方法的参数 role 的值会作为权限表达式的一部分。 用于引用方法参数的属性或方法：如果方法参数是一个对象，你可以使用 # 操作符来访问其属性或调用其方法。例如，@PreAuthorize(“#user.isAdmin()”) 表示方法的参数 user 的 isAdmin() 方法的结果会作为权限表达式的一部分。 例如上面第一个代码，#rs代表的就是使用参数中的TestController rs作为验证身份方法的使用类，如果参数中没有rs就会报错，之前提到的http.authorizeRequests().antMatchers(“&#x2F;order&#x2F;**”).access(“#oauth2.hasScope(‘scope’)”)中的#oauth2也是如此，只是逻辑较为复杂，我们无法直接看到oauth2是如何作为参数的 @ 占位符： 用于引用身份验证上下文对象的属性：如果你想要引用当前身份验证上下文对象 (Authentication) 中的属性，可以使用 @ 占位符。例如，@PreAuthorize(“@authentication.isAuthenticated()”) 表示身份验证上下文对象的 isAuthenticated() 方法的结果会作为权限表达式的一部分。 用于引用当前用户的主体信息：你可以使用 @ 操作符来访问当前用户的主体信息。例如，@PreAuthorize(“@principal.username &#x3D;&#x3D; ‘admin’”) 表示当前用户的用户名为 “admin” 时才满足权限表达式。 例如上面第二个中的@rs中的rs就是一个上文对象，即注册到Spring的对象，不许在参数中定义了","categories":["安全"]},{"title":"Sharding Proxy分库分表以及读写分离","path":"/2025/01/07/Sharding Proxy分库分表以及读写分离/","content":"sharding proxy下载地址：https://archive.apache.org/dist/shardingsphere/ 下载之后需要在lib目录下放一个mysql的驱动jar包 分库分表配置sharding-proxy安装目录&#x2F;conf&#x2F;config-sharding.yaml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960databaseName: shardingdataSources: ds_0: url: jdbc:mysql://127.0.0.1:3306/sharding_db?serverTimezone=UTC&amp;useSSL=false username: root password: 123456 connectionTimeoutMilliseconds: 30000 idleTimeoutMilliseconds: 60000 maxLifetimeMilliseconds: 1800000 maxPoolSize: 50 minPoolSize: 1 ds_1: url: jdbc:mysql://127.0.0.1:3316/sharding_db?serverTimezone=UTC&amp;useSSL=false username: root password: 123456 connectionTimeoutMilliseconds: 30000 idleTimeoutMilliseconds: 60000 maxLifetimeMilliseconds: 1800000 maxPoolSize: 50 minPoolSize: 1rules:- !SHARDING tables: t_user_sharding: actualDataNodes: ds_$&#123;0..1&#125;.t_user_sharding$&#123;0..1&#125; tableStrategy: standard: shardingColumn: id shardingAlgorithmName: t_user_inline keyGenerateStrategy: column: id keyGeneratorName: snowflake bindingTables: - t_user_sharding defaultDatabaseStrategy: standard: shardingColumn: id shardingAlgorithmName: database_inline defaultTableStrategy: none: shardingAlgorithms: database_inline: type: INLINE props: algorithm-expression: ds_$&#123;id % 2&#125; t_user_inline: type: INLINE props: algorithm-expression: t_user_$&#123;id % 2&#125; keyGenerators: snowflake: type: SNOWFLAKE auditors: sharding_key_required_auditor: type: DML_SHARDING_CONDITIONS dataSources：配置的实际的节点，可以配置到库，mycat只能配置到连接 rules：配置规则 rules.tables：定义表以及表的相关配置，有些配置没有实际定义，需要从下面的策略中选择 rules.bindingTables：配置表，从上述定义表中选择 rules.defaultDatabaseStrategy：配置默认的分库策略，这里只是配置，但没有定义实际的策略，实际的策略从下面的配置选择 rules.shardingAlgorithms：定义实际的分库分表策略，就是上面配置的 rules.keyGenerators：主键生成策略，就是上面配置的 Java端测试这里用的是sharding proxy5.4.0版本，如果用sharding proxy5.4.0之前的版本，会出现“Unknown system variable ‘query_cache_size’”错误 读写分离配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546databaseName: read_writedataSources: write_ds: url: jdbc:mysql://127.0.0.1:3306/write_read?serverTimezone=UTC&amp;useSSL=false username: root password: 123456 connectionTimeoutMilliseconds: 30000 idleTimeoutMilliseconds: 60000 maxLifetimeMilliseconds: 1800000 maxPoolSize: 50 minPoolSize: 1 read_ds_0: url: jdbc:mysql://127.0.0.1:3316/write_read?serverTimezone=UTC&amp;useSSL=false username: root password: 123456 connectionTimeoutMilliseconds: 30000 idleTimeoutMilliseconds: 60000 maxLifetimeMilliseconds: 1800000 maxPoolSize: 50 minPoolSize: 1rules:- !READWRITE_SPLITTING dataSources: readwrite_ds: writeDataSourceName: write_ds readDataSourceNames: - read_ds_0 loadBalancerName: random loadBalancers: random: type: RANDOM- !SHARDING tables: t_user_sharding: actualDataNodes: write_ds.t_user_sharding keyGenerateStrategy: column: id keyGeneratorName: snowflake bindingTables: - t_user_sharding keyGenerators: snowflake: type: SNOWFLAKE 这里除了用到读写分离策略，还用到了分库分表策略（实际配置并没有分库分表），是为了自动生成id Java端测试 Sharding JDBCsharding jdbc可以理解为sharding proxy本地版，不需要再引入中间件添加系统复杂性了 sharding配置 这里的配置可以直接用sharding proxy conf目录下的配置，两者是同一个东西 数据源配置1234# 配置 DataSource Driverspring.datasource.driver-class-name=org.apache.shardingsphere.driver.ShardingSphereDriver# 指定 YAML 配置文件spring.datasource.url=jdbc:shardingsphere:classpath:config-sharding.yaml 这里不需要配置账号和密码，url使用上面的sharding配置，驱动使用sharding自带的驱动即可 Java端测试","categories":["Mysql分库分表"]},{"title":"Sharding JDBC+Druid+Dynamic","path":"/2025/01/07/Sharding JDBC+Druid+Dynamic/","content":"Sharding JDBCsharding jdbc可以理解为sharding proxy本地版，不需要再引入中间件添加系统复杂性了 sharding依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;shardingsphere-jdbc-core&lt;/artifactId&gt; &lt;version&gt;5.4.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--sharding本身的snakeyaml依赖版本好像低了，所以额外引入高版本的snakeyaml依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.yaml&lt;/groupId&gt; &lt;artifactId&gt;snakeyaml&lt;/artifactId&gt; &lt;version&gt;1.33&lt;/version&gt;&lt;/dependency&gt; sharding配置 这里的配置可以直接用sharding proxy conf目录下的配置，两者唯一的区别就是sharding jdbc中需要配置dataSourceClassName，我们引入了druid，所以使用的是druid的数据源 数据源配置123456789# 配置 DataSource Driverspring.datasource.driver-class-name=org.apache.shardingsphere.driver.ShardingSphereDriver# 指定 YAML 配置文件spring.datasource.url=jdbc:shardingsphere:classpath:config-sharding.yamlspring.datasource.druid.initial-size=5spring.datasource.druid.min-idle=5spring.datasource.druid.max-active=20spring.datasource.druid.max-wait=60000spring.datasource.druid.validation-query=SELECT 1 这里不需要配置账号和密码，url使用上面的sharding配置，驱动使用sharding自带的驱动（必须是用sharding自带的），下面配置的是druid连接池的属性 Java端测试 # 引入Dynamic **dynamic-datasource-spring-boot-starter是mybatis-plus的一部分，是该项目提供的一个子模块，用于增强mybatis-plus在多数据源场景下的功能** 依赖12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;dynamic-datasource-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.5.6&lt;/version&gt;&lt;/dependency&gt; 数据源配置123456789spring.datasource.dynamic.datasource.ds1.driver-class-name=org.apache.shardingsphere.driver.ShardingSphereDriverspring.datasource.dynamic.datasource.ds1.url=jdbc:shardingsphere:classpath:config-sharding.yamlspring.datasource.dynamic.primary=ds1spring.datasource.druid.initial-size=5spring.datasource.druid.min-idle=5spring.datasource.druid.max-active=20spring.datasource.druid.max-wait=60000spring.datasource.druid.validation-query=SELECT 1spring.datasource.dynamic.druid.filters= 引入dynamic后，数据源配置也需要修改 Dynamic与Druid的冲突自动配置类冲突dynamic的DynamicDataSourceAutoConfiguration与druid的DruidDataSourceAutoConfigure在启动会造成冲突，导致dynamic无法正常完成配置，需要在启动类中去除DruidDataSourceAutoConfigure的自动配置 12345678@SpringBootApplication(exclude = DruidDataSourceAutoConfigure.class)public class ShardingjdbcApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ShardingjdbcApplication.class, args); &#125;&#125; 去除DruidDataSourceAutoConfigure的自动配置后，类似于spring.datasource.druid.*之类的配置几乎都是去意义了 filters报错如果不配置spring.datasource.dynamic.druid.filters&#x3D;的话，会出现以下错误 是因为druid的com.alibaba.druid.wall.WallFilter类的init方法，会根据url获取数据库的类型，但是我们配置的是sharding jdbc，并不是正常数据库的连接方式，故WallFilter无法获取数据库类型，所以出现这个错误 代码以及配置中并没有配置druid的WallFilter，为什么会调用此方法呢，因为Dynamic在创建Druid数据源时，会自动为其创建一个WallFilter和一个StatFilter com.baomidou.dynamic.datasource.DynamicDataSourceCreator#createDruidDataSource 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public DataSource createDruidDataSource(DataSourceProperty dataSourceProperty) &#123; if (StringUtils.isEmpty(dataSourceProperty.getPublicKey())) &#123; dataSourceProperty.setPublicKey(this.globalPublicKey); &#125; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUsername(dataSourceProperty.getUsername()); dataSource.setPassword(dataSourceProperty.getPassword()); dataSource.setUrl(dataSourceProperty.getUrl()); dataSource.setDriverClassName(dataSourceProperty.getDriverClassName()); dataSource.setName(dataSourceProperty.getPollName()); DruidConfig config = dataSourceProperty.getDruid(); Properties properties = config.toProperties(this.druidGlobalConfig); String filters = properties.getProperty(&quot;druid.filters&quot;); List&lt;Filter&gt; proxyFilters = new ArrayList(2); if (!StringUtils.isEmpty(filters) &amp;&amp; filters.contains(&quot;stat&quot;)) &#123; StatFilter statFilter = new StatFilter(); statFilter.configFromProperties(properties); proxyFilters.add(statFilter); &#125; if (!StringUtils.isEmpty(filters) &amp;&amp; filters.contains(&quot;wall&quot;)) &#123; WallConfig wallConfig = DruidWallConfigUtil.toWallConfig(dataSourceProperty.getDruid().getWall(), this.druidGlobalConfig.getWall()); WallFilter wallFilter = new WallFilter(); wallFilter.setConfig(wallConfig); proxyFilters.add(wallFilter); &#125; if (this.applicationContext != null) &#123; Iterator var15 = this.druidGlobalConfig.getProxyFilters().iterator(); while(var15.hasNext()) &#123; String filterId = (String)var15.next(); proxyFilters.add(this.applicationContext.getBean(filterId, Filter.class)); &#125; &#125; dataSource.setProxyFilters(proxyFilters); dataSource.configFromPropety(properties); dataSource.setConnectProperties(config.getConnectionProperties()); Boolean testOnReturn = config.getTestOnReturn() == null ? this.druidGlobalConfig.getTestOnReturn() : config.getTestOnReturn(); if (testOnReturn != null &amp;&amp; testOnReturn.equals(true)) &#123; dataSource.setTestOnReturn(true); &#125; Integer validationQueryTimeout = config.getValidationQueryTimeout() == null ? this.druidGlobalConfig.getValidationQueryTimeout() : config.getValidationQueryTimeout(); if (validationQueryTimeout != null &amp;&amp; !validationQueryTimeout.equals(-1)) &#123; dataSource.setValidationQueryTimeout(validationQueryTimeout); &#125; Boolean sharePreparedStatements = config.getSharePreparedStatements() == null ? this.druidGlobalConfig.getSharePreparedStatements() : config.getSharePreparedStatements(); if (sharePreparedStatements != null &amp;&amp; sharePreparedStatements.equals(true)) &#123; dataSource.setSharePreparedStatements(true); &#125; Integer connectionErrorRetryAttempts = config.getConnectionErrorRetryAttempts() == null ? this.druidGlobalConfig.getConnectionErrorRetryAttempts() : config.getConnectionErrorRetryAttempts(); if (connectionErrorRetryAttempts != null &amp;&amp; !connectionErrorRetryAttempts.equals(1)) &#123; dataSource.setConnectionErrorRetryAttempts(connectionErrorRetryAttempts); &#125; Boolean breakAfterAcquireFailure = config.getBreakAfterAcquireFailure() == null ? this.druidGlobalConfig.getBreakAfterAcquireFailure() : config.getBreakAfterAcquireFailure(); if (breakAfterAcquireFailure != null &amp;&amp; breakAfterAcquireFailure.equals(true)) &#123; dataSource.setBreakAfterAcquireFailure(true); &#125; try &#123; dataSource.init(); return dataSource; &#125; catch (SQLException var13) &#123; throw new ErrorCreateDataSourceException(&quot;druid create error&quot;, var13); &#125;&#125; 观察代码可以看出，dynamic会根据druid.filters（不配置则默认为”wall,stat”）配置为druid数据源创建filter，而且因为这里的filter是dynamic通过代码创建的，不是spring管理的，所以spring.datasource.druid.filter.wall.db-type&#x3D;mysql配置对于这里的filter是无效的，而且dynamic也并没有提供filter的dbType的配置，所以我们只能通过配置spring.datasource.dynamic.druid.filters&#x3D;，让dynamic不去生成filter，如果在使用sharding jdbc的情况下需要为druid配置filter的话，可以根据代码逻辑使用spring.datasource.dynamic.druid.proxy-filters配置 如何管理连接以及执行 从图片中可以看到druid连接底层实际上是sharding的连接，也就是druid连接池实际管理的是sharding的连接 从图片中可以看到druid的preparedStatement底层实际上是sharding的preparedStatement，druid的执行实际是sharding的执行 可以看到，最终进入到了sharding的执行方法，具体如何执行的这里就不具体看了","categories":["Mysql分库分表"]},{"title":"Zookeeper 一致性算法","path":"/2025/01/07/Zookeeper 一致性算法/","content":"文章开头先介绍一篇非常好的文章：带你彻底认识 Paxos 算法、Zab 协议和 Raft 协议的原理和本质 简介 我们都知道分布式系统要遵守CAP原则，即一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）只能同时满足两个。 而zookeeper满足的是CP（需要注意这里的C是在选主的过程中会停止服务，而读写过程中并不是强一致性），但是做到一致性并不是那么容易，在科学家和程序员的不断探索中，就出现了很多的一致性协议和算法。比如 2PC（两阶段提交），3PC（三阶段提交），Paxos算法等等。 这里还要提到一个问题，就是信道可靠性的问题，如果消息在传输过程中就已经被修改过了，那么哪怕算法再厉害，最终也不可能做到一致性，所以这里就要提到拜占庭将军问题(在不可靠信道上试图通过消息传递的方式达到一致性是不可能的) 2PC协议2PC协议具体过程分为两步 协调者告诉所有参与者可以进行事务，但不提交，并在执行完事务后，返回执行结果给协调者 协调者收到所有参与者的反馈之后，根据得到的反馈告诉所有参与者提交或者回滚 该协议非常简单，同时也有很多问题，尤为明显的就是过于依赖协调者，这将带来不少问题 协调者如果挂掉，整个系统都将不可用，当然了，可以考虑将协调者设为集群，那么协调者之间的一致性又变成了新的问题，这明显在使问题变复杂。 所有参与者过于依赖协调者的指令，如果执行完事务，因为网络等原因没有收到协调者的指令，将会一直处于等待的阶段，占用资源，并且第二阶段不是所有参与者都成功收到指令，极有可能造成数据不一致 3PC协议3P协议具体过程分为3步 CanCommit: 协调者向所有参与者发起请求，询问参与者是否可以进行事务，参与者收到请求后，向协调者反馈，有需要的可以直接做好准备 PreCommit: 协调者根据上个步骤参与者的反馈向参与者发出执行事务或者取消事务的请求，参与者收到请求后进行相应的操作，如果是执行事务，则执行完后，将 Undo 和 Redo 信息写入事务日志中并反馈给参与者。需要注意，如果参与者在这个过程中长时间没有收到协调者的执行事务或者取消事物的请求，那么参与者将直接取消事务，因为这是参与者并不知道其他参与者是否可以进行事务，所以只能取消事务 DoCommit: 协调者根据上个步骤参与者的反馈向参与者发出提交事务或者回滚事物的请求，参与者收到请求后进行相应的操作。需要注意如果参与者在这个过程中长时间没有收到协调者的提交事务或者回滚事务的请求，那么参与者将直接提交事务，因为经过第一个阶段，基本可以认为其他参与者都可以执行并且提交事务 可以看到，3PC比2PC多了一个CanCommit阶段并且加入了超时机制，CanCommit阶段可以提高事务执行成功的可能性并且是第三阶段超时机制的根据。超时机制的存在让参与者不在过分依赖协调者，有了一定的自主性，克服了2PC过于依赖协调者所导致的问题。但是3PC并不是就完事大吉了，因为超时机制本身就有一定的风险，并且通信次数过多提高了通信带来的风险。 Paxos算法 两个角色 Proposer提案者：负责提出 proposal，同时它也是表决者，只不过对于自己的提案，默认同意，每个提案者在提出提案时都会首先获取到一个 具有全局唯一性的、递增的提案编号N，即在整个集群中是唯一的编号 N，然后将该编号赋予其要提出的提案，在第一阶段是只将提案编号发送给所有的表决者。 Acceptor表决者：每个表决者在 accept 某提案后，会将该提案编号N记录在本地，这样每个表决者中保存的已经被 accept 的提案中会存在一个编号最大的提案，其编号假设为 maxN。每个表决者仅会 accept 编号大于自己本地 maxN 的提案，在批准提案时表决者会将以前接受过的最大编号的提案作为响应反馈给 Proposer Learner学习者：即不参与表决的角色，当一个提案被通过后，学习者再从提案者或者表决者那里获取提案 两个阶段 prepare阶段：提案者获取一个提案编号，并将获取的提案编号发送给所有表决者，表决者收到提案编号后，与自己本地最大的提案编号进行对比，如果新的提案编号大于本地最大的提案编号，将本地的提案编号更新，批准提案并返回结果给提案者，如果新的提案编号不大于本地最大的提案编号，则不批准并返回本地最大提案编号以及提案内容给提案者（这一步可以理解为通过对比拿到集群中最大编号的提案） accept阶段：提案者收到一半以上表决者批准的消息后，如果有收到表决者反馈提案编号大于本次提案编号，则以收到的编号和内容为准，重复第一阶段，将提案编号与提案内容提交给表决者，表决者收到提案后，接受提案内容并返回结果给提案者，如果提案者收到一半以上表决者同意的消息，那么会继续发消息让不同意的表决者无条件的接受提案，到这一步同时会涉及到一个learner学习的过程，即提案者会将本次提案也提交给学习者，或者表决者推送给学习者 Paxos算法也有他的不足，就是如果同时存在多个提案者的时候，容易造成死循环，不过可以限定只能有一个提案者就可以了。 Multi-Paxos协议就是Paxos的基础上限定了一个提案者成为Leader，如果没有Leader或者Leader宕机了，则通过prepare阶段选举Leader，所以当Leader的存在时可以不再进行prepare阶段，因为Leader的特点保证它的提案编号一定会是最大的 ZAB协议作为一个优秀高效且可靠的分布式协调框架，ZooKeeper 在解决分布式数据一致性问题时并没有直接使用 Paxos ，而是专门定制了一致性协议叫做 ZAB(ZooKeeper Atomic Broadcast) 原子广播协议，该协议能够很好地支持崩溃恢复 先了解一些基本概念 electionEpoch：每执行一次 leader 选举，electionEpoch 就会自增，用来标记 leader 选举的轮次 peerEpoch：每次 leader 选举完成之后，都会选举出一个新的 peerEpoch，用来标记事务请求所属的轮次 zxid：事务请求的唯一标记，由 leader 服务器负责进行分配高 32 位是上述的 peerEpoch，低 32 位是请求的计数，从 0 开始。 lastprocessZxid：最后一次 commit 的事务请求的 zxid LinkedList committedLog、long maxCommittedLog、long minCommittedLog：ZooKeeper 会保存最近一段时间内执行的事务请求议案，个数限制默认为 500 个议案。committedLog 就是用来保存议案的列表，maxCommittedLog 表示最大议案的 zxid，minCommittedLog 表示 committedLog 中最小议案的 zxid。 ConcurrentMap&lt;Long, Proposal&gt; outstandingProposals：Leader 拥有的属性，每当提出一个议案，都会将该议案存放至 outstandingProposals，一旦议案被过半认同了，就要提交该议案，则从 outstandingProposals 中删除该议案。 ConcurrentLinkedQueue toBeApplied：Leader 拥有的属性，每当准备提交一个议案，就会将该议案存放至该列表中，一旦议案应用到 ZooKeeper 的内存树中了，然后就可以将该议案从 toBeApplied 中删除。 state：当前服务器的状态 recvQueue：消息接收队列，用于存放那些从其他服务器接收到的消息。 queueSendMap：消息发送队列，用于保存那些待发送的消息，按照 SID 进行分组。 senderWorkerMap：发送器集合，每个 SenderWorker 消息发送器，都对应一台远程 Zookeeper 服务器，负责消息的发送，也按照 SID 进行分组。 lastMessageSent：最近发送过的消息，为每个 SID 保留最近发送过的一个消息。 三个角色 Leader 领导者、Follower跟随者、Observer观察者 （在zookeeper基础中介绍过） 两个模式 消息广播模式：我们可以理解为zookeeper的写机制，当客户端写入数据到zookeeper集群，数据首先会写入Leader，随后Leader将消息广播给Follwer，Follwer接收完消息后并反馈给Leader，Leader收到一半以上的反馈后，返回客户端zxid（每次写操作唯一的事务id），代表写入成功（从这里可以看出zookeeper的写操作不是强一致性，即客户端收到写入成功时并不保证zookeeper所有节点均已成功写入数据），并将消息广播给Observer 奔溃恢复模式：我们可以理解为Leader的选举机制，从字面意思可以看出是当Leader宕机时触发的机制，但其实zookeeper集群初始化选择Leader也是采取这个机制。 具体过程：每个节点发起投票，首先投票给自己，投票内容为（myid，zxid），随后将投票内容广播出去，每个节点收到其他节点的投票内容后，与自己的投票内容作比较，如果zxid大于本地的zxid（如果zxid等于，则比较myid），则更新自己的投票并广播出去，最后当一个节点收到了超过一半的票时，就把自己设为Leader，其他节点设为Follower并根据Leader更新提案(数据)。需要注意，如果上一个Leader宕机时，还有数据没有广播到其他节点，当上一个Leader恢复而其他节点又已经选出了Leader时，上一个Leader的数据就会被抛弃（确保已经被Leader提交的提案最终能够被所有的Follower提交 和 跳过那些已经被丢弃的提案 。） 例子： 假设我们集群中有3台机器，那也就意味着我们需要两台以上同意（超过半数）。比如这个时候我们启动了 server1 ，它会首先 投票给自己 ，投票内容为服务器的 myid 和 ZXID ，因为初始化所以 ZXID 都为0，此时 server1 发出的投票为 (1,0)。但此时 server1 的投票仅为1，所以不能作为 Leader ，此时还在选举阶段所以整个集群处于 Looking 状态。 接着 server2 启动了，它首先也会将投票选给自己(2,0)，并将投票信息广播出去（server1也会，只是它那时没有其他的服务器了），server1 在收到 server2 的投票信息后会将投票信息与自己的作比较。首先它会比较 ZXID ，ZXID 大的优先为 Leader，如果相同则比较 myid，myid 大的优先作为 Leader。所以此时server1 发现 server2 更适合做 Leader，它就会将自己的投票信息更改为(2,0)然后再广播出去，之后server2 收到之后发现和自己的一样无需做更改，并且自己的 投票已经超过半数 ，则 确定 server2 为 Leader，server1 也会将自己服务器设置为 Following 变为 Follower。整个服务器就从 Looking 变为了正常状态。 当 server3 启动发现集群没有处于 Looking 状态时，它会直接以 Follower 的身份加入集群。还是前面三个 server 的例子，如果在整个集群运行的过程中 server2 挂了，那么整个集群会如何重新选举 Leader 呢？其实和初始化选举差不多。 首先毫无疑问的是剩下的两个 Follower 会将自己的状态 从 Following 变为 Looking 状态 ，然后每个 server 会向初始化投票一样首先给自己投票（这不过这里的 zxid 可能不是0了，这里为了方便随便取个数字）。 假设 server1 给自己投票为(1,99)，然后广播给其他 server，server3 首先也会给自己投票(3,95)，然后也广播给其他 server。server1 和 server3 此时会收到彼此的投票信息，和一开始选举一样，他们也会比较自己的投票和收到的投票（zxid 大的优先，如果相同那么就 myid 大的优先）。这个时候 server1 收到了 server3 的投票发现没自己的合适故不变，server3 收到 server1 的投票结果后发现比自己的合适于是更改投票为(1,99)然后广播出去，最后 server1 收到了发现自己的投票已经超过半数就把自己设为 Leader，server3 也随之变为 Follower。","categories":["Zookeeper"]},{"title":"Spring Boot整合GRPC","path":"/2025/01/07/Spring Boot整合GRPC/","content":"说明文档：http://doc.oschina.net/grpc?t=60134 参考文档：https://zhuanlan.zhihu.com/p/377860784 参考文档：https://baijiahao.baidu.com/s?id=1762269686952396195&amp;wfr=spider&amp;for=pc 依赖12345&lt;dependency&gt; &lt;groupId&gt;net.devh&lt;/groupId&gt; &lt;artifactId&gt;grpc-server-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.14.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 12345&lt;dependency&gt; &lt;groupId&gt;net.devh&lt;/groupId&gt; &lt;artifactId&gt;grpc-client-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.14.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 如果服务只作为grpc服务端或者grpc客户端，建议只引入对应的依赖，不要引入grpc-spring-boot-starter 1234567891011121314151617181920212223242526272829303132333435&lt;build&gt; &lt;extensions&gt; &lt;extension&gt; &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt; &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.6.2&lt;/version&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.6.1&lt;/version&gt; &lt;configuration&gt; &lt;protocArtifact&gt;com.google.protobuf:protoc:3.5.1:exe:$&#123;os.detected.classifier&#125;&lt;/protocArtifact&gt; &lt;pluginId&gt;grpc-java&lt;/pluginId&gt; &lt;pluginArtifact&gt;io.grpc:protoc-gen-grpc-java:1.11.0:exe:$&#123;os.detected.classifier&#125;&lt;/pluginArtifact&gt; &lt;!--设置proto文件目录--&gt; &lt;protoSourceRoot&gt;$&#123;project.basedir&#125;/src/main/proto&lt;/protoSourceRoot&gt; &lt;!--设置grpc生成代码到指定路径--&gt; &lt;outputDirectory&gt;$&#123;project.basedir&#125;/src/main/java&lt;/outputDirectory&gt; &lt;!--生成代码前是否清空目录--&gt; &lt;clearOutputDirectory&gt;false&lt;/clearOutputDirectory&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;compile-custom&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; os-maven-plugin和protobuf-maven-plugin都需要 配置12345server.port=8080spring.application.name=grpc-server#如果使用nacos，则加入此配置#spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848grpc.server.port=9090 1234567891011#如果使用nacos或者其他中间件作为注册与发现中心，则不需要此配置grpc.client.grpc-server.address=static://localhost:9090grpc.client.grpc-server.enableKeepAlive=truegrpc.client.grpc-server.keepAliveWithoutCalls=truegrpc.client.grpc-server.negotiationType=plaintextspring.application.name=grpc-client#如果使用nacos，则加入此配置#spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848server.port=8081 编写proto文件12345678910111213141516171819syntax = &quot;proto3&quot;;option java_multiple_files = true;option java_package = &quot;com.example.client.proto&quot;;//生成代码的位置service EventInfoService &#123; rpc sendMessageEvent(EventInfoMessage) returns (EventInfoResponse) &#123;&#125;&#125;message EventInfoMessage &#123; string msg = 1;&#125;message EventInfoResponse &#123; int32 code = 1; string msg = 2; bool success = 3;&#125; proto文件编写还比较简单 service EventInfoService：代表要创建一个名为EventInfoService的类，并且具有sendMessageEvent方法，这个方法需要指定入参和反参，指定的入参和反参都要此文件中或者引入的其他proto文件中定义，这个方法代表了访问服务端的接口，所以proto文件服务端与客户端要一致，生成的代码中会有三个不同的io.grpc.stub.AbstractStub实现类和一个io.grpc.BindableService的实现类，前者是为客户端实现的，客户端调用请求方法在前者中实现的，后者是为了服务端实现的，实现了服务端接收请求的方法，四个实现类都会实现自定义的请求方法 XXXServiceBlockingStub：代表阻塞的实现我们定义的方法（例如上面的sendMessageEvent），即发送消息的方法会阻塞直到客户端接收到服务端的响应，即上面的EventInfoResponse XXXServiceFutureStub：代表等待的实现我们定义的方法，即发送消息后会立即返回一个com.google.common.util.concurrent.ListenableFuture&lt;自定义返回参数&gt;，但是调用ListenableFuture的get方法时会阻塞 XXXServiceStub：代表完全异步的实现我们定义的方法，即发送消息时，需要我们传入一个回调方法并且不会返回参数，回调方法实现io.grpc.stub.StreamObserver&lt;自定义返回参数&gt;即可 XXXServiceImplBase：实现了处理请求的方法 message EventInfoMessage：代表创建一个名为EventInfoMessage的消息类 message EventInfoResponse：代表创建一个名为EventInfoResponse的消息类 通过proto生成代码 执行完就可以在指定目录看到代码了 客户端请求代码12345678910111213141516171819202122232425262728293031323334353637@RestControllerpublic class ClientController &#123; @GrpcClient(&quot;grpc-server&quot;) private EventInfoServiceGrpc.EventInfoServiceBlockingStub eventInfoServiceBlockingStub; @GrpcClient(&quot;grpc-server&quot;) private EventInfoServiceGrpc.EventInfoServiceFutureStub eventInfoServiceFutureStub; @GrpcClient(&quot;grpc-server&quot;) private EventInfoServiceGrpc.EventInfoServiceStub eventInfoServiceStub; @RequestMapping(value = &quot;/query/&#123;str&#125;&quot;) public String queryUser(@PathVariable String str) throws ExecutionException, InterruptedException &#123; EventInfoResponse eventInfoResponse = eventInfoServiceBlockingStub.sendMessageEvent(EventInfoMessage.newBuilder().setMsg(&quot;success&quot;).build()); System.out.println(eventInfoResponse.getMsg()); ListenableFuture&lt;EventInfoResponse&gt; eventInfoResponseListenableFuture = eventInfoServiceFutureStub.sendMessageEvent(EventInfoMessage.newBuilder().setMsg(&quot;success&quot;).build()); System.out.println(eventInfoResponseListenableFuture.get().getMsg()); eventInfoServiceStub.sendMessageEvent(EventInfoMessage.newBuilder().setMsg(&quot;success&quot;).build(), new StreamObserver&lt;EventInfoResponse&gt;() &#123; @Override public void onNext(EventInfoResponse response) &#123; System.out.println(response.getMsg()); &#125; @Override public void onError(Throwable throwable) &#123; new Exception(throwable).printStackTrace(); &#125; @Override public void onCompleted() &#123; System.out.println(&quot;complete&quot;); &#125; &#125;); return &quot;success&quot;; &#125;&#125; 这里展示三个AbstractStub实现类的用法示例，客户端会使到io.grpc.ClientCall类 服务端响应代码123456789101112131415161718192021222324@GrpcServicepublic class EventInfoServiceGrpcImpl extends EventInfoServiceGrpc.EventInfoServiceImplBase &#123; @Override public void sendMessageEvent(EventInfoMessage request, StreamObserver&lt;EventInfoResponse&gt; responseObserver) &#123; EventInfoResponse.Builder eventInfo = EventInfoResponse.newBuilder(); //业务处理 String msg = request.getMsg(); // if (&quot;success&quot;.equals(msg))&#123; eventInfo.setCode(200).setMsg(&quot;success&quot;+100000).setSuccess(true); &#125;else&#123; eventInfo.setCode(500).setMsg(&quot;error&quot;+100000).setSuccess(false); &#125; try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; responseObserver.onNext(eventInfo.build()); responseObserver.onCompleted(); &#125;&#125; 服务端请求响应处理类需要继承BindableService的实现类并实现我们自定义方法名称的方法，服务端使用了ServerCall","categories":["GRPC"]},{"title":"Java生成SSL证书","path":"/2025/01/07/Java生成SSL证书/","content":"依赖Java SSL相关功能需要引入bouncycastle相关依赖，它与java.security有很好的集成 12345&lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcpkix-jdk15on&lt;/artifactId&gt; &lt;version&gt;1.70&lt;/version&gt;&lt;/dependency&gt; 代码下面是根据bouncycastle实现的一套代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public static void main(String[] args) throws Exception &#123; // 创建密钥对生成器 KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(&quot;RSA&quot;); // 初始化密钥对生成器 keyPairGenerator.initialize(2048); // 生成密钥对 KeyPair keyPair = keyPairGenerator.generateKeyPair(); // 获取私钥和公钥 PrivateKey privateKey = keyPair.getPrivate(); PublicKey publicKey = keyPair.getPublic(); StringWriter stringWriter = new StringWriter(); JcaPEMWriter pemWriter = new JcaPEMWriter(stringWriter); pemWriter.writeObject(privateKey); pemWriter.close(); FileOutputStream fos = new FileOutputStream(&quot;C:\\\\Users\\\\pengtong\\\\Desktop\\\\cert\\\\certificate.key&quot;); fos.write(stringWriter.toString().getBytes()); fos.close(); // 创建证书构造器 JcaX509v3CertificateBuilder certificateBuilder = new JcaX509v3CertificateBuilder( new X500Principal(&quot;CN=localhost&quot;), BigInteger.valueOf(System.currentTimeMillis()), new Date(), new Date(System.currentTimeMillis() + 365 * 24 * 60 * 60 * 1000), new X500Principal(&quot;CN=localhost&quot;), publicKey ); //添加扩展程序 DERSequence subjectAlternativeNames = new DERSequence(new ASN1Encodable[] &#123; new GeneralName(GeneralName.dNSName, &quot;localhost&quot;), new GeneralName(GeneralName.iPAddress, &quot;127.0.0.1&quot;), &#125;); certificateBuilder.addExtension(Extension.subjectAlternativeName, false, subjectAlternativeNames); X509CertificateHolder certificateHolder = certificateBuilder.build(new JcaContentSignerBuilder(&quot;SHA256WITHRSA&quot;).build(privateKey)); StringWriter stringWriter1 = new StringWriter(); JcaPEMWriter pemWriter1 = new JcaPEMWriter(stringWriter1); pemWriter1.writeObject(certificateHolder); pemWriter1.close(); // 将证书保存为pem/crt文件 FileOutputStream fos1 = new FileOutputStream(&quot;C:\\\\Users\\\\pengtong\\\\Desktop\\\\cert\\\\certificate.crt&quot;); fos1.write(stringWriter1.toString().getBytes()); fos1.close(); System.out.println(&quot;Certificate generated successfully.&quot;);&#125; 对于证书的生成，还可以参考netty的io.netty.handler.ssl.util.SelfSignedCertificate类的构造方法，其中包括bouncycastle和sun.security两套生成证书的方法 代码解释具体参数意思可以参考浏览器中的证书信息，https网站都会有一个证书，无论是有效的还是无效的 JcaX509v3CertificateBuilder：代码中的JcaX509v3CertificateBuilder使用了六个构造函数的方法，分别是 Issuer：颁发者，对应上图的颁发者 SerialNumber：序列号，对应上图的序列号 StartDate：有效期-不早于，对应上图的有效期-不早于 EndDate：有效期-不晚于，对应上图的有效期-不晚于 Subject：主题背景，其包含被授权网站，对应上图的主题背景 SubjectPublicKeyInfo：证书持有者的公共密钥信息，对应上图的证书持有者公共密钥信息 certificateBuilder.addExtension：这是JcaX509v3CertificateBuilder的addExtension方法，它是由参数的，只是在代码中没写，因为注释了，所以没有影响而已，它的作用是配置扩展程序，就是上图的扩展程序 new JcaContentSignerBuilder(“SHA256WITHRSA”).build(privateKey)：这是JcaContentSignerBuilder的构建方法，返回的是一个ContentSigner对象，其中两部分的作用分别是： new JcaContentSignerBuilder(“SHA256WITHRSA”)：ContentSigner的算法是SHA256WITHRSA，为带“有 RSA 加密的 SHA-256”，即上图中的sha-256指纹 build(privateKey)：设置密钥，这里的密钥和上面的SubjectPublicKeyInfo中的公钥必须是密钥对，在上图不会有展示 JcaPEMWriter：因为生成的证书都是二进制格式的，即der格式，nginx无法使用，需要JcaPEMWriter转为文本格式，即pem格式 让浏览器信任自签名 如果直接使用生成等待自签名证书，浏览器会显示以上警告，显示操作系统不信任该证书，一般CA认证中心发布的证书，都是直接得到操作系统信任的，因为我们是自签名证书，所以不会直接得到信任，这时候我们将证书加入到操作系统信任 双击生成的crt文件（pem文件无法直接打开，所以生成crt），点击安装证书，将证书放入到“受信任的根证书颁发机构”，这时候重启浏览器，重新访问 这时候浏览器有报警显示该证书没有指定主题备用名称，这个可能是每个浏览器有限制，我们为证书添加主题备用名称并重新生成 12345DERSequence subjectAlternativeNames = new DERSequence(new ASN1Encodable[] &#123; new GeneralName(GeneralName.dNSName, &quot;localhost&quot;), new GeneralName(GeneralName.iPAddress, &quot;127.0.0.1&quot;),&#125;);certificateBuilder.addExtension(Extension.subjectAlternativeName, false, subjectAlternativeNames); 生成后，按照上述步骤，将证书添加操作系统信任中，重新打开浏览器访问 看到上面灰色的锁，证明证书已经通过浏览器，没有报警 der、cer、pem.der扩展名DER是一种编码方法，本身可以表示任何类型的数据，但通常用来编码证书。证书的结构使用ASN.1（Abstract Syntax Notation One 一种数据描述语言）描述。 BER和DER都是二进制编码方法。 .pem扩展名PEM是一种将二进制数据编码为字符串的方法。它包含header和footer，用来指定数据的开始和结束，header和footer中间是base64数据。如果数据是证书，那么会简单的编码DER证书。crt格式是pem的证书格式，pem扩展名文件无法打开，需要将扩展名替换成crt才会被定义为证书文件。都是PEM代表Privacy Enhanced Mail；PEM格式如下 123-----BEGIN &lt;whatever&gt;----- data -----END &lt;whatever&gt;---- whatever可以是private keys, public keys, X509 certificates，比如 1234-----BEGIN CERTIFICATE-----... base 64 encoding of the DER encoded certificate with line endings and padding with equals signs ...-----END CERTIFICATE----- 代码中生成的pem文件即为上述格式 123-----BEGIN PRIVATE KEY-----base 64 encoding of the private key-----END PRIVATE KEY----- 代码中生成的key文件即为上述格式 PEM文件也可以包含一个完整的证书链，证书链以叶子&#x2F;结尾证书服务开始，紧跟着签名它的证书，通常直到根证书（一般不包含根证书）。所以如果缺失证书，你也会首先check一下第一个证书。。由此可知PEM既可以包含公钥、也可以包含私钥。 .cer扩展名.cer指的是证书certificate，通常是DER编码格式的，但是windows也可以接受PEM格式。","categories":["安全"]},{"title":"Elasticsearch集群","path":"/2025/01/07/Elasticsearch集群/","content":"Elasticsearch集群搭建配置为每个节点添加以下配置，有些配置根据不通的节点做不同的配置 1234567891011121314151617181920#集群名称cluster.name: cluster-es#节点名称node.name: cluster-1 #是不是有资格主节点node.master: true#是否存储数据node.data: true#最大集群节点数node.max_local_storage_nodes: 3 #ip地址network.host: 0.0.0.0#端口http.port: 9201#内部节点之间沟通端口transport.tcp.port: 9701#es7.x 之后新增的配置，节点发现discovery.seed_hosts: [&quot;localhost:9701&quot;,&quot;localhost:9702&quot;,&quot;localhost:9703&quot;]#es7.x 之后新增的配置，初始化一个新的集群时需要此配置来选举mastercluster.initial_master_nodes: [&quot;cluster-1&quot;, &quot;cluster-2&quot;,&quot;cluster-3&quot;] 为集群添加权限配置 生成证书：在elasticsearch目录下执行以下命令在config目录下生成一个证书，执行这个命令时需要设置一个密码，下一步操作中需要用到这个密码 1bin\\elasticsearch-certutil ca -out config\\elastic-certificates.p12 将创建证书是设置的密码加入到Elasticsearch keystore中：在elasticsearch\\bin目录下分别执行下面两条语句，密码输入刚才设置的密码 12elasticsearch-keystore add xpack.security.transport.ssl.keystore.secure_passwordelasticsearch-keystore add xpack.security.transport.ssl.truststore.secure_password 将config目录下证书以及密码两个文件拷贝到其他节点的config目录下 在所有节点中加入以下配置 12345678http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;http.cors.allow-headers: Authorizationxpack.security.enabled: truexpack.security.transport.ssl.enabled: truexpack.security.transport.ssl.verification_mode: certificatexpack.security.transport.ssl.keystore.path: elastic-certificates.p12xpack.security.transport.ssl.truststore.path: elastic-certificates.p12 启动所有节点，设置密码，在ealsticsearch\\bin目录下执行以下文件，这个命令中需要给四个用户设置密码，建议设成一样的 1elasticsearch-setup-passwords interactive 下面这个索引千万不能删（别名也不能删），是用来管理密码的 ES集群需要启动半数才有效，不启动半数节点，输入账号密码也无法使用 ElasticSearch选主算法7.x以前采用bully7.x之后采用raftraft算法参考文章 termterm是raft全局维护的任期，一个任期只会有一个Leader，全局维护代表正常运行的情况下所有节点的term应该是一致的 角色，raft定义了三类角色 Leader：主节点，负责消息写入 Follower：负责消息读负载，写请求会重定向到Leader，接受Leader日志同步 Candidate：Follower于Leader的中间角色 选主过程 每个节点有一个election timeout（表示未接受到Leader心跳的时间，150ms~300ms的一个随机数，避免多个节点同时发起选举），当一个节点超过election timeout没有收到Leader的心跳时就会将自己转为Candidate（集群初始化也是如此），将term加1，并向自己投一票，然后向其他人发出RequestVote RPC（让大家投他），有一个原则，统一任期的选举阶段，每个节点只有一票，遵从先到先得原则 如果该节点收到半数的投票，将自己转为Leader，并发送心跳，其他Follower收到心跳后，重置election timeout，达到阻止Follower发起选举的效果。如果因为其他节点term比自己大而遭到了拒绝，就会转为Follower，并重置election timeout。这里需要强调一下，在任何时候，不管是Leader或者Candidate，只要收到term比自己大的消息，就会转为Follower。 raft选举过程可以保证选举出来的Leader的日志比大部分节点新，而且加上raft的日志同步机制，可以保证Leader的日志比全部已提交的日志更新或者一样（包括前一个Leader），因为日志的提交需要满足日志已经被复制到超过半数节点，所以如果一个节点被过半数的节点选举，证明它的日志一定等于或者新于已提交的日志。 日志同步Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC 复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。某些Followers可能没有成功的复制日志，Leader会无限的重试 AppendEntries RPC直到所有的Followers最终存储了所有的日志条目。这里可以看出raft写操作并不是强一致性。日志由有序编号（log index）的日志条目组成。每个日志条目包含它被创建时的任期号（term），和用于状态机执行的命令。如果一个日志条目被复制到大多数服务器上，就被认为可以提交（commit）了。 Raft日志同步保证如下两点 如果不同日志中的两个条目有着相同的索引和任期号，则它们所存储的命令是相同的。 如果不同日志中的两个条目有着相同的索引和任期号，则它们之前的所有条目都是完全一样的。 第一条是因为每个任期内，Leader在指定的index long处，最多创建一个日志条目，并且该条目的位置不会变。 第二条是因为 AppendEntries 的一个简单的一致性检查。leader通过发送日志复制RPC的一致性检查找到follower与自己相同日志项的最大索引值，然后，leader强制复制follower更新覆盖的不一致日志项。 leader给follower发送日志复制信息中带着(PrevLogTerm， PrevLogEntry)。PrevLogEntry表示当前复制日志项前一条的索引值。PrevLogTerm表示当前要复制的日志项前面一条的任期编号。 比如，下图中leader将索引值为8的日志项发送给follower，那么PrevLogTerm值为4，PrevLogEntry为7。 leader通过日志复制RPC消息发送当前日志项到follower。比如上图PrevLogEntry值为7，PrevLogTerm值为4。 如果follower在它的日志中，找不到与PrevLogEntry为7，PrecvLogTerm值为4的日志项表示它和leader的日志文件不一致了，那么follower拒绝接受新的日志项，并返回失败信息给leader。 leader递减要复制的日志项的索引值，并发送日志项到follower，既值为（6,3）的日志项。 如果follower在它的日志中找到了PrevLogEntry值为6，PrevLogTerm值为3的日志项，日志复制RPC返回成功，这样leader就知道在PrevLogEntry值为6，PrevLogTerm值为3的位置，follower和leader的日志项相同。 leader发送日志复制RPC消息给follower，follower复制并覆盖该索引之后的日志项，最终实现了集群各节点日志的一致。 安全性 Raft增加了如下两条限制以保证安全性： 拥有最新的已提交的log entry的Follower才有资格成为Leader。这个保证是在RequestVote RPC中做的，Candidate在发送RequestVote RPC时，要带上自己的最后一条日志的term和log index，其他节点收到消息时，如果发现自己的日志比请求中携带的更新，则拒绝投票。日志比较的原则是，如果本地的最后一条log entry的term更大，则term大的更新，如果term一样大，则log index更大的更新。 Leader只能推进commit index来提交当前term的已经复制到大多数服务器上的日志，旧term日志的提交要等到提交当前term的日志来间接提交（log index 小于 commit index的日志被间接提交）。这个较为复杂，可查看参考文章第四节 ElasticSearch7.X之后集群算法选举过程 节点的初始化状态为Candidate; 启动选举任务，向探测到的集群中其他节点发送PRE_VOTE投票请求，请求中会携带节点的Term信息; 其他节点收到PRE_VOTE投票请求后，对请求进行处理：（1）更新自己收到过的最大的Term 如果请求中的Term比自己的Term大并且当前节点是Leader节点，意味着当前的Leader可能已经过期，其他节点已经开始竞选Leader，所以此时当前节点需要放弃Leader的身份，重新发起选举。 （2）根据当前节点记录的Leader信息决定是否投票给发起者，然后向发起者返回投票响应信息： - 如果当前节点记录的集群Leader为空，同意投票给发起者。 - 如果当前节点记录的集群Leader不为空，但是与本次发起的节点一致，同样同意投票。 - 如果当前节点记录的集群Leader为空，但是与本次发起的节点不同，拒绝投票给发起者。 发起者收到其他节点对PRE_VOTE投票请求的响应，判断是否得到了大多数投票，如果是进入下一步； 发起者向集群中的节点发送StartJoin请求，邀请节点加入集群，发送StartJoin请求的时候会将Term增加1，但是发起者的Term暂不更新，这与Raft协议在发起选举的时候就对Term增加的操作不一样； 其他节点收到StartJoin请求，更新自己的Term信息，处理完毕后向发起者发送JOIN请求，JOIN请求中携带了节点的Term信息； 收到StartJoin请求时，只要请求中的Term比当前节点的Term大，当前节点都会同意为发起者进行投票，这里也与Raft协议规定的每个任期内只能为一个节点进行投票不一致。 既然节点可以多次进行投票，那么就有可能产生多个Leader，对于这种情况，Elasticsearch会选择最后那个选举成功的节点成为Leader。 发起者收到其他节点发送的JOIN请求后，会统计收到的JOIN请求个数，如果达到了大多数投票，即可成为Leader； 发起者收到JOIN请求时也会校验自己的Term是否比JOIN请求中的Term大，在第5步中发起者并未更新自己的Term，所以首次收到JOIN请求后，Term信息会小于JOIN请求中的Term，这里发起者会模拟一个JOIN请求给自己，也就是自己为自己投一票。 发起者成为Leader；文章来源站点 日志同步 ElasticSearch的数据并不是基于节点间的主副本，而是基于分片间的主副本，&lt;font style=&quot;color:rgb(61, 70, 77);&quot;&gt;默认情况下当大多数副本都同步完成时，就返回存储完成的通知。这个可以通过 consistency 参数配置，all 表示必须所有的 副本都同步完成才返回存储完成的通知，one 表示只要主分片同步完成就返回存储完成的通知（检索结果可能会被还未同步的副本处理，造成未检索到），默认值是 quornum&lt;/font&gt;。 ES写入失败可以分为主分片写入失败和副本分片写入失败： 主分片写入失败：主分片写入失败时，即判定这次写入请求整体失败，并且一个副本分片将成为主分片 副本分片写入失败：主分片在将数据同步给副本分片时，如果失败了，仍然会返回写入成功，但是将同步失败的副本分片置为不可读，以保证数据的一致性，等该副本分片同步完成后，重新置为可读","categories":["ElasticSearch"]},{"title":"Nginx代理WebSocket","path":"/2025/01/07/Nginx代理WebSocket/","content":"Nginx代理从WebSocket的通信过程得知，WebSocket通信的第一步是发送一个Http请求，这个请求可以通过Nginx的Http模块代理，但是后面具体的信息交换则是通过WebSocket协议，Nginx的Http模块是否可以继续代理呢 上图的几个步骤分别是 浏览器提交受个http请求到nginx nginx将http请求转发给服务端 服务端返回101响应给nginx nginx将服务端的响应返回给浏览器 浏览器发送websocket消息给nginx nginx将websocket消息转发给服务端 通过上面5、6个步骤可知，nginx确实代理了websocket协议，这是因为nginx通过首次http代理后，就会将两个tcp连接绑定起来，后续websocket协议就可以通过这两个绑定的tcp连接进行通信，这里有个注意的地方，nginx在代理http时，如果没有配置与服务端的长连接，nginx在收到服务端的消息后，会关闭与服务端的tcp连接，但是101状态是个例外，如果nginx收到的服务端的http消息的状态是101，则不会关闭和服务端的tcp连接，但是会受到超时配置的影响，比如proxy_read_timeout。另外一点，如果响应状态为101，虽然nginx不会转发Upgrade请求头，但是客户端请求头必须包括Upgrade，否则nginx收到101响应后不会认为是一个完成的请求，就不会把响应返回给客户端 Nginx配置nginx在http模块代理websocket协议和代理普通的http请求有一些不同 123456789101112location /connectWebSocket &#123; fastcgi_hide_header Access-Control-Allow-Origin; proxy_hide_header Access-Control-Allow-Origin; add_header Access-Control-Allow-Origin *; proxy_http_version 1.1; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_send_timeout 1; proxy_read_timeout 1000; proxy_connect_timeout 1;&#125; 主要的不同是以下几点 proxy_set_header Upgrade $http_upgrade：这个配置是因为nginx不会转发Upgrade请求头 proxy_set_header Connection “upgrade”：这个配置是因为nginx不会转发Connection: Upgrade请求头，如果不配置这个的话，就是变成Connection: close proxy_read_timeout 1000：这个配置在普通http的情况下，代表服务端的响应时间，而在代理websocket的情况下，由于tcp连接不是一次性的了，所以这个配置可以理解为最大空闲时间，这个配置是因为如果不配置大一点的话，nginx与服务端的tcp连接会太容易断开","categories":["Nginx"]},{"title":"TCP相关知识","path":"/2025/01/07/TCP相关知识/","content":"tcp四次挥手 主动关闭方状态变化： ESTABLISHED（连接建立） -&gt; 发送FIN报文（第一次挥手） -&gt; FIN_WAIT_1 -&gt; 收到对方的ACK确认 -&gt; FIN_WAIT_2 -&gt; 收到对方的FIN报文 -&gt; 发送ACK确认（第四次挥手）-&gt; TIME_WAIT -&gt; CLOSED 被动关闭方状态变化： ESTABLISHED（连接建立） -&gt; 收到对方的FIN报文 -&gt; 发送ACK确认（第二次挥手）-&gt; CLOSE_WAIT -&gt; 发送FIN报文（第三次挥手） -&gt; LAST_ACK -&gt; 收到对方的ACK确认 -&gt; CLOSED 第一次挥手 (FIN, Finish)： 客户端发送一个 FIN 报文段给服务器，设置 FIN 位为 1，序列号 seq &#x3D; u。客户端进入 FIN_WAIT_1 状态。这表示客户端没有数据要发送了，但仍然可以接收来自服务器的数据。 第二次挥手 (ACK, Acknowledgement)： 服务器收到 FIN 报文后，发送一个 ACK 报文段给客户端，确认序号 ack &#x3D; u + 1，序列号 seq &#x3D; v。服务器进入 CLOSE_WAIT 状态。此时服务器已知晓客户端不再发送数据，但它可能还有数据需要发送给客户端。 第三次挥手 (FIN)： 当服务器完成所有数据的发送或者确定不再发送数据后，它也发送一个 FIN 报文段给客户端，设置 FIN 位为 1，序列号 seq &#x3D; w。服务器进入 LAST_ACK 状态。这意味着服务器也完成了数据传输，并准备好关闭连接。 第四次挥手 (ACK)： 客户端收到服务器的 FIN 报文后，返回一个 ACK 报文段给服务器，确认序号 ack &#x3D; w + 1，序列号 seq &#x3D; u + 1。客户端进入 TIME_WAIT 状态，等待一段时间以确保服务器收到了最后一个 ACK 报文。在服务器收到这个 ACK 后，进入 CLOSED 状态，关闭连接。客户端在等待一段时间（通常称为 TIME_WAIT 状态持续时间，用于确保网络中的任何重传报文都被处理完）后也会进入 CLOSED 状态，彻底关闭连接。","categories":["知识累积"]},{"title":"ElasticSearch笔记","path":"/2025/01/07/ElasticSearch笔记/","content":"ElasticSearch下载下载地址：ElasticSearch官网下载地址 Elasticsearch对jdk有版本要求：Elasticsearch官网版本要求 Windows下的Elasticsearch下载完压缩包，直接解压即可，通过安装目录下的bin\\elasticsearch.bat启动 ElasticSearch端口介绍 9200端口：9200作为Http协议，主要用于外部通讯，http接口用的就是这个端口。一般都是给ElasticSearch-Head等工具连接ElasticSearch使用的。 9300端口：9300作为Tcp协议，jar之间就是通过tcp协议通讯。ES集群之间是通过9300进行通讯。 ElasticSearch分词器中文分词器Elasticsearch中文分词我们采用Ik分词 安装 下载压缩包 在github上下载对应版本的分词器 将下载的ik分词器的压缩包复制到es安装目录下的plugin目录下并解压即可 直接通过命令安装 进入github上找到对应版本的分词器的地址 在es安装目录bin目录下执行一下命令：elasticsearch-plugin.bat install &lt;对应版本ik分词器地址&gt; 测试ik分词器有两种分词模式，ik_max_word,和ik_smart模式 ik_max_word：会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌”，会穷尽各种可能的组合 ik_smart: 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”，既不会重复。只会不断往后分词 其他分词器 Standard Analyzer - 默认分词器，按词切分，小写处理 Simple Analyzer – 按照非字母切分（符号被过滤），小写处理 Stop Analyzer – 小写处理，停用词过滤（the，a，is） Whitespace Analyzer – 按照空格切分，不转小写 Keyword Analyzer – 不分词，直接将输入当作输出 Patter Analyzer – 正则表达式，默认 \\W+ (非字符分隔) Language – 提供了30多种常见语言的分词器 参考地址 ES多字段查询multi_match的几种type BEST_FIELDS：将查询拆分为多个字段，并使用每一个字段中最匹配的文本作为匹配分值。应该适用于多个字段匹配文本的场景，例如全文搜索、文章标题&#x2F;正文搜索。如果有一个字段完全匹配但其他字段不匹配，则该字段的分值将超过其他字段。示例：假设有3个字段（title、description、tags），对于查询“apple”，如果title完全匹配，则它将获得最高分数，如果其他字段也有匹配，这个分数将被累加。 MOST_FIELDS：将查询拆分为多个字段，并将所有匹配的字段将其分值相加。适用于多个字段中所有匹配项都是同等重要的场景，例如产品名称、描述搜索。示例：同样是3个字段（title、description、tags），对于查询“apple”，如果3个字段都有匹配，则它们的分值将被累加，没有完全匹配的字段并不会获得更高的分值。 CROSS_FIELDS：将查询视为单个字段，并将所有匹配项的权重相加得到文档分值。适用于多个字段中匹配的文本都有相同的重要性（权重），例如对于人名、电子邮件地址搜索。示例：对于3个字段（title、description、tags），如果它们包含子字符串”apple”，这些子字符串的匹配将被累加以获得文档的总分。 PHRASE：搜索字段中包含精确短语匹配的文档。适合于必须以一组特定单词顺序搜索的场景，例如完整的诗歌、歌词等。示例：查询“apple pie”，只有包含按照这个顺序全匹配的字段才会获得高分。这里需要才提到一点，严格来讲，这里参考的是分词顺序，例如，如果查询参数使用的是自定义分词器，“阀门”被分为了三个词，而es文档使用的是默认分词器，那么“阀门”在es文档中就会被分为两个词，所以在这种情况，也是无法匹配的，因为当匹配到“阀”字时，会尝试匹配“阀门”，而es文档中“阀”后面是“门”，所以无法匹配。 PHRASE_PREFIX：搜索以查询开头的短语匹配的文档。适用于需要根据用户输入搜索不完整的短语的场景，例如输入“re”然后给出匹配的所有词。示例：查询“a”将匹配“apple”、“apricot”等。 BOOLEAN：搜索所有匹配的文档，查询可以使用通配符、布尔逻辑等高级语法。适用于需要高级查询操作的场景，例如过滤器。示例：使用布尔运算符“AND”、“OR”、“NOT”等，可以组合具有不同匹配条件的查询来精细化搜索。","categories":["ElasticSearch"]},{"title":"ElasticSearch基础","path":"/2025/01/07/ElasticSearch基础/","content":"基本的APIapi官方文档 测试分词器apimethod：posturl：http://localhost:9200/_analyzebody： 1234&#123;\t&quot;text&quot;: &quot;中华五千年华夏&quot;,\t&quot;analyzer&quot;: &quot;ik_smart&quot;&#125; 新建索引apimethod：puturl：http://localhost:9200/studentbody： 123456789101112131415161718192021222324252627282930313233343536&#123;\t&quot;settings&quot;: &#123; &quot;index&quot;: &#123; &quot;number_of_shards&quot;: 3, &quot;number_of_replicas&quot;: 3 &#125;\t&#125;,\t&quot;mappings&quot;: &#123; &quot;dynamic&quot;: false, &quot;properties&quot;: &#123; &quot;productid&quot;: &#123; &quot;type&quot;: &quot;long&quot; &#125;, &quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: true, &quot;analyzer&quot;: &quot;ik_max_word&quot; &#125;, &quot;age&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: true, &quot;analyzer&quot;: &quot;ik_max_word&quot; &#125;, &quot;sex&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: true, &quot;analyzer&quot;: &quot;ik_max_word&quot; &#125;, &quot;desc&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: true, &quot;analyzer&quot;: &quot;ik_max_word&quot; &#125; &#125;\t&#125;&#125; url中的student即为索引名，新建其他索引更换即可，并且此api可以根据put、delete，get达到新增、删除和查看的效果 查看全部索引method：geturl：http://localhost:9200/_cat&#x2F;indices 为索引添加mappingmethod：puturl：http://localhost:9200/studentbody： 12345678&#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot; &#125; &#125;&#125; url中的student即为索引名，为其他索引创建mapping更换即可，此api可以根据put、get达到新增、和查看的效果 添加数据method：posturl：http://localhost:9200/student/_doc&#x2F;1?op_type&#x3D;createbody： 1234567&#123;\t&quot;productid&quot;: 2,\t&quot;name&quot;: &quot;张三&quot;,\t&quot;age&quot;: &quot;12&quot;,\t&quot;sex&quot;: &quot;女&quot;,\t&quot;desc&quot;: &quot;喜欢打篮球、听音乐，不喜欢下棋，语文成绩好，数学成绩差&quot;&#125; url中的student为索引名，_doc为默认类型，elasticsearch7已经移除索引类型（type）概念，不再支持指定索引类型，默认索引类型是_doc，1是id，也可以不写，如果请求方式为put，则必须写，op_type&#x3D;create的作用是当url中的id已存在的时候，会报错，如果不写op_type&#x3D;create，而id又已经存在，则会更新 条件查询（四种查询模式：精确词查询、匹配查询、多条件查询、复合查询、聚合查询，分别对应 “term”、”match”、”multi_match”、”bool”、”aggs”）method：geturl：http://localhost:9200/student/_search 匹配查询body： 1234567&#123;\t&quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;desc&quot;: &quot;数学&quot; &#125;\t&#125;&#125; 2. 多条件查询 body： 1&#123;&quot;query&quot;:&#123;&quot;multi_match&quot;:&#123;&quot;query&quot;:&quot;篮球&quot;,&quot;fields&quot;:[&quot;desc&quot;,&quot;name&quot;]&#125;&#125;&#125; query为查询条件，fields为查询字段，多条件查询命中一条就可以查出来，类似于or 3. 复合查询 body： 1234567891011121314151617181920&#123;\t&quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;desc&quot;: &quot;篮球&quot; &#125; &#125; ], &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;name&quot;: &quot;四&quot; &#125; &#125; ] &#125;\t&#125;&#125; bool把各种其它查询通过 must（与）、must_not（非，不计算分数）、should（或）、filter （与、但不会计算分数）的方式进行组合，像这个例子中，只会匹配desc中有篮球并且有音乐的记录，但是如果should中的条件满足一条的话，会提高_source，也可以说提高分数，如果两条都满足，分数可以提高更多。must、should满足条件都会提高分数。与must同时存在时，should的作用就是将感兴趣的信息放在前面。特别注意，json格式不能同时存在两个match，只有最后一个会生效，故相同的查询方式只能放在数组中 4. 聚合查询 body: 1234567891011121314151617&#123;\t&quot;size&quot;: 0,\t&quot;aggs&quot;: &#123; &quot;sex_aggs&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;productid&quot; &#125;, &quot;aggs&quot;: &#123; &quot;sum_age&quot;: &#123; &quot;sum&quot;: &#123; &quot;field&quot;: &quot;age&quot; &#125; &#125; &#125; &#125;\t&#125;&#125; 这里根据procutid分组并且对age求和 桶的分组方式Date Histogram Aggregation：根据日期阶梯分组，例如给定阶梯为周，会自动每周分为一组Histogram Aggregation：根据数值阶梯分组，与日期类似Terms Aggregation：根据词条内容分组，词条内容完全匹配的为一组Range Aggregation：数值和日期的范围分组，指定开始和结束，然后按段分组 度量度量类似mysql的avg,max等函数，用来求分组内平均值，最大值等。 比较常用的一些度量聚合方式： Avg Aggregation：求平均值Max Aggregation：求最大值Min Aggregation：求最小值Percentiles Aggregation：求百分比Stats Aggregation：同时返回avg、max、min、sum、count等Sum Aggregation：求和Top hits Aggregation：求前几Value Count Aggregation：求总数 列的类型参考文章 核心数据类型： string字符串： text：文本类型（分词）； keyword：关键字类型（不分词）； numeric-数值类型： long, integer, short, byte, double, float, half_float, scaled_float date-日期类型（存储自unix纪元以来的毫秒数）； date_nanos：日期纳秒类型（存储自unix纪元以来的纳秒数）； boolean-布尔类型； binary-二进制类型； range-范围类型: integer_range, float_range, long_range, double_range, date_range 复杂数据类型 object：对象类型；存储单个json对象； nested：嵌套类型；存储json对象数组； 数组类型（字段数组类型） 数组不需要专用的数据类型。一个字段默认可以包含0个或多个值。然而，数组中的所有值必须是同一种类型； 多字段类型： 根据不同目的以不同方式索引同一字段是有帮助的；举例，字符串字段可以被映射为 text字段以便全文搜索，也可以映射为keword以便于排序或聚合。 其他数据类型 如地理位置信息数据类型，ip数据类型等（没有罗列完全） ElasticSearch数据结构 在了解写入流程前先来看下ES的结构是什么样子。这是网上介绍ES的一张图片，从中可以看出一个ES集群中有多个Server节点，每个Server节点中含有多个Index。 一个Index含有多个分片(shard)，其中有一个 primary 主分片，负责写入，其他副本为 replica，不能写，只能同步 primary 的数据，但可以处理读请求。 ES 收到写请求后，会将请求路由到index的主分片上。 ES的底层是Lucene引擎，ES的每一个分片对应到底层实际上就是一个 Lucene Index，包含多个 segment 文件，和一个 commit point 文件。segment 文件存储的就是一个个的 Document，commit point 相当于一个索引文件，记录了都有哪些 segment 文件。 ElasticSearch读取流程读阶段(query) 当客户端发出一个请求到服务端，收到请求的节点会成为协调节点，将请求发送到所有的分片上，分片收到请求，会在本地生成一个优先级队列，这个优先级队列的大小是from+size，故深度分页搜索不能用from+size，因为深度越大，这个优先级队列越大，性能就越低。举一个网上的列子：&lt;font style=&quot;color:rgb(77, 77, 77);&quot;&gt;假如有1万条数据记录了各种水果在全国各省市的销量，其中草莓的销量数据如下（三个颜色代表三个分片）：&lt;/font&gt; 现在如果根据销量排序分页查询，假设from&#x3D;2，size&#x3D;2，那么每个分片将前四条数据放入优先级队列并返回给协调节点（只包括id和排序的字段）。我们假设一下如果不返回前条而是返回第三条和第四条数据的话，会怎么样，我们可以看出，我们最终想要的结果是深蓝色区域销量为50000和浅蓝色销量为36000的数据，如果每个分片只返回第三条和第四条数据的话，那么浅蓝色区域销量为36000的数据就无法被查出，数据的准备性就无法得到保证。协调节点收到所有分片的数据后，合并到一个全局的有序队列 取阶段(fetch) 协调节点收到所有分片的数据后合并到一个有序队列，合并排序完后，查出自己需要的数据，然后根据id像分片查询完整文档。 一般情况，都是query then fetch，即先读后取，但也可以query and fetch，即在query的时候直接返回完整文档，而不是只返回id和排序字段，这种方式查询速度很快，因为少了fetch的第二次查询，少了一次网络传输，但是如果查询数据量特别大的话，query and fetch的方式可能并不可取，因为在query阶段返回的数据可能是好几倍 ElasticSearch写入流程 从上图可以看出客户端写入请求进入ES后，首先会写入内存Buffer中，同时写入Translog日志，内存Buffer读写速度快，但因为不能持久化，所以并不安全，容易出现数据丢失，所以同时写入Tranlog日志，Tranlog日志只是做日志追加，所以写入快，并且稳定，如果系统出现宕机，重启后可以通过Tranlog日志恢复。 ES每隔一秒就会执行一次refresh，创建一个Segment，并将Buffer内存写入Segment，ES 有一个后台程序，用于 merge 合并这些 segment 文件，把小 segment 整合到一个大的 segment 中，并修改 commit point 的 segment 记录。merge 过程还会清理被删除的数据。es 接收到删数据请求时，不会真的到 segment 中把数据删了，而是把要删除的数据写到 ‘.del’ 文件中，在读操作时，会根据这个文件进行过滤。merge 合并时才真正删除，合并后的 segment 中就没有已经删除的数据了。 进入 segment 的数据就进入了 Lucene，建立好了倒排索引，可以被搜索到，所以写入的数据最多只有一秒无法被搜索到。 当数据写入Segment时，数据并没有真正落盘，因为系统本身还有一层缓存，这是系统自带的优化方法，&lt;font style=&quot;color:rgb(77, 77, 77);&quot;&gt;ES每隔5秒会异步执行一次fsync操作，将系统缓存强制写到真实的硬盘上&lt;/font&gt;。 当Translog日志大小达到阈值或者时间超过30分钟，就会触发flush操作。 1、执行 refresh 操作。 2、把这次提交动作之前所有没有落盘的 segment 强制fsync，确保写入物理文件。 3、创建一个提交点，记录这次提交对应的所有 segment，写入 commit point 文件。 4、清空 Translog，因为 Segment 都已经踏实落地了，之前的 Translog 就不需要了。 ElasticSearch设置密码参考文章 打开bin目录下的elasticsearch-setup-passwords.bat interactive 发现需要配置xpack，配置config目录下的elasticsearch.yml 12345http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;http.cors.allow-headers: Authorizationxpack.security.enabled: truexpack.security.transport.ssl.enabled: true 重启完elasticsearch，重复第一步并输入密码（账号是默认的） 访问api时要加入账号密码，否则报错","categories":["ElasticSearch"]},{"title":"Ribbon、LoadBalancer负载均衡","path":"/2025/01/07/Ribbon、LoadBalancer负载均衡/","content":"前言RestTemplate是spring的http客户端，底层使用HttpURLConnection，不过也支持使用apache httpclient、okhttp、netty等方式 loadbalancer和ribbon介绍 loadbalancer： spring cloud commons下面有个loadbalance包，是spring cloud提供的负载均衡通用包，这个通用基础包，定义了许多spring cloud的负载均衡接口，客户端只需要实现这些接口，就可以整合到spring cloud中，符合面向对象七大设计原则 spring cloud loadbalancer是spring cloud实现这个上面通用包而产生的负载均衡包，所以这里需要区别一下，有一个loadbalance是spring cloud commons通用包，定义了一系列通用接口，有一个loadbalance是spring cloud专门实现的负载均衡包。并且loadbalance支持spring后面提出的WebClient，ribbon太早不再维护而不支持WebClient ribbon：ribbon是Netflix实现spring cloud commons下面loadbalancer包的负载均衡组件，和spring cloud loadbalancer属于同一类的产品，只不过ribbon后面不再维护，在spring cloud后续版本中，只支持spring cloud loadbalancer RestTemplate整合Ribbon依赖123456&lt;!--spring-cloud-starter-netflix-ribbon已停止维护，最新版本为2.2.10.RELEASE（2021年11月），并且在spring cloud 2020.0.0之后不再引入（包括2020.0.0），故需要单独定义版本--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;version&gt;2.2.10.RELEASE&lt;/version&gt;&lt;/dependency&gt; 这里需要注意，如果项目引入的是spring-cloud-dependencies：2020.0.0及以后的版本，将需要单独定义ribbon版本，并且可能因为不适配而存在一些问题，所以并不推荐使用，推荐使用spring cloud官方提供的spring-cloud-starter-loadbalancer，这里只做演示 代码如果需要在RestTemplate请求过程中加入ribbon负载均衡，只需要在注册RestTemplate的时候加上@LoadBalanced即可 1234567891011121314151617/** * springboot注入RestTemplate * @return */@Bean@LoadBalancedpublic RestTemplate restTemplate()&#123; //配置使用apache httpclient作为RestTemplate的Http客户端 RestTemplate restTemplate = new RestTemplate(new HttpComponentsClientHttpRequestFactory()); //设置自定义拦截器 restTemplate.setInterceptors( Collections.singletonList( new RestTemplateInterceptor() ) ); return restTemplate;&#125; 如何生效@LoadBalanced生效的方法是通过为RestTemplate添加一个拦截器，拦截器会将RestTemplate提交的请求中的服务名通过负载均衡替换为实际的地址，例如http://user:6060/会被替换成http://192.168.0.1:6060/，这个拦截器是org.springframework.cloud.client.loadbalancer.RetryLoadBalancerInterceptor，RetryLoadBalancerInterceptor实现了ClientHttpRequestInterceptor，但是ClientHttpRequestInterceptor不只有这一个实现类，只是这一个实现类整合了spring重试的机制 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public ClientHttpResponse intercept(final HttpRequest request, final byte[] body, final ClientHttpRequestExecution execution) throws IOException &#123; URI originalUri = request.getURI(); String serviceName = originalUri.getHost(); Assert.state(serviceName != null, &quot;Request URI does not contain a valid hostname: &quot; + originalUri); LoadBalancedRetryPolicy retryPolicy = this.lbRetryFactory.createRetryPolicy(serviceName, this.loadBalancer); RetryTemplate template = this.createRetryTemplate(serviceName, request, retryPolicy); return (ClientHttpResponse)template.execute((context) -&gt; &#123; ServiceInstance serviceInstance = null; if (context instanceof LoadBalancedRetryContext) &#123; LoadBalancedRetryContext lbContextxx = (LoadBalancedRetryContext)context; serviceInstance = lbContextxx.getServiceInstance(); if (LOG.isDebugEnabled()) &#123; LOG.debug(String.format(&quot;Retrieved service instance from LoadBalancedRetryContext: %s&quot;, serviceInstance)); &#125; &#125; Set&lt;LoadBalancerLifecycle&gt; supportedLifecycleProcessors = LoadBalancerLifecycleValidator.getSupportedLifecycleProcessors(this.loadBalancerFactory.getInstances(serviceName, LoadBalancerLifecycle.class), RetryableRequestContext.class, ResponseData.class, ServiceInstance.class); String hint = this.getHint(serviceName); if (serviceInstance == null) &#123; if (LOG.isDebugEnabled()) &#123; LOG.debug(&quot;Service instance retrieved from LoadBalancedRetryContext: was null. Reattempting service instance selection&quot;); &#125; ServiceInstance previousServiceInstance = null; if (context instanceof LoadBalancedRetryContext) &#123; LoadBalancedRetryContext lbContext = (LoadBalancedRetryContext)context; previousServiceInstance = lbContext.getPreviousServiceInstance(); &#125; DefaultRequest&lt;RetryableRequestContext&gt; lbRequestx = new DefaultRequest(new RetryableRequestContext(previousServiceInstance, new RequestData(request), hint)); supportedLifecycleProcessors.forEach((lifecycle) -&gt; &#123; lifecycle.onStart(lbRequestx); &#125;); serviceInstance = this.loadBalancer.choose(serviceName, lbRequestx); if (LOG.isDebugEnabled()) &#123; LOG.debug(String.format(&quot;Selected service instance: %s&quot;, serviceInstance)); &#125; if (context instanceof LoadBalancedRetryContext) &#123; LoadBalancedRetryContext lbContextx = (LoadBalancedRetryContext)context; lbContextx.setServiceInstance(serviceInstance); &#125; Response&lt;ServiceInstance&gt; lbResponse = new DefaultResponse(serviceInstance); if (serviceInstance == null) &#123; supportedLifecycleProcessors.forEach((lifecycle) -&gt; &#123; lifecycle.onComplete(new CompletionContext(Status.DISCARD, new DefaultRequest(new RetryableRequestContext((ServiceInstance)null, new RequestData(request), hint)), lbResponse)); &#125;); &#125; &#125; LoadBalancerRequestAdapter&lt;ClientHttpResponse, RetryableRequestContext&gt; lbRequest = new LoadBalancerRequestAdapter(this.requestFactory.createRequest(request, body, execution), new RetryableRequestContext((ServiceInstance)null, new RequestData(request), hint)); ClientHttpResponse response = (ClientHttpResponse)this.loadBalancer.execute(serviceName, serviceInstance, lbRequest); int statusCode = response.getRawStatusCode(); if (retryPolicy != null &amp;&amp; retryPolicy.retryableStatusCode(statusCode)) &#123; if (LOG.isDebugEnabled()) &#123; LOG.debug(String.format(&quot;Retrying on status code: %d&quot;, statusCode)); &#125; byte[] bodyCopy = StreamUtils.copyToByteArray(response.getBody()); response.close(); throw new ClientHttpResponseStatusCodeException(serviceName, response, bodyCopy); &#125; else &#123; return response; &#125; &#125;, new LoadBalancedRecoveryCallback&lt;ClientHttpResponse, ClientHttpResponse&gt;() &#123; protected ClientHttpResponse createResponse(ClientHttpResponse response, URI uri) &#123; return response; &#125; &#125;);&#125; RetryLoadBalancerInterceptor的loadBalancer对象就是负载均衡客户端，LoadBalancerClient属于spring cloud基础包的内容 123456789public interface LoadBalancerClient extends ServiceInstanceChooser &#123; &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request) throws IOException; &lt;T&gt; T execute(String serviceId, ServiceInstance serviceInstance, LoadBalancerRequest&lt;T&gt; request) throws IOException; URI reconstructURI(ServiceInstance instance, URI original);&#125;public interface ServiceInstanceChooser &#123; ServiceInstance choose(String serviceId); &lt;T&gt; ServiceInstance choose(String serviceId, Request&lt;T&gt; request);&#125; ribbon和loadbanlancer分别实现了这个接口，serviceInstance &#x3D; this.loadBalancer.choose(serviceName, lbRequestx);，方法中的这一行代码就是负载均衡获取服务实例，但是ribbon因为没有维护的原因，实现的是之前的一个参数choose方法，和现在两个参数的方法有冲突，所以我们需要自己实现一版 12345678910public class MyRibbonLoadBalancerClient extends RibbonLoadBalancerClient &#123; public MyRibbonLoadBalancerClient(SpringClientFactory clientFactory) &#123; super(clientFactory); &#125; @Override public &lt;T&gt; ServiceInstance choose(String serviceId, Request&lt;T&gt; request) &#123; return choose(serviceId); &#125;&#125; 我们继承RibbonLoadBalancerClient并实现ServiceInstanceChooser的choose(String serviceId, Request request)方法，但是调用的还是RibbonLoadBalancerClient的choose(String serviceId)方法，从而去除版本不一致带来的影响，最后还要将我们继承的类注册到spring 12345@Beanpublic LoadBalancerClient loadBalancerClient()&#123; return new MyRibbonLoadBalancerClient(springClientFactory);&#125; 自定义负载均衡规则123protected Server getServer(ILoadBalancer loadBalancer, Object hint) &#123; return loadBalancer == null ? null : loadBalancer.chooseServer(hint != null ? hint : &quot;default&quot;);&#125; 从这个方法可以看出，具体的负载规则是由ILoadBalancer负责的，我们可以实现ILoadBalancer并且注册到spring中，但是ribbon对于ILoadBalancer有了默认的实现，BaseLoadBalancer，并且BaseLoadBalancer还有很多子类，实现了多种多样的功能，一般情况不通过实现ILoadBalancer来自定义负载均衡规则，BaseLoadBalancer默认实现了获取服务的通用方法 12345678910111213141516public Server chooseServer(Object key) &#123; if (counter == null) &#123; counter = createCounter(); &#125; counter.increment(); if (rule == null) &#123; return null; &#125; else &#123; try &#123; return rule.choose(key); &#125; catch (Exception e) &#123; logger.warn(&quot;LoadBalancer [&#123;&#125;]: Error choosing server for key &#123;&#125;&quot;, name, key, e); return null; &#125; &#125;&#125; 其中我们需要查看的就是rule.choose(key)这行代码，这就是BaseLoadBalancer具体的负载均衡规则，也就是说BaseLoadBalancer对于具体负载均衡并不是强实现，而是给了扩展的空间，并且在此基础上，封装了许多功能，所以我们一般实现IRule（或者AbstractLoadBalancerRule（IRule的子类））接口即可，并且注册到spring中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146@Beanpublic IRule iRule() &#123; return new NacosSameClusterWeightedRule();&#125;public class NacosSameClusterWeightedRule extends AbstractLoadBalancerRule &#123; @Autowired private NacosDiscoveryProperties nacosDiscoveryProperties; @Override public void initWithNiwsConfig(IClientConfig iClientConfig) &#123; &#125; @Override public Server choose(Object o) &#123; String clusterName = nacosDiscoveryProperties.getClusterName(); BaseLoadBalancer loadBalancer = (BaseLoadBalancer) this.getLoadBalancer(); String name = loadBalancer.getName(); NamingService namingService; try &#123; namingService = NacosFactory.createNamingService(nacosDiscoveryProperties.getNacosProperties()); &#125; catch (NacosException e) &#123; throw new RuntimeException(e); &#125; List&lt;Instance&gt; instances; try &#123; instances = namingService.selectInstances(name, true); &#125; catch (NacosException e) &#123; System.out.println(&quot;集群负载均衡算法出现问题&quot;); e.printStackTrace(); return null; &#125; List&lt;Instance&gt; collect = instances.stream() .filter(instance -&gt; Objects.equals(instance.getClusterName(), clusterName)) .collect(Collectors.toList()); if (CollUtil.isNotEmpty(collect)) &#123; Instance instance = ExtendsBalancer.getHostByRandomWeight2(instances); return new Server(instance.getIp(), instance.getPort()); &#125; else &#123; return null; &#125; &#125;&#125;public class NacosVersionRule extends AbstractLoadBalancerRule &#123; @Autowired private NacosDiscoveryProperties nacosDiscoveryProperties; @Override public void initWithNiwsConfig(IClientConfig iClientConfig) &#123; &#125; @Override public Server choose(Object o) &#123; String clusterName = nacosDiscoveryProperties.getClusterName(); String targetVersion = nacosDiscoveryProperties.getMetadata().get(&quot;target-version&quot;); NamingService namingService; try &#123; namingService = NacosFactory.createNamingService(nacosDiscoveryProperties.getNacosProperties()); &#125; catch (NacosException e) &#123; throw new RuntimeException(e); &#125; BaseLoadBalancer loadBalancer = (BaseLoadBalancer) getLoadBalancer(); String name = loadBalancer.getName(); List&lt;Instance&gt; instances; try &#123; instances = namingService.selectInstances(name, true); &#125; catch (NacosException e) &#123; log.error(&quot;通过服务名获取实例失败，可能不存在该服务&quot;); return null; &#125; if (StringUtils.isNotBlank(targetVersion)) &#123; instances = instances.stream() .filter(instance -&gt; Objects.equals(targetVersion, instance.getMetadata().get(&quot;version&quot;))) .collect(Collectors.toList()); if (CollectionUtils.isEmpty(instances)) &#123; log.error(&quot;未找到符合servicename=&#123;&#125;且version=&#123;&#125;的实例&quot;, name, targetVersion); return null; &#125; &#125; if (StringUtils.isNotBlank(clusterName)) &#123; List&lt;Instance&gt; collect = instances.stream() .filter(instance -&gt; Objects.equals(clusterName, instance.getClusterName())) .collect(Collectors.toList()); if (CollUtil.isNotEmpty(collect)) &#123; Instance instance = ExtendsBalancer.getHostByRandomWeight2(instances); return new Server(instance.getIp(), instance.getPort()); &#125; else &#123; return null; &#125; &#125;else &#123; return null; &#125; &#125;&#125;/** * 根据权重的负载均衡算法 */public class NacosWeightedRule extends AbstractLoadBalancerRule &#123; @Autowired private NacosDiscoveryProperties nacosDiscoveryProperties; @Override public void initWithNiwsConfig(IClientConfig iClientConfig) &#123; &#125; @Override public Server choose(Object o) &#123; //Ribbon的入口 BaseLoadBalancer loadBalancer = (BaseLoadBalancer) this.getLoadBalancer(); //指定服务的名称 String name = loadBalancer.getName(); NamingService namingService; try &#123; namingService = NacosFactory.createNamingService(nacosDiscoveryProperties.getNacosProperties()); &#125; catch (NacosException e) &#123; throw new RuntimeException(e); &#125; Instance instance; try &#123; //根据基于权重的业务方法得到一个实例 instance = namingService.selectOneHealthyInstance(name); &#125; catch (NacosException e) &#123; System.out.println(&quot;基于权重的负载均衡算法出现问题！&quot;); return null; &#125; return new Server(instance.getIp(), instance.getPort()); &#125;&#125;static class ExtendsBalancer extends Balancer &#123; static Instance getHostByRandomWeight2(List&lt;Instance&gt; instanceList)&#123; return getHostByRandomWeight(instanceList); &#125;&#125; 上面实现了三种不同的负载均衡算法，有只返回同clusterName的服务，只返回同target-version的服务，最为主要的方法就是com.alibaba.nacos.client.naming.core.Balancer#getHostByRandomWeight，它是nacos实现的一个针对nacos服务的负载均衡算法，由于这个方法是protected（只允许子类调用），所以我们实现一个它的子类，并且调用这个方法，让我们的程序可以简介调用getHostByRandomWeight，namingService.selectOneHealthyInstance(name)的底层也是调用的它 Ribbon获取服务Ribbon获取服务比较重要的几个类 com.netflix.loadbalancer.ServerList：ServerList是获取服务列表的接口，在不同注册中心下有不同的实现，例如2020之前版本的spring-cloud-starter-alibaba-nacos-discovery中就有实现com.alibaba.cloud.nacos.ribbon.NacosServerList com.netflix.loadbalancer.ServerListFilter：ServerListFilter接口根据配置的规则对服务实例进行过滤 com.netflix.loadbalancer.BaseLoadBalancer：BaseLoadBalancer的allServerList为上面IRule获取服务过程中默认获取的服务列表，初始会通过ServerList的getInitialListOfServers方法获取初始服务列表 com.netflix.loadbalancer.DynamicServerListLoadBalancer#updateListOfServers：updateListOfServers方法通过调用ServerList的getUpdatedListOfServers方法获取服务列表并通过调用ServerListFilter的getFilteredListOfServers方法过滤服务，并且通过调用父类BaseLoadBalancer的setServersList方法，更新BaseLoadBalancer的allServerList 123456789101112public interface ServerList&lt;T extends Server&gt; &#123; public List&lt;T&gt; getInitialListOfServers(); /** * Return updated list of servers. This is called say every 30 secs * (configurable) by the Loadbalancer&#x27;s Ping cycle * */ public List&lt;T&gt; getUpdatedListOfServers(); &#125; 12345public interface ServerListFilter&lt;T extends Server&gt; &#123; public List&lt;T&gt; getFilteredListOfServers(List&lt;T&gt; servers);&#125; 123456789101112131415public void updateListOfServers() &#123; List&lt;T&gt; servers = new ArrayList&lt;T&gt;(); if (serverListImpl != null) &#123; servers = serverListImpl.getUpdatedListOfServers(); LOGGER.debug(&quot;List of Servers for &#123;&#125; obtained from Discovery client: &#123;&#125;&quot;, getIdentifier(), servers); if (filter != null) &#123; servers = filter.getFilteredListOfServers(servers); LOGGER.debug(&quot;Filtered List of Servers for &#123;&#125; obtained from Discovery client: &#123;&#125;&quot;, getIdentifier(), servers); &#125; &#125; updateAllServerList(servers);&#125; 上述获取服务的流程，是在IRule负载过程中获取服务的默认方式，如果我们自定义了负载均衡规则，那么获取服务的操作就在我们自己实现的负载均衡规则代码中实现。在2020之后版本的spring-cloud-starter-alibaba-nacos-discovery已经不提供ServerList的实现类了，所以在nacos作为注册中心的情况下，只能需要自定义负载均衡规则获取nacos服务，或者实现ServerList RestTemplate整合LoadBalancer依赖12345&lt;!--基本所有spring-cloud-dependencies版本都会引入spring-cloud-starter-loadbalancer，所以一般不需要单独定义版本---&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-loadbalancer&lt;/artifactId&gt;&lt;/dependency&gt; 代码代码和RestTemplate整合Ribbon的一致，也是通过@LoadBalanced注解 如何生效生效过程和ribbion一致，也是通过RetryLoadBalancerInterceptor类，和ribbon唯一的区别就是对于LoadBalancerClient的实现，相对于ribbon实现的RibbonLoadBalancerClient，loadBalancer实现了BlockingLoadBalancerClient，如果项目引入了loadbalancer没有引入ribbon，那么默认会使用BlockingLoadBalancerClient，但是如果引入了ribbon，会默认使用RibbonLoadBalancerClient，所以不可避免的引入ribbon的情况下，需要手动注册BlockingLoadBalancerClient 1234567@Autowiredprivate LoadBalancerClientFactory loadBalancerClientFactory;@Beanpublic BlockingLoadBalancerClient blockingLoadBalancerClient()&#123; return new BlockingLoadBalancerClient(loadBalancerClientFactory);&#125; 自定义负载均衡规则123456789public &lt;T&gt; ServiceInstance choose(String serviceId, Request&lt;T&gt; request) &#123; ReactiveLoadBalancer&lt;ServiceInstance&gt; loadBalancer = this.loadBalancerClientFactory.getInstance(serviceId); if (loadBalancer == null) &#123; return null; &#125; else &#123; Response&lt;ServiceInstance&gt; loadBalancerResponse = (Response)Mono.from(loadBalancer.choose(request)).block(); return loadBalancerResponse == null ? null : (ServiceInstance)loadBalancerResponse.getServer(); &#125;&#125; 这是BlockingLoadBalancerClient实现的choose方法，可以看出具体负载规则是由ReactiveLoadBalancer类控制的，所以只需要实现ReactiveLoadBalancer并且配置即可 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113@ConditionalOnDiscoveryEnabled@LoadBalancerClient(name = &quot;LoadBalancerClientConfiguration&quot;, configuration = LoadBalancerClientConfiguration.class)@LoadBalancerClients(defaultConfiguration = LoadBalancerClientConfiguration.class)public class LoadBalancerClientConfiguration &#123; @Bean public ReactorLoadBalancer&lt;ServiceInstance&gt; reactorServiceInstanceLoadBalancer(Environment environment, LoadBalancerClientFactory loadBalancerClientFactory) &#123; String name = environment.getProperty(&quot;loadbalancer.client.name&quot;); return new NacosSameClusterWeightedRule(loadBalancerClientFactory.getLazyProvider(name, ServiceInstanceListSupplier.class), name); &#125; public class NacosSameClusterWeightedRule implements ReactorServiceInstanceLoadBalancer &#123; @Autowired private NacosDiscoveryProperties nacosDiscoveryProperties; final String serviceId; ObjectProvider&lt;ServiceInstanceListSupplier&gt; serviceInstanceListSupplierProvider; public NacosSameClusterWeightedRule(ObjectProvider&lt;ServiceInstanceListSupplier&gt; serviceInstanceListSupplierProvider, String serviceId) &#123; this.serviceId = serviceId; this.serviceInstanceListSupplierProvider = serviceInstanceListSupplierProvider; &#125; @Override public Mono&lt;Response&lt;ServiceInstance&gt;&gt; choose(Request request) &#123; try &#123; String clusterName = nacosDiscoveryProperties.getClusterName(); NamingService namingService = NacosFactory.createNamingService(nacosDiscoveryProperties.getNacosProperties()); List&lt;Instance&gt; instances = namingService.getAllInstances(serviceId).stream().filter(instance -&gt; instance.getClusterName().equals(clusterName)).collect(Collectors.toList()); Instance instance = ExtendsBalancer.getHostByRandomWeight2(instances); return Mono.create(responseMonoSink -&gt; responseMonoSink.success(new DefaultResponse(toNacosServiceInstance(instance)))); &#125; catch (NacosException e) &#123; throw new RuntimeException(e); &#125; &#125; &#125; public class NacosVersionRule implements ReactorServiceInstanceLoadBalancer &#123; @Autowired private NacosDiscoveryProperties nacosDiscoveryProperties; final String serviceId; ObjectProvider&lt;ServiceInstanceListSupplier&gt; serviceInstanceListSupplierProvider; public NacosVersionRule(ObjectProvider&lt;ServiceInstanceListSupplier&gt; serviceInstanceListSupplierProvider, String serviceId) &#123; this.serviceId = serviceId; this.serviceInstanceListSupplierProvider = serviceInstanceListSupplierProvider; &#125; @Override public Mono&lt;Response&lt;ServiceInstance&gt;&gt; choose(Request request) &#123; try &#123; String targetVersion = nacosDiscoveryProperties.getMetadata().get(&quot;target-version&quot;); NamingService namingService = NacosFactory.createNamingService(nacosDiscoveryProperties.getNacosProperties()); List&lt;Instance&gt; instances = namingService.getAllInstances(serviceId).stream().filter(instance -&gt; instance.getMetadata().get(&quot;target-version&quot;).equals(targetVersion)).collect(Collectors.toList()); Instance instance = ExtendsBalancer.getHostByRandomWeight2(instances); return Mono.create(responseMonoSink -&gt; responseMonoSink.success(new DefaultResponse(toNacosServiceInstance(instance)))); &#125; catch (NacosException e) &#123; throw new RuntimeException(e); &#125; &#125; &#125; public class NacosWeightedRule implements ReactorServiceInstanceLoadBalancer &#123; @Autowired private NacosDiscoveryProperties nacosDiscoveryProperties; final String serviceId; ObjectProvider&lt;ServiceInstanceListSupplier&gt; serviceInstanceListSupplierProvider; public NacosWeightedRule(ObjectProvider&lt;ServiceInstanceListSupplier&gt; serviceInstanceListSupplierProvider, String serviceId) &#123; this.serviceId = serviceId; this.serviceInstanceListSupplierProvider = serviceInstanceListSupplierProvider; &#125; @Override public Mono&lt;Response&lt;ServiceInstance&gt;&gt; choose(Request request) &#123; try&#123; NamingService namingService = NacosFactory.createNamingService(nacosDiscoveryProperties.getNacosProperties()); //根据基于权重的业务方法得到一个实例 Instance instance = namingService.selectOneHealthyInstance(serviceId); return Mono.create(responseMonoSink -&gt; responseMonoSink.success(new DefaultResponse(toNacosServiceInstance(instance)))); &#125;catch (Exception e)&#123; throw new RuntimeException(e); &#125; &#125; &#125; public static NacosServiceInstance toNacosServiceInstance(Instance instance) &#123; NacosServiceInstance nacosServiceInstance = new NacosServiceInstance(); nacosServiceInstance.setHost(instance.getIp()); nacosServiceInstance.setMetadata(instance.getMetadata()); nacosServiceInstance.setServiceId(instance.getServiceName()); nacosServiceInstance.setPort(instance.getPort()); return nacosServiceInstance; &#125; static class ExtendsBalancer extends Balancer &#123; static Instance getHostByRandomWeight2(List&lt;Instance&gt; instanceList)&#123; return getHostByRandomWeight(instanceList); &#125; &#125;&#125; 上述代码和上面ribbon实现的负载均衡一致，只是实现方式略有不同。loadBalancer的负载均衡不仅需要注册到spring，还需要使用到@LoadBalancerClient和@LoadBalancerClients，并且需要两个同时配置才会生效 LoadBalancer获取服务LoadBalancer获取服务过程中比较重要的几个类 org.springframework.cloud.client.discovery.DiscoveryClient：DiscoveryClient是spring-cloud-common下面的包，不同注册中心下有不同的实现，spring-cloud-loadbalancer在负载过程中通过调用这个接口获取服务列表 com.alibaba.cloud.nacos.discovery.NacosDiscoveryClient：NacosDiscoveryClient是nacos对于DiscoveryClient的实现，底层是通过NamingService获取服务 1234567891011121314151617public interface DiscoveryClient extends Ordered &#123; int DEFAULT_ORDER = 0; String description(); List&lt;ServiceInstance&gt; getInstances(String serviceId); List&lt;String&gt; getServices(); default void probe() &#123; this.getServices(); &#125; default int getOrder() &#123; return 0; &#125;&#125; 123456789101112131415161718192021222324252627282930public class NacosDiscoveryClient implements DiscoveryClient &#123; private static final Logger log = LoggerFactory.getLogger(NacosDiscoveryClient.class); public static final String DESCRIPTION = &quot;Spring Cloud Nacos Discovery Client&quot;; private NacosServiceDiscovery serviceDiscovery; public NacosDiscoveryClient(NacosServiceDiscovery nacosServiceDiscovery) &#123; this.serviceDiscovery = nacosServiceDiscovery; &#125; public String description() &#123; return &quot;Spring Cloud Nacos Discovery Client&quot;; &#125; public List&lt;ServiceInstance&gt; getInstances(String serviceId) &#123; try &#123; return this.serviceDiscovery.getInstances(serviceId); &#125; catch (Exception var3) &#123; throw new RuntimeException(&quot;Can not get hosts from nacos server. serviceId: &quot; + serviceId, var3); &#125; &#125; public List&lt;String&gt; getServices() &#123; try &#123; return this.serviceDiscovery.getServices(); &#125; catch (Exception var2) &#123; log.error(&quot;get service name from nacos server fail,&quot;, var2); return Collections.emptyList(); &#125; &#125;&#125; 上述获取服务的流程，是在ReactiveLoadBalancer负载过程中获取服务的默认方式，如果我们自定义了负载均衡规则，那么获取服务的操作就在我们自己实现的负载均衡规则代码中实现","categories":["Spring Cloud"]},{"title":"Java基础知识","path":"/2025/01/07/Java基础知识/","content":"类加载机制流程 双亲委派机制 线程上下文类加载器但往往在SPI接口中，会经常调用实现者的代码，所以一般会需要先去加载自己的实现类，但实现类并不在Bootstrap类加载器的加载范围内，经过前面的双亲委派机制的分析，我们已经得知：子类加载器可以将类加载请求委托给父类加载器进行加载，但这个过程是不可逆的。也就是父类加载器是不能将类加载请求委派给自己的子类加载器进行加载的 它可以打破双亲委托机制，父ClassLoader可以使用当前线程的Thread.currentThread().getContextClassLoader()所指定的classLoader来加载类，这就可以改变父ClassLoader不能使用子ClassLoader或是其他没有直接父子关系的ClassLoader加载的类的情况，即改变了双亲委托模型 对于SPI来说，有些接口是Java核心库所提供的，而Java核心库是由启动类加载器加载的，而这些接口的实现却是来自于不同jar包（厂商提供），Java的启动类加载是不会加载其他来源的jar包，这样传统的双亲委托模型就无法满足SPI的要求。而通过给当前线程设置上下文类加载器，就可以由设置的上线文类加载器来实现与接口实现类的加载","categories":["知识累积"]},{"title":"RocketMQ延时队列","path":"/2025/01/07/RocketMQ延时队列/","content":"什么是延迟队列指消息发送到某个队列后，在指定多长时间之后才能被消费。消费消息，按照0到18级别来，0 表示不延迟，1表示延迟1s，大于等于18表示延迟2h按照级别一次类推默认值为“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m8m 9m 10m 20m 30m 1h 2h”，18个level 测试生产端test-topic 有四个队列，测试代码将0-99 分别放到不同的队列中，根据不同的队列设置不同的延时值(0(0s)，4(30s)，8(4m)，12(8m)) 123456789101112131415@GetMapping(&quot;/send/&#123;message&#125;&quot;)public void send(@PathVariable(&quot;message&quot;) String messageStr) &#123; rocketMQTemplate.setMessageQueueSelector((list, message, o) -&gt; &#123; int index = Integer.valueOf((String) o) % 4; message.setDelayTimeLevel(index * 4); return list.get(index); &#125;); for (int i = 0; i &lt; 100; i++) &#123; Message message = MessageBuilder .withPayload(&quot;message is :&quot; + i) .setHeader(&quot;avg&quot;, i) .build(); rocketMQTemplate.sendOneWayOrderly(&quot;test-topic&quot;, message, String.valueOf(i)); &#125;&#125; 消费端可以看到，队列1的消息比队列0的消息慢了30s 原理rocketmq会创建一个专门处理延迟消息的topic叫做SCHEDULE_TOPIC_XXXX，这个topic中会根据延迟级别创建队列，然后将不同延迟级别的消息放到指定的队列，保证顺序消费，否则如果高延迟和低延迟的放一起的话，高延迟消息必然会影响低延迟消息的消费，等待指定时间后，SCHEDULE_TOPIC_XXXX会把消息发送到真正的topic(1)、修改消息Topic名称和队列信息RocketMQ Broker端在存储生产者写入的消息时，首先都会将其写入到CommitLog中。之后根据消息中的Topic信息和队列信息，将其转发到目标Topic的指定队列(ConsumeQueue)中。 由于消息一旦存储到ConsumeQueue中，消费者就能消费到，而延迟消息不能被立即消费，所以这里将Topic的名称修改为SCHEDULE_TOPIC_XXXX，并根据延迟级别确定要投递到哪个队列下。同时，还会将消息原来要发送到的目标Topic和队列信息存储到消息的属性中。 (2)、转发消息到延迟主题SCHEDULE_TOPIC_XXXX的CosumeQueue中CommitLog中的消息转发到CosumeQueue中是异步进行的。在转发过程中，会对延迟消息进行特殊处理，主要是计算这条延迟消息需要在什么时候进行投递。 投递时间 &#x3D; 消息存储时间(storeTimestamp) + 延迟级别对应的时间 需要注意的是，会将计算出的投递时间当做消息Tag的哈希值存储到CosumeQueue中，CosumeQueue单个存储单元组成结构如下图所示： 其中： Commit Log Offset：记录在CommitLog中的位置；Size：记录消息的大小；Message Tag HashCode：记录消息Tag的哈希值，用于消息过滤。特别的，对于延迟消息，这个字段记录的是消息的投递时间戳。这也是为什么java中hashCode方法返回一个int型，只占用4个字节，而这里Message Tag HashCode字段却设计成8个字节的原因；(3)、延迟服务消费SCHEDULE_TOPIC_XXXX消息Broker内部有一个ScheduleMessageService类，其充当延迟服务，主要是消费SCHEDULE_TOPIC_XXXX中的消息，并投递到目标Topic中。 ScheduleMessageService在启动时，其会创建一个定时器Timer，并根据延迟级别的个数，启动对应数量的TimerTask，每个TimerTask负责一个延迟级别的消费与投递。 需要注意的是，每个TimeTask在检查消息是否到期时，首先检查对应队列中尚未投递第一条消息，如果这条消息没到期，那么之后的消息都不会检查。如果到期了，则进行投递，并检查之后的消息是否到期。 (4)、将信息重新存储到CommitLog中在将消息到期后，需要投递到目标Topic。由于在第一步已经记录了原来的Topic和队列信息，因此这里重新设置，再存储到CommitLog即可。此外，由于之前Message Tag HashCode字段存储的是消息的投递时间，这里需要重新计算tag的哈希值后再存储。 (5)、将消息投递到目标Topic中这一步与第二步类似，不过由于消息的Topic名称已经改为了目标Topic。因此消息会直接投递到目标Topic的ConsumeQueue中，之后消费者即消费到这条消息。 (6)、消费者消费目标topic中的数据。","categories":["RocketMQ"]},{"title":"Spring Boot整合Activiti","path":"/2025/01/07/Spring Boot整合Activiti/","content":"依赖12345&lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-spring-boot-starter-basic&lt;/artifactId&gt; &lt;version&gt;6.0.0&lt;/version&gt;&lt;/dependency&gt; 数据库配置activiti需要很多表存储流程信息（activiti会自动创建），直接使用spring数据源配置 123456789101112spring: application: name: acitiviti datasource: username: root password: 123456 url: jdbc:mysql://localhost:3306/activiti?useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTC&amp;allowMultiQueries=true driver-class-name: com.mysql.cj.jdbc.Driver activiti: database-schema-update: true history-level: full db-history-used: true activiti配置类(各种Service) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778@Configurationpublic class ActivitiConfiguration &#123; @Autowired private DataSource dataSource; @Autowired private PlatformTransactionManager platformTransactionManager; @Autowired private ProcessEngineFactoryBean processEngine; @Bean public SpringProcessEngineConfiguration springProcessEngineConfiguration()&#123; SpringProcessEngineConfiguration spec = new SpringProcessEngineConfiguration(); spec.setDataSource(dataSource); spec.setTransactionManager(platformTransactionManager); spec.setDatabaseSchemaUpdate(ProcessEngineConfiguration.DB_SCHEMA_UPDATE_FALSE); Resource[] resources = null; // 启动自动部署流程 try &#123; resources = new PathMatchingResourcePatternResolver().getResources(&quot;classpath*:bafy.bpmn&quot;); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; spec.setDeploymentResources(resources); return spec; &#125; /** * Activiti 中每一个不同版本的业务流程的定义都需要使用一些定义文件，部署文件和支持数据 ( 例如 BPMN2.0 XML 文件，表单定义文件，流程定义图像文件等 )， * 这些文件都存储在 Activiti 内建的 Repository 中。Repository Service 提供了对 repository 的存取服务 * @return * @throws Exception */ @Bean public RepositoryService repositoryService() throws Exception&#123; return processEngine.getObject().getRepositoryService(); &#125; /** * 在 Activiti 中，每当一个流程定义被启动一次之后，都会生成一个相应的流程对象实例。Runtime Service 提供了启动流程、查询流程实例、设置获取流程实例变量等功能。 * 此外它还提供了对流程部署，流程定义和流程实例的存取服务 * @return * @throws Exception */ @Bean public RuntimeService runtimeService() throws Exception&#123; return processEngine.getObject().getRuntimeService(); &#125; /** * Activiti 中业务流程定义中的每一个执行节点被称为一个 Task，对流程中的数据存取，状态变更等操作均需要在 Task 中完成。Task Service 提供了对用户 Task 和 * Form 相关的操作。它提供了运行时任务查询、领取、完成、删除以及变量设置等功能 * @return * @throws Exception */ @Bean public TaskService taskService() throws Exception&#123; return processEngine.getObject().getTaskService(); &#125; /** * 用于获取正在运行或已经完成的流程实例的信息，与 Runtime Service 中获取的流程信息不同，历史信息包含已经持久化存储的永久信息，并已经被针对查询优化 * @return * @throws Exception */ @Bean public HistoryService historyService() throws Exception&#123; return processEngine.getObject().getHistoryService(); &#125; /** * 用于获取组任务相关记录 * @return * @throws Exception */ @Bean public IdentityService identityService() throws Exception &#123; return processEngine.getObject().getIdentityService(); &#125;&#125; 流程配置xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;&lt;definitions xmlns=&quot;http://www.omg.org/spec/BPMN/20100524/MODEL&quot; xmlns:activiti=&quot;http://activiti.org/bpmn&quot; xmlns:bpmndi=&quot;http://www.omg.org/spec/BPMN/20100524/DI&quot; xmlns:dc=&quot;http://www.omg.org/spec/DD/20100524/DC&quot; xmlns:di=&quot;http://www.omg.org/spec/DD/20100524/DI&quot; xmlns:tns=&quot;http://sourceforge.net/bpmn/definitions/_1659861584170&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:yaoqiang=&quot;http://bpmn.sourceforge.net&quot; expressionLanguage=&quot;http://www.w3.org/1999/XPath&quot; id=&quot;_1659861584170&quot; name=&quot;test&quot; targetNamespace=&quot;http://sourceforge.net/bpmn/definitions/_1659861584170&quot; typeLanguage=&quot;http://www.w3.org/2001/XMLSchema&quot;&gt; &lt;process id=&quot;askForLeave&quot; isClosed=&quot;false&quot; isExecutable=&quot;true&quot; processType=&quot;None&quot;&gt; &lt;startEvent id=&quot;_2&quot; name=&quot;StartEvent&quot;/&gt; &lt;userTask activiti:assignee=&quot;$&#123;worker&#125;&quot; activiti:exclusive=&quot;true&quot; id=&quot;_3&quot; name=&quot;项目经理审批&quot;/&gt; &lt;userTask activiti:assignee=&quot;$&#123;worker&#125;&quot; activiti:exclusive=&quot;true&quot; id=&quot;_4&quot; name=&quot;部门经理审批&quot;&gt; &lt;multiInstanceLoopCharacteristics activiti:collection=&quot;workers&quot; activiti:elementVariable=&quot;worker&quot; isSequential=&quot;false&quot;&gt; &lt;completionCondition&gt;$&#123;nrOfCompletedInstances/nrOfInstances &gt;= 0.5&#125;&lt;/completionCondition&gt; &lt;/multiInstanceLoopCharacteristics&gt; &lt;/userTask&gt; &lt;userTask activiti:assignee=&quot;$&#123;worker&#125;&quot; activiti:exclusive=&quot;true&quot; id=&quot;_5&quot; name=&quot;总经理审批&quot;/&gt; &lt;endEvent id=&quot;_6&quot; name=&quot;EndEvent&quot;/&gt; &lt;sequenceFlow id=&quot;_7&quot; sourceRef=&quot;_2&quot; targetRef=&quot;_3&quot;/&gt; &lt;sequenceFlow id=&quot;_8&quot; sourceRef=&quot;_3&quot; targetRef=&quot;_4&quot;/&gt; &lt;sequenceFlow id=&quot;_9&quot; sourceRef=&quot;_4&quot; targetRef=&quot;_5&quot;/&gt; &lt;sequenceFlow id=&quot;_10&quot; sourceRef=&quot;_5&quot; targetRef=&quot;_6&quot;/&gt; &lt;/process&gt; &lt;bpmndi:BPMNDiagram documentation=&quot;background=#3C3F41;count=1;horizontalcount=1;orientation=0;width=842.4;height=1195.2;imageableWidth=832.4;imageableHeight=1185.2;imageableX=5.0;imageableY=5.0&quot; id=&quot;Diagram-_1&quot; name=&quot;New Diagram&quot;&gt; &lt;bpmndi:BPMNPlane bpmnElement=&quot;askForLeave&quot;&gt; &lt;bpmndi:BPMNShape bpmnElement=&quot;_2&quot; id=&quot;Shape-_2&quot;&gt; &lt;dc:Bounds height=&quot;32.0&quot; width=&quot;32.0&quot; x=&quot;130.0&quot; y=&quot;10.0&quot;/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height=&quot;32.0&quot; width=&quot;32.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=&quot;_3&quot; id=&quot;Shape-_3&quot;&gt; &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;100.0&quot; y=&quot;115.0&quot;/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=&quot;_4&quot; id=&quot;Shape-_4&quot;&gt; &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;100.0&quot; y=&quot;235.0&quot;/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=&quot;_5&quot; id=&quot;Shape-_5&quot;&gt; &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;100.0&quot; y=&quot;340.0&quot;/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=&quot;_6&quot; id=&quot;Shape-_6&quot;&gt; &lt;dc:Bounds height=&quot;32.0&quot; width=&quot;32.0&quot; x=&quot;125.0&quot; y=&quot;445.0&quot;/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height=&quot;32.0&quot; width=&quot;32.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNEdge bpmnElement=&quot;_7&quot; id=&quot;BPMNEdge__7&quot; sourceElement=&quot;_2&quot; targetElement=&quot;_3&quot;&gt; &lt;di:waypoint x=&quot;146.0&quot; y=&quot;42.0&quot;/&gt; &lt;di:waypoint x=&quot;146.0&quot; y=&quot;115.0&quot;/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height=&quot;0.0&quot; width=&quot;0.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement=&quot;_8&quot; id=&quot;BPMNEdge__8&quot; sourceElement=&quot;_3&quot; targetElement=&quot;_4&quot;&gt; &lt;di:waypoint x=&quot;142.5&quot; y=&quot;170.0&quot;/&gt; &lt;di:waypoint x=&quot;142.5&quot; y=&quot;235.0&quot;/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height=&quot;0.0&quot; width=&quot;0.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement=&quot;_9&quot; id=&quot;BPMNEdge__9&quot; sourceElement=&quot;_4&quot; targetElement=&quot;_5&quot;&gt; &lt;di:waypoint x=&quot;142.5&quot; y=&quot;290.0&quot;/&gt; &lt;di:waypoint x=&quot;142.5&quot; y=&quot;340.0&quot;/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height=&quot;0.0&quot; width=&quot;0.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement=&quot;_10&quot; id=&quot;BPMNEdge__10&quot; sourceElement=&quot;_5&quot; targetElement=&quot;_6&quot;&gt; &lt;di:waypoint x=&quot;141.0&quot; y=&quot;395.0&quot;/&gt; &lt;di:waypoint x=&quot;141.0&quot; y=&quot;445.0&quot;/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height=&quot;0.0&quot; width=&quot;0.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;/bpmndi:BPMNPlane&gt; &lt;/bpmndi:BPMNDiagram&gt;&lt;/definitions&gt; 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990@Slf4j@RestController@RequestMapping(&quot;/askForLeave&quot;)public class askForLeaveController &#123; @Autowired private RuntimeService runtimeService; @Autowired private TaskService taskService; private final RepositoryService repositoryService; public askForLeaveController(RepositoryService repositoryService) &#123; this.repositoryService = repositoryService; repositoryService.createDeployment() .name(&quot;请假申请流程&quot;) .addClasspathResource(&quot;processes/test.bpmn20.xml&quot;) .addClasspathResource(&quot;processes/test.bpmn20.png&quot;) .deploy(); &#125; @GetMapping(&quot;/submit&quot;) public void submit(String username) &#123; Map map = CollUtil.newHashMap(); map.put(&quot;worker&quot;, &quot;zhangsan&quot;); //&quot;askForLeave&quot;是流程定义id（processDefinitionKey），即xml文件中&lt;process&gt;标签的id，可通过xml配置，每修改一次xml并重启，则会对流程定义（processDefinition）生成一个新的版本，可在act_re_procdef表中查看 ProcessInstance processInstance = runtimeService.startProcessInstanceByKey(&quot;askForLeave&quot;, username, map); log.info(&quot;processInstance is: &#123;&#125;&quot;, processInstance); &#125; @GetMapping(&quot;/projectManager&quot;) public List&lt;Map&gt; projectManager(String username) &#123; List&lt;Task&gt; tasks = taskService.createTaskQuery().processInstanceBusinessKey(username).taskAssignee(&quot;zhangsan&quot;).list(); Map map = CollUtil.newHashMap(); map.put(&quot;workers&quot;, CollUtil.newArrayList(&quot;lisi&quot;, &quot;wangwu&quot;)); //总经理审批的处理人不能放到部门经理去设置，可能是因为部门经理审批是个会签 map.put(&quot;worker&quot;, &quot;zhaoliu&quot;); for (Task task : tasks) &#123; taskService.complete(task.getId(), map); &#125; return toMap(tasks); &#125; @GetMapping(&quot;/departmentManagerLisi&quot;) public List&lt;Map&gt; departmentManagerLisi(String username) &#123; List&lt;Task&gt; tasks = taskService.createTaskQuery().processInstanceBusinessKey(username).taskAssignee(&quot;lisi&quot;).list(); Map map = CollUtil.newHashMap(); for (Task task : tasks) &#123; taskService.complete(task.getId(), map); &#125; return toMap(tasks); &#125; @GetMapping(&quot;/departmentManagerWangwu&quot;) public List&lt;Map&gt; departmentManagerWangwu(String username) &#123; List&lt;Task&gt; tasks = taskService.createTaskQuery().processInstanceBusinessKey(username).taskAssignee(&quot;wangwu&quot;).list(); Map map = CollUtil.newHashMap(); for (Task task : tasks) &#123; taskService.complete(task.getId(), map); &#125; return toMap(tasks); &#125; @GetMapping(&quot;/generalManager&quot;) public List&lt;Map&gt; generalManager(String username) &#123; List&lt;Task&gt; tasks = taskService.createTaskQuery().processInstanceBusinessKey(username).taskAssignee(&quot;zhaoliu&quot;).list(); for (Task task : tasks) &#123; taskService.complete(task.getId()); &#125; return toMap(tasks); &#125; /** * 由于task是接口，无法直接返回给前端，通过map转换一下 * @param list * @return */ public List&lt;Map&gt; toMap(List&lt;Task&gt; list) &#123; List&lt;Map&gt; result = CollUtil.newArrayList(); for (Task task : list) &#123; Map map = CollUtil.newHashMap(); map.put(&quot;user&quot;, task.getAssignee()); map.put(&quot;name&quot;, task.getName()); result.add(map); &#125; return result; &#125;&#125;","categories":["Activiti流程引擎"]},{"title":"快照读以及当前读","path":"/2025/01/07/快照读以及当前读/","content":"MVCC提到快照读和当前读就不得不提到MVCC(多版本并发控制)，可以理解为乐观锁的一种具体的实现，Mysql Innodb引擎下，在可重复读和提交读的隔离级别下，会使用到MVCC，每一行数据都会有两个默认字段，及生成版本和删除版本，还有一个指针，指向上一个版本，每开启一个事务，都会有一个版本号，在事务内部执行update或者insert时，会为记录新增一个版本，例如： ReadView提到MVCC，就不得不提到ReadView，ReadView是MVCC最为关键的部分，控制事务可以访问到的版本read view中存放的是当前活跃事务id，也就是当前还没有提交的事务id，如下图所示，假如在事务之间还存在一个活跃事务id为50,事务A的事务Id为51，事务B为52,事务C为53。那么事务A的read view为[50,51]，事务B为[50,51,52]，事务C为[50,51,52,53]。 高水位和低水位 高水位指事务创建时当前系统中最大的事务id+1，例如事务A创建时，事务A本身就是最新创建的事务，事务A的高水位就是事务A的事务id加1，即高水位为52 低水位指事务创建时当前系统中最小的活跃事务id，例如事务A创建时，事务A的低水位就是50，也可以理解为read view中最小的事务id&#x2F;&#x2F;注：高水位和低水位是伴随着read view的，所以高水位和低水位是个固定值 高低水位比对规则mysql在可重复读级别下，读到的数据始终是一致的，原因就是因为高低水位加上一个事务id（这里指的是某个版本的事务id，不是具体事务的事务，为了区分，下面用版本id代替）以及一个比对结果 具体规则： 如果版本id小于等于低水位落在绿色部分，证明这个版本已经提交或者就是当前事务创建的，是可见的 如果版本id大于等于高水位落在红色部分，证明这个版本是当前事务后面的事务创建的，是不可见的 如果版本id大于低水位而小于高水位，则需要分情况 如果当前事务的read view中不存在该版本id，证明该版本在当前事务创建时已经提交了，是可见的 如果当前事务的read view中存在该版本id，证明该版本在当前事务创建时还未提交，是不可见的 快照读根据实际运行，事务B查询的k为3，事务A查询的k为1，事务A的查询就是快照读，如下图，存在52、53、50三个版本，事务A查询到52时，发现大于自己read view的高水位，不可见，继续往下走，53也大于自己的高水位，继续往下走，发现50等于自己的低水位，是可见的，返回这个快照的结果，即查询的k为1，所谓快照读通俗来讲就是访问到以前的快照 当前读按照MVCC的思想事务B的查询结果应该是2才对，为什么是3呢，这里就涉及到了当前读，当前读只会读取最新的数据，而除了select之外的动作都会触发当前读，所以事务B进行update操作时，最新的版本是53，所以事务B的k值变成了3。如果事务C没有提交，那事务B的update还会因为当前读访问到事务C的版本吗，这样的话不是违背了提交读吗，这里忘记了一个知识点，update操作会加锁，如果事务C不提交，那么事务B的update会阻塞，也就不存在能不能访问到的问题了，所以当前读的实现是有锁的参与的 可重复读和提交读可重复读和提交读级别的区别在于read view的机制不一样，可重复读只在创建事务时生成，而提交读会在每次执行查询时重新生成 我们假设事务B比事务A先提交 如果是可重复读级别的话，事务A进行select操作时，由于事务A的read view没有发生变化，事务B在事务A眼里仍然是活跃的，所以事务A还是只会查询到之前的快照 如果是提交读级别的话，事务A进行select操作时，由于事务B和事务C都已提交，事务A会重新生成read view[50, 51]，事务A的高低水位也会随着变化，高水位变成54，低水位还是50，而事务B的事务id时52，小于高水位54，且由于已经提交了不在read view中，所以事务B对于记录的更改对于事务A是可见的，这就是读已提交的实现原理 一个小知识使用navicat时，如果改变了隔离级别，需要将当前查询窗口关掉，重新建查询窗口，不然隔离级别的修改可能不会生效，另外，修改隔离级别时，最好session和global的隔离级别都更改","categories":["数据库"]},{"title":"Canal结合RabbitMQ","path":"/2025/01/07/Canal结合RabbitMQ/","content":"Canal基于 MySQL 数据库增量日志解析,提供增量数据订阅和消费，Canal将自己伪装成MySQL从服务器，从而获取主服务器的数据 MySQL配置修改mysql配置，修改完重启服务my.cnf(linux)或者my.ini(windows) 1234[mysqld]log-bin=mysql-bin # 开启 binlogbinlog-format=ROW # 选择 ROW 模式server_id=1 # 配置 MySQL replaction 需要定义，不要和 canal 的 slaveId 重复 Canal配置12345678910.....# 指定rabbitmqcanal.serverMode = rabbitmq...# rabbitmq 设置canal.mq.servers = 192.168.5.4 ## 注意不要加端口号，不然会报IPV6错误。canal.mq.vhost=/canal.mq.exchange=exchange.trade.ordercanal.mq.username=admincanal.mq.password=admin 12345678910canal.instance.mysql.slaveId=9999...# position infocanal.instance.master.address=192.168.3.157:3306 ## 数据库地址# enable druid Decrypt database passwordcanal.instance.defaultDatabaseName=file ## 数据库名canal.mq.topic=example # 路由键... 测试mysql插入数据 1insert into test values (10,10); rabbitmq 1message body is &#123;&quot;data&quot;:[&#123;&quot;id&quot;:&quot;10&quot;,&quot;number&quot;:&quot;10&quot;&#125;],&quot;database&quot;:&quot;test&quot;,&quot;es&quot;:1656042929000,&quot;id&quot;:9,&quot;isDdl&quot;:false,&quot;mysqlType&quot;:&#123;&quot;id&quot;:&quot;int&quot;,&quot;number&quot;:&quot;int&quot;&#125;,&quot;old&quot;:null,&quot;pkNames&quot;:[&quot;id&quot;],&quot;sql&quot;:&quot;&quot;,&quot;sqlType&quot;:&#123;&quot;id&quot;:4,&quot;number&quot;:4&#125;,&quot;table&quot;:&quot;test&quot;,&quot;ts&quot;:1656042930093,&quot;type&quot;:&quot;INSERT&quot;&#125;","categories":["数据库相关中间件"]},{"title":"Spring Cloud Gateway配置过滤器","path":"/2025/01/07/Spring Cloud Gateway配置过滤器/","content":"依赖12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 这里引入两个依赖，spring-cloud-dependencies使用Greenwich.SR2版本，第一个依赖及引入gateway的功能，第二个依赖引入的actuator是为了方便查看gateway的路由配置 配置12345678910spring: gateway: discovery: locator: enabled: truemanagement: endpoints: web: exposure: include: &quot;*&quot; 第一个配置是允许gateway发现所有在nacos上注册的服务，前提是gateway也注册在该nacos上，第二配置是为了打开actuator的功能，具体我也不太清楚。 代码通过实现GatewayFilter设置过滤器过滤器类123456789101112131415public class AuthGatewayFilter implements GatewayFilter, Ordered &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; log.info(&quot;请求前执行的语句&quot;); return chain.filter(exchange).then( Mono.fromRunnable(() -&gt; log.info(&quot;请求后执行的语句&quot;)) ); &#125; @Override public int getOrder() &#123; return 0; &#125;&#125; 这里只写了两条日志打印语句，是为了强调在chain.filter(exchange).then()外部的程序实在请求转发之前运行的，既“pre”， Mono.fromRunnable()方法内部的程序是在请求处理完之后运行的，既“post”。也可以直接返回chain.filter(exchange);，则表示不对请求完之后的事件进行处理。这里同样实现了Ordered是为了是指定滤器的执行顺序，order越小越先执行，这里要强调一下，过滤器的order和路由的order不是一回事 配置过滤器1234567891011121314151617181920@SpringBootApplicationpublic class GatewayApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GatewayApplication.class, args); &#125; @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) &#123; return builder.routes() .route(r -&gt; r.path(&quot;/producer/**&quot;) .filters(f -&gt; f.stripPrefix(1) .filters(new AuthGatewayFilter()) ) .uri(&quot;lb://producer&quot;) ) .build(); &#125;&#125; 这里通过配置RouteLocator使AuthGatewayFilter过滤器生效，这里的f.stripPrefix(1)是设置路径切割的，既切掉头部1(既设置的参数)个字段，如果不设置则转发将会变为&#x2F;producer&#x2F;producer&#x2F;。 效果图我们通过访问&#x2F;actuator&#x2F;gateway&#x2F;routes可以看到，我们设置的过滤器已经在第一个路由中生效了，并且在路由列表第一个。 通过实现AbstractGatewayFilterFactory设置过滤器过滤器类123456789101112131415161718192021222324252627282930@Slf4j@Componentpublic class AuthGatewayFilterFactory extends AbstractGatewayFilterFactory&lt;AuthGatewayFilterFactory.Config&gt; &#123; public AuthGatewayFilterFactory()&#123; super(Config.class); &#125; @Override public GatewayFilter apply(Config config) &#123; log.info(config.getKey()); return (exchange, chain) -&gt; &#123; log.info(&quot;请求前执行的语句&quot;); return chain.filter(exchange).then( Mono.fromRunnable(() -&gt; log.info(&quot;请求后执行的语句&quot;)) ); &#125;; &#125; @Override public List&lt;String&gt; shortcutFieldOrder() &#123; return Arrays.asList(&quot;key&quot;); &#125; @Data static class Config&#123; private String key; &#125;&#125; 可以看到apply方法返回的是一个GatewayFilter对象，所以也可以直接返回我们上面实现的AuthGatewayFilter对象。注意：在类的构造器中一定要调用下父类的构造器把Config类型传过去，否则会报ClassCastException。shortcutFieldOrder方法也要实现就是将config中的参数添加到列表，这样才能从配置文件读数据。还有一点，这里的config不能用内部类，原因不明，可以静态内部类 配置过滤器123456789101112spring: cloud: gateway: routes: - id: auth_route uri: lb://producer predicates: - Path=/producer/** filters: - StripPrefix=1 - Auth order: -1 配置与上面在启动类里面的RouteLocator配置没有什么区别，但是多了一个order: -1，下面看一下order: -1的效果 不配置order: -1我们可以看到自定义的auth_route在列表最后一列，而第2个route是gateway默认配置的，就是由最上面的写的那个enabled: true配置产生的，它的predicates与我们自定义的predicates是一样的，所以我们自定义的route根本不会生效 配置order: -1我们可以看到，auth_route已经在列表第一项了，这样gateway默认配置的与auth_route的predicates一样的route就失效了。当然我这里只是强调order的作用，实际上不会这么写。而且我们发现上面通过RouteLocator配置的route直接在列表的第一项，并没有配置order，这应该和gateway内部的配置有关 全局过滤器上面两个过滤器都是局部过滤器，全局过滤器比较简单，只要实现GlobalFilter就行了，写法与上面的实现的AuthGatewayFilter一样，区别是只要在全局过滤器类上加上@Component即可生效。最后强调一下，全局过滤器在与其他过滤器order相同的情况下，其他过滤器会优先执行。","categories":["Spring Cloud"]},{"title":"Spring Cloud Stream整合RabbitMQ","path":"/2025/01/07/Spring Cloud Stream整合RabbitMQ/","content":"前言在使用消息队列组件时，如果程序需要更换消息队列组件，那么代码内部可能需要做巨大的修改，而Spring Cloud Stream则解决了这个问题，应用程序只需要通过 inputs 或者 outputs 来与 Spring Cloud Stream 中binder 交互，通过我们配置来 binding ，而 Spring Cloud Stream 的 binder 负责与消息中间件交互。所以，我们只需要搞清楚如何与 Spring Cloud Stream 交互就可以方便使用消息驱动的方式。 生产者依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; 配置1234567891011121314151617spring: cloud: stream: bindings: output: #output为默认“管道”，也可以设置为自己定义的，但是需要与自己定义的类相对应，例如自定义为myoutput destination: testStreamExchange binder: local_rabbit binders: local_rabbit: type: rabbit environment: spring: rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest 消息发送类12345678910111213@RestController@EnableBinding(Processor.class)public class MessageController &#123; @Autowired private Processor processor; @GetMapping(&quot;/sendMessage&quot;) public void sendMessage(String message)&#123; processor.output().send(MessageBuilder.withPayload(message).build()); &#125;&#125; 注：这里的Processor继承了Source与Sink，可以参考Processor的结构定义自己的配置类，与配置文件中自定义的output(myoutput)对应 消费者依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; 配置123456789101112131415161718192021222324252627spring: cloud: stream: bindings: input: destination: testStreamExchange #要和output的destination一致, 这样才能将队列和写入消息的exchange关联起来 binder: local_rabbit group: testStreamQueue binders: local_rabbit: type: rabbit environment: spring: rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest rabbit: bindings: input: consumer: requeue-rejected: false # 是否支持重新放回队列 acknowledge-mode: MANUAL # 接收模式是手工接收 recovery-interval: 3000 # 服务断开,3秒钟重连 durable-subscription: true # 是否启用持久化订阅 max-concurrency: 5 # 最大的监听数 监听类123456789101112131415161718192021@Component@EnableBinding(Processor.class)public class Listener &#123; private Logger log = LoggerFactory.getLogger(Listener.class); @StreamListener(Processor.INPUT) public void process(Message message)&#123; log.info(&quot;&#123;&#125;: message is &#123;&#125;&quot;, this.getClass().getSimpleName(), message); MessageHeaders headers = message.getHeaders(); Channel channel = (Channel) headers.get(AmqpHeaders.CHANNEL); Long deliveryTag = (Long) message.getHeaders().get(AmqpHeaders.DELIVERY_TAG); try &#123; assert channel != null; channel.basicAck(deliveryTag, false); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 注：这里的Processor继承了Source与Sink，可以参考Processor的结构定义自己的配置类，与配置文件中自定义的input(myinput)对应\\ 关于Channel如果每一次访问RabbitMQ都建立一个Connection，在消息量大的时候建立TCP Connection的开销将是巨大的，效率也较低。Channel是在connection内部建立的逻辑连接，如果应用程序支持多线程，通常每个thread创建单独的channel进行通讯，AMQP method包含了channel id帮助客户端和message broker识别channel，所以channel之间是完全隔离的。Channel作为轻量级的Connection极大减少了操作系统建立TCP connection的开销我们在消费这边编写两个监听器监听同一个队列 12345678910111213141516171819202122232425262728293031323334353637@Component@EnableBinding(Processor.class)public class Listener &#123; private Logger log = LoggerFactory.getLogger(Listener.class); private Channel channel = null; @StreamListener(Processor.INPUT) public void process(Message message)&#123; deal(message); &#125; @StreamListener(Processor.INPUT) public void processTwo(Message message)&#123; deal(message); &#125; private void deal(Message message) &#123; log.info(&quot;&#123;&#125;: message is &#123;&#125;&quot;, this.getClass().getSimpleName(), message); MessageHeaders headers = message.getHeaders(); Channel channel = (Channel) headers.get(AmqpHeaders.CHANNEL); if (this.channel == null)&#123; this.channel = channel; &#125;else&#123; log.info(&quot;&#123;&#125;&quot;, channel == this.channel); &#125; Long deliveryTag = (Long) message.getHeaders().get(AmqpHeaders.DELIVERY_TAG); try &#123; assert channel != null; channel.basicAck(deliveryTag, false); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 生产者发送消息（多次）可以看到发送一次消息两个监听器同时被触发，与纯rabbitmq不同（纯rabbitmq是轮询），并且第一次判断为true，证明一个接收通道（input）只使用同一个channel，监听同一个接收通道与监听同一个队列是不同的概念。而且可以发送当两（多）个监听器监听同一个接收通道时，会导致线程死掉，重新生成channel。","categories":["Spring Cloud"]},{"title":"Spring Boot整合Activiti笔记","path":"/2025/01/07/Spring Boot整合Activiti笔记/","content":"流程修改了，如何使之前的任务转到新的流程中act_re_procdef中找到要更新的流程记录根据version来判断版本，这里上一版本id值为askForLeave1:2:72505，最新版本的id_值为：askForLeave1:1:67505 更新如下表中的记录update act_ru_task set proc_def_id_ &#x3D; ‘askForLeave1:2:72505’ where proc_def_id_ &#x3D; ‘askForLeave1:1:67505’;update act_hi_taskinst set proc_def_id_ &#x3D; ‘askForLeave1:2:72505’ where proc_def_id_ &#x3D; ‘askForLeave1:1:67505’;update act_hi_procinst set proc_def_id_ &#x3D; ‘askForLeave1:2:72505’ where proc_def_id_ &#x3D; ‘askForLeave1:1:67505’;update act_hi_actinst set proc_def_id_ &#x3D; ‘askForLeave1:2:72505’ where proc_def_id_ &#x3D; ‘askForLeave1:1:67505’;update act_ru_execution set proc_def_id_ &#x3D; ‘askForLeave1:2:72505’ where proc_def_id_ &#x3D; ‘askForLeave1:1:67505’; 将任务修改为最新流程的前提是，最新的流程和上一版本的流程的节点不能有变化，不然会导致逻辑错误。 设置会签任务 在流程图中添加一个任务，并且设置以下属性 Sequential：执行顺序，true表示多实例顺序执行，false表示多实例并行。 Loop Cardinality：循环基数，选填，会签人数。 Completion Condition：完成条件，Activiti预定义了3个变量，可以在UEL表达式中直接使用，可以根据表达式设置按数量、按比例、一票通过、一票否定等条件。 nrOfInstances：总实例数，Collection中的数量。 nrOfCompletedInstances：已经完成的实例数。 nrOfActiveInstances：表示当前处于活动状态（尚未完成或取消）的实例数量 nrOfActiveTokens：对于并行执行的多实例，表示当前正在执行的令牌数量。 Collection：任务处理人集合（Assignee）集合，可以在启动实例时赋值变量。 Element Variable：任务处理人定义，必须和Assignee一样。 或者直接编写xml，填入如下代码（此为实例，根据实际情况修改） 123&lt;multiInstanceLoopCharacteristics activiti:collection=&quot;workers&quot; activiti:elementVariable=&quot;worker&quot; isSequential=&quot;false&quot;&gt; &lt;completionCondition&gt;$&#123;nrOfCompletedInstances/nrOfInstances &gt;= 0.5&#125;&lt;/completionCondition&gt;&lt;/multiInstanceLoopCharacteristics&gt;","categories":["Activiti流程引擎"]},{"title":"Nacos集群搭建","path":"/2025/01/07/Nacos集群搭建/","content":"官网地址 数据库配置Mysql准备nacos集群需要使用Mysql数据库替换掉原来的单机derby数据库 直接在数据库导入nacos安装目录conf目录下的nacos-mysql.sql即可 导入成功后，会生成以下表 Nacos配置Mysql数据库打开nacos安装目录conf\\application.properties进行配置，所有nacos节点都 1234567spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://127.0.0.1:3306/nacos?characterEncoding=utf8&amp;connectTimeout=10000&amp;socketTimeout=30000&amp;autoReconnect=true&amp;serverTimezone=UTCdb.user.0=rootdb.password.0=123456 Nacos配置Nacos节点配置打开nacos安装目录conf\\application.properties进行配置 12server.port=8858nacos.inetutils.ip-address=127.0.0.1 server.port：配置节点端口，节点访问端口和集群配置端口都是这个端口 nacos.inetutils.ip-address：配置节点ip，这里不是指只有这个ip可以访问，只是在集群配置中识别这个ip，因为一个节点机器可能不止一个ip，所以需要这个配置控制一个ip作为集群ip Nacos集群配置将nacos安装目录conf子目录下的cluster.conf.example复制一份并重命名为cluster.conf，打开进行配置 打开cluster.conf，配置nacos所有节点的地址 123127.0.0.1:8858127.0.0.1:8868127.0.0.1:8878 Nginx配置nacos集群并没有提供一个统一对外的地址，所以使用nginx做负载均衡 打开nginx安装目录conf ginx.conf，进行配置，upstream中的ip使用每个节点的nacos.inetutils.ip-address配置 1234567891011121314151617181920212223242526upstream nacos &#123; server 127.0.0.1:8858; server 127.0.0.1:8868; server 127.0.0.1:8878; &#125;server &#123; listen 8848; server_name localhost; #proxy_redirect http://localhost:8081 http://116.228.152.154:28081; location /nacos &#123; fastcgi_hide_header Access-Control-Allow-Origin; proxy_hide_header Access-Control-Allow-Origin; add_header Access-Control-Allow-Origin *; proxy_pass http://nacos; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_send_timeout 360; proxy_read_timeout 360; proxy_connect_timeout 60;\t&#125; &#125; 浏览器使用8848访问nacos即可 Nacos使用Mysql刚开始的时候在想，为什么nacos要用mysql存储，既然用mysql存储又何来用raft保证一致性一说，后面发现nacos集群搭建的mysql数据库是为了存储配置管理中的配置数据，以及nacos本身的基础数据，而像服务、实例等信息还是存储在内存或者本地磁盘的，临时实例只存储在内存中，非临时实例会持久化到磁盘","categories":["Spring Cloud相关中间件"]},{"title":"Mysql-记录锁、间隙锁、临键锁","path":"/2025/01/07/Mysql-记录锁、间隙锁、临键锁/","content":"介绍间隙锁的一篇博客我们先准备一张测试表 1234567CREATE TABLE `test` ( `id` int(11) NOT NULL AUTO_INCREMENT, `a` int(255) DEFAULT NULL, `b` int(255) DEFAULT NULL, PRIMARY KEY (`id`), KEY `a` (`a`)) ENGINE=InnoDB AUTO_INCREMENT=11 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci; id为主键；a为普通索引；b为普通列； 再准备一些数据 先看下目前a索引上的数据（不是真实的索引结构） 普通索引等值查询sql语句 123begin;select * from test where a = 6 for update;end; &#x2F;&#x2F;解释：进行查询并加排他锁 运行下面语句查看加锁信息（所有的锁都是加在索引上的，这一点很重要） 1select * from performance_schema.data_locks; 结果&#x2F;&#x2F;这是我认为比较重要的信息，没有将所有内容截取下来 LOCK_DATA代表锁住的索引，where a &#x3D; 6这条数据走的是a索引的（6，8）这条索引，所以a索引的（6，8）被锁住了，第三行的（8）代表这条主键索引被锁住了，可能和回表的机制有关系，第四行是本次的重点：间隙锁 测试： 1update test set b = 7 where a = 6; 相当于修改该索引的值，由于写锁的存在，所以修改失败 1234567update test set a = 3 where id = 9; //成功update test set a = 5 where id = 9; //失败；被锁住了update test set a = 7 where id = 7; //成功update test set a = 9 where id = 7; //失败；被锁住了 可以得出结论，查询到的索引和的前一个索引以及后一个索引之间不允许插入新的索引（要明白和插入数据的区别）&#x2F;&#x2F;注：这里我们直接修改原始的id（id为9和id为7）的数据，这里只考虑顺序性，与具体的id无关* 这里需要强调一下，间隙锁是指索引之间的范围，不具体指哪条索引，间隙锁没有锁住任何一条索引，它锁住的是一个范围，所以查询到的索引的前后的索引是可以改变的，锁住的范围为（（4，9），（8，7）），即该范围内的索引不能发生变化，这里可以发现，两边都是开区间，所以（4，9）和（8，7）作为边缘值，是可以发生变化的 123delete from test where id = 7; //执行成功delete from test where id = 9; //执行成功 索引结构变为同时间隙锁的范围也发生变化了，范围变成了（（2，10），（10，6）） 普通索引等值查询（存在多条语句，即有多个索引）先改变一下数据sql语句 12begin;select * from test where a = 10 for update; 加锁的情况 和只查询一个条件的时候没有区别，所以查询出来的索引都加上了排它锁，最后一个索引的后一个索引加上了gap锁（间隙锁），锁住的范围为（（8，7），（14，4）） 普通索引等值查询（查询条件不存在）sql语句 123begin;select * from test where a = 11 for update; //该记录不存在end; 加锁情况 那么间隙锁的范围：加锁范围为（（10，6），（12，5）） 普通索引范围查询SQL语句 12begin;select * from test where a between 4 and 12 for update; 加锁信息 不难看出，与上面的区别在于索引（14，4）的锁类型从（X,GAP）变成了（X）,意味着所以（14，4）变成了排它锁，则锁住的范围是（（2，10），（14，4）]，由于查询到的最后一个索引的下一个索引，从gap变成排他锁，所以右边变成了闭区间，成了临键锁，需要注意，包括’&gt;’和’&lt;’等操作也是一样的 普通索引范围查询（查询不到索引）数据SQL语句 12begin;select * from test where a BETWEEN 8 and 9 for update; 锁信息可以看出，和等值查询（查询不到索引）的区别在于，范围查询会将下一个索引加上排它锁，锁住的范围为（（10，6），（12，5）] 总结我们不难发现，范围查询和等值查询的区别在于，范围查询会将查询到的最后一个索引的下一个索引也加上排他锁，导致整个间隙锁的范围向右加了一个索引的范围，而整个范围的左右没办法做新增索引的操作的，其实不能做新增索引操作的是范围是，所有加上排它锁的索引的左右 记录锁就是查询到的记录上的锁，间隙锁就是加入排它锁索引的左右，临键锁就是记录锁和间隙锁的集合 主键（唯一索引）等值查询sql语句 12begin;select * from test where id = 10 for update; 加锁信息 范围查询sql语句 12begin;select * from test where id BETWEEN 8 and 12 for update; 加锁信息&#x2F;&#x2F;画红线的地方是一个bug，8.0.22之后，将无法访问到不满足条件的第一个值 总结不难发现，主键（唯一索引）与普通索引的区别在于最左边，失去了间隙锁的功能，等值查询例子中，id &#x3D; 10的索引的左右都可以新增索引，因为（X）变成了（X,REC_NOT_GAP），而且失去了下一个索引的（X,GAP），而在范围查询中，8的左边不能新增索引，即最左边索引的（X）退化成了（X,REC_NOT_GAP），同时失去了最右边的间隙锁，可以认为相比较之下，唯一索引失去了保护左右的能力 整体总结个人觉得可以这么认为，（X）拥有保护自己和左边的作用，（X,REC_NOT_GAP）只能保护自己，不能保护左边，（X,GAP）可以保护左边，但不能保护自己，而且它是伴随着（X）出现的，所以持有（X,GAP）的索引可以发生变化（比如持有（X,GAP）的索引被删除，则接替他位置的持有（X,GAP）），按照这个原则，可以很好的解释上面的情况，不过这是我自己根据实验现象得出的，不一定准确，可能有其他的影响因素，（X）就是临键锁，（X,REC_NOT_GAP）是记录锁，（X,GAP）是间隙锁，可以理解为后两者都是前者退化而来 临键锁的前开后闭临键锁的前开后闭是指查询的索引的前一个索引是开，后一个是闭例如：where a &gt;10 and a &lt; 12（假设10的索引和12的索引存在），那么临键锁就是(10,12] **两个原则以及两个优化原则1：加锁的基本单位是 next-key lock。next-key lock 是前开后闭区间。原则2：查找过程中访问到的对象才会加锁。优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。 8.0.22之后已修复，故唯一索引上的范围查询，第一个满足条件和最后一个满足条件的索引会退化为行锁**关于两个优化 我们可以认为只需要考虑等值查询的情况，非等值查询一律按照普通的next-key处理，查询到的索引和向右遍历最后一个不满足等值条件的索引会被加上行锁，而当等值查询时，向右遍历最后一个不满足等值条件的索引的行锁会消失，并且当走的是唯一索引的时候，间隙锁也会消失，只剩行锁 我们知道，在查询操作时，索引是向右遍历的，当遇到第一个不满足条件的索引时，结束查询，并未该索引加上行锁，但是如果使等值查询，该锁便不会加行锁了，并且如果该索引是唯一索引时，两边的间隙锁也会消失","categories":["数据库"]},{"title":"Spring事务导致@DS不生效","path":"/2025/01/07/Spring事务导致@DS不生效/","content":"参考文章：https://blog.csdn.net/PyongSen/article/details/125421724 问题代码1234@Transactional(rollbackFor = Exception.class)public Boolean feedback(String worderid, String currstatus)&#123; return redrOrderService.upMidData() &gt; 0;&#125; 12345@DS(&quot;hty&quot;)public int upMidData() &#123; String sql = &quot;select * from test&quot;; return jdbcTemplate.query(sql);&#125; 结果从上图可以看出，调用了push方法，说明@DS产生的拦截器已经生效了，但是整个过程并没有执行peek，说明并没有切换数据源，后面报错找不到表也证明了这一点 原因 如果不存在事务（这里指整个过程都没有事务，因为一旦某个方法开启事务，不设置的话，这个事务会沿着方法调用链一直传递下去），每次调用service层方法或者mapper层方法，都会从数据库连接池获取数据库连接，所以搭配@DS可以设置成我们想要的数据源（@DS本质是通过拦截器生效的） 如果存在事务，则只会在事务开启时从数据库连接池获取数据库连接，并且事务和数据库连接绑定了，继续往下执行，也不会从数据库连接池获取数据库连接，即使使用了@DS，也只加一层拦截器而已，并不能切换数据库连接 平时我们切换数据源都是直接使用@DS，但是它本身并没有切换数据源的作用，spring boot 整合 mybatis plus环境下，系统每次从数据库连接池获取数据库连接时，都会从DynamicDataSourceContextHolder类中获取最新的数据源名，如果没有则使用默认数据源，而@DS的作用则是通过拦截器在设置数据库连接之前设置最新的数据源名，DynamicDataSourceContextHolder类中有一个队列，存储数据源名，并且由于队列的特点，允许@DS多层设置 解决在方法上加入@Transactional(propagation &#x3D; Propagation.REQUIRES_NEW) 1234@Transactional(rollbackFor = Exception.class)public Boolean feedback(String worderid, String currstatus)&#123; return redrOrderService.upMidData() &gt; 0;&#125; 123456@DS(&quot;hty&quot;)@Transactional(propagation = Propagation.REQUIRES_NEW)public int upMidData() &#123; String sql = &quot;select * from test&quot;; return jdbcTemplate.query(sql);&#125; @Transactional不生效 被同一个对象的方法调用，@Transactional(propagation &#x3D; Propagation.REQUIRES_NEW)不会生效，此时可以在在该类中引入该类的父类接口，不能直接引入该类的对象，会造成循环依赖，通过父类的对象调用，可以实现不在同一个对象中调用的效果，特别注意，用this调用是不行的。此外，还可以使用AopContext.currentProxy()方法 用在非public方法上 @DS最终是如何生效的我们知道@DS通过拦截器，设置当前的数据源，上面提到过每次从数据库连接池获取数据库连接时，都会从DynamicDataSourceContextHolder类中获取最新的数据源名，而这个就是在com.baomidou.dynamic.datasource.DynamicRoutingDataSource#getDataSource中实现的 123456789101112131415public DataSource getDataSource(String ds) &#123;if (StringUtils.isEmpty(ds)) &#123; return this.determinePrimaryDataSource();&#125; else if (!this.groupDataSources.isEmpty() &amp;&amp; this.groupDataSources.containsKey(ds)) &#123; log.debug(&quot;从 &#123;&#125; 组数据源中返回数据源&quot;, ds); return ((DynamicGroupDataSource)this.groupDataSources.get(ds)).determineDataSource();&#125; else if (this.dataSourceMap.containsKey(ds)) &#123; log.debug(&quot;从 &#123;&#125; 单数据源中返回数据源&quot;, ds); return (DataSource)this.dataSourceMap.get(ds);&#125; else if (this.strict) &#123; throw new RuntimeException(&quot;不能找到名称为&quot; + ds + &quot;的数据源&quot;);&#125; else &#123; return this.determinePrimaryDataSource();&#125;&#125; 这个方法根据不同的数据源名称，返回不同的数据源，是在determineDataSource中调用的com.baomidou.dynamic.datasource.DynamicRoutingDataSource#determineDataSource 123public DataSource determineDataSource() &#123; return this.getDataSource(DynamicDataSourceContextHolder.peek());&#125; determineDataSource方法是获取DynamicDataSourceContextHolder中最新的数据源名称，是在com.baomidou.dynamic.datasource.AbstractRoutingDataSource#getConnection()中调用的 123public Connection getConnection() throws SQLException &#123;return this.determineDataSource().getConnection();&#125; AbstractRoutingDataSource是DataSource的抽象实现，代码中DataSource调用getConnection的时候，最后调用的就是AbstractRoutingDataSource的getConnection方法，实现了动态切换数据源的效果DynamicRoutingDataSource继承了AbstractRoutingDataSource，determineDataSource是AbstractRoutingDataSource的抽象方法 为什么和事务有关系既然动态切换是在getConnection中实现的，为什么通过jdbcTemplate时会和事务有关系，按道理jdbcTemplate在获取connection时就可以动态切换了，jdbcTemplate获取连接时，调用的以下方法org.springframework.jdbc.datasource.DataSourceUtils#doGetConnection 1234567891011121314151617181920212223242526272829303132333435363738public static Connection doGetConnection(DataSource dataSource) throws SQLException &#123; Assert.notNull(dataSource, &quot;No DataSource specified&quot;); ConnectionHolder conHolder = (ConnectionHolder)TransactionSynchronizationManager.getResource(dataSource); if (conHolder == null || !conHolder.hasConnection() &amp;&amp; !conHolder.isSynchronizedWithTransaction()) &#123; logger.debug(&quot;Fetching JDBC Connection from DataSource&quot;); Connection con = fetchConnection(dataSource); if (TransactionSynchronizationManager.isSynchronizationActive()) &#123; try &#123; ConnectionHolder holderToUse = conHolder; if (conHolder == null) &#123; holderToUse = new ConnectionHolder(con); &#125; else &#123; conHolder.setConnection(con); &#125; holderToUse.requested(); TransactionSynchronizationManager.registerSynchronization(new ConnectionSynchronization(holderToUse, dataSource)); holderToUse.setSynchronizedWithTransaction(true); if (holderToUse != conHolder) &#123; TransactionSynchronizationManager.bindResource(dataSource, holderToUse); &#125; &#125; catch (RuntimeException var4) &#123; releaseConnection(con, dataSource); throw var4; &#125; &#125; return con; &#125; else &#123; conHolder.requested(); if (!conHolder.hasConnection()) &#123; logger.debug(&quot;Fetching resumed JDBC Connection from DataSource&quot;); conHolder.setConnection(fetchConnection(dataSource)); &#125; return conHolder.getConnection(); &#125;&#125; 可以看到在获取connection时，会先查看当前是不是事务中，如果是，则直接获取事务的connection，所以上面为什么要新开事务就是这个原因，如果用老的事务，那么connection也是老的事务的，而@DS就无法生效了，而如果没有事务，则通过dataSource.getConnection()获取，mybatis也是同理，这里提一下，事务开启时，会获取一次connection，jdbc事务的基础就是建立在connection上的，如果在事务中，我们在代码里面自己获取connection的话，我们自己获取的connection所做的操作是无法实现事务的效果的","categories":["Spring Boot"]},{"title":"Netty实现HTTP!HTTP2客户端","path":"/2025/01/07/Netty实现HTTP!HTTP2客户端/","content":"普通http&#x2F;https客户端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public class HttpClient &#123; public static void main(String[] args) throws Exception &#123; // 创建EventLoopGroup EventLoopGroup group = new NioEventLoopGroup(); try &#123; // 构建SSL上下文 SslContext sslContext = SslContextBuilder.forClient() .sslProvider(SslProvider.OPENSSL) .trustManager(InsecureTrustManagerFactory.INSTANCE) .build(); // 创建Bootstrap，并配置相关参数 Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.SO_KEEPALIVE, true) .remoteAddress(new InetSocketAddress(&quot;127.0.0.1&quot;, 8080)) .handler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; ch.pipeline() .addLast(sslContext.newHandler(ch.alloc())) // 添加HTTP帧编解码器 .addLast(new HttpClientCodec()) .addLast(new HttpObjectAggregator(1000000)) .addLast(new HttpClientHandler()); &#125; &#125;); // 连接服务器 ChannelFuture channelFuture = bootstrap.connect().sync(); Channel channel = channelFuture.channel(); String url = &quot;/query&quot;; DefaultFullHttpRequest defaultHttpRequest = new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.POST, url); defaultHttpRequest.headers().set(HttpHeaderNames.HOST, &quot;127.0.0.1:8080&quot;); /** * POST /query HTTP/1.1 * Host: 127.0.0.1:8080 * Content-Type: application/x-www-form-urlencoded * * param1=value1&amp;param2=value2 */// 方式一：直接设置content的值// defaultHttpRequest.content().writeBytes(&quot;query=query&quot;.getBytes());// defaultHttpRequest.headers().set(HttpHeaderNames.CONTENT_TYPE, ContentType.FORM_URLENCODED);// defaultHttpRequest.headers().set(HttpHeaderNames.CONTENT_LENGTH, &quot;param1=value1&amp;param2=value2&quot;.length());// channel.writeAndFlush(defaultHttpRequest);// 方式二// HttpPostRequestEncoder httpPostRequestEncoder = new HttpPostRequestEncoder(defaultHttpRequest, false);// httpPostRequestEncoder.addBodyAttribute(&quot;param1&quot;,&quot;value1&quot;);// httpPostRequestEncoder.addBodyAttribute(&quot;param2&quot;,&quot;value2&quot;);// HttpRequest httpRequest = httpPostRequestEncoder.finalizeRequest();// channel.writeAndFlush(httpRequest); /** * POST /your-path HTTP/1.1 * Host: example.com * Content-Type: multipart/form-data; boundary=---------------------------1234567890 * * -----------------------------1234567890 * Content-Disposition: form-data; name=&quot;param1&quot; * * value1 * -----------------------------1234567890 * Content-Disposition: form-data; name=&quot;param2&quot; * * value2 * -----------------------------1234567890 * Content-Disposition: form-data; name=&quot;file&quot;; filename=&quot;example.txt&quot; * Content-Type: text/plain * * This is the content of the file. * -----------------------------1234567890-- */// 直接设置content的值的方式参考上面，下面是通过httpPostRequestEncoder的方式 HttpPostRequestEncoder httpPostRequestEncoder = new HttpPostRequestEncoder(defaultHttpRequest, true); httpPostRequestEncoder.addBodyAttribute(&quot;param1&quot;,&quot;value1&quot;); httpPostRequestEncoder.addBodyAttribute(&quot;param2&quot;,&quot;value2&quot;); httpPostRequestEncoder.addBodyFileUpload(&quot;file&quot;,&quot;example.txt&quot;, new File(&quot;C:\\\\Users\\\\pengtong\\\\Desktop\\\\example.txt&quot;), ContentType.TEXT_PLAIN.getValue(), true); HttpRequest httpRequest = httpPostRequestEncoder.finalizeRequest(); channel.write(httpRequest); HttpContent httpContent = httpPostRequestEncoder.readChunk(channel.alloc()); channel.writeAndFlush(httpContent); // 关闭连接 channel.closeFuture().sync(); &#125; finally &#123; // 关闭EventLoopGroup group.shutdownGracefully(); &#125; &#125; @ChannelHandler.Sharable static class HttpClientHandler extends ChannelInboundHandlerAdapter &#123; int i = 0; long start = System.currentTimeMillis(); @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof FullHttpMessage) &#123; System.out.println(((FullHttpMessage)msg).content().toString(CharsetUtil.UTF_8)); System.out.println(System.currentTimeMillis() - start + &quot;----------&quot; + (i++)); &#125; &#125; &#125;&#125; http与https的区别就在于https需要构建一个SslContext，并且通过它生成一个SslHandler添加到channel pipeline中 http升级http2客户端这里面的注释详细介绍到了netty channel pipeline的逻辑 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203public class Http2UpgradeClient &#123; private static final String HOST = &quot;127.0.0.1&quot;; private static final int PORT = 8080; private SendHandler sendHandler = new SendHandler(); public static void main(String[] args) throws Exception &#123; // 创建EventLoopGroup EventLoopGroup group = new NioEventLoopGroup(); try &#123; // 创建Bootstrap，并配置相关参数 Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.SO_KEEPALIVE, true) .remoteAddress(new InetSocketAddress(HOST, PORT)) .handler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new HttpClientHandler()); &#125; &#125;); // 连接服务器 ChannelFuture channelFuture = bootstrap.connect().sync(); Channel channel = channelFuture.channel(); DefaultFullHttpRequest upgradeRequest = new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.POST, &quot;/query&quot;); upgradeRequest.headers() .add(&quot;HTTP2-Settings&quot;, &quot;&quot;) .add(HttpHeaderNames.UPGRADE, &quot;h2c&quot;) .add(HttpHeaderNames.CONNECTION, &quot;HTTP2-Settings,upgrade&quot;); channel.writeAndFlush(upgradeRequest); // 关闭连接 channel.closeFuture().sync(); &#125; finally &#123; // 关闭EventLoopGroup group.shutdownGracefully(); &#125; &#125; @ChannelHandler.Sharable static class HttpClientHandler extends HttpObjectAggregator &#123; private HttpRequestEncoder httpRequestEncoder; private HttpResponseDecoder httpResponseDecoder; public HttpClientHandler() &#123; super(1024); &#125; @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123; httpRequestEncoder = new HttpRequestEncoder(); httpResponseDecoder = new HttpResponseDecoder(); ctx.pipeline().addBefore(ctx.name(), null, httpRequestEncoder).addBefore(ctx.name(), null, httpResponseDecoder); SendHandler.sendHandler((line) -&gt; &#123; DefaultFullHttpRequest defaultFullHttpRequest = new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.POST, &quot;/query&quot;, Unpooled.wrappedBuffer(line.getBytes())); defaultFullHttpRequest.headers() .add(HttpHeaderNames.CONNECTION, &quot;keep-alive&quot;) .add(HttpHeaderNames.CONTENT_LENGTH, String.valueOf(line.length())); ctx.writeAndFlush(defaultFullHttpRequest); &#125;); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof HttpObject) &#123; List&lt;Object&gt; out = new ArrayList&lt;&gt;(); super.decode(ctx, (HttpObject) msg, out); if (out.isEmpty()) &#123; return; &#125; assert out.size() == 1; FullHttpResponse fullHttpResponse = (FullHttpResponse) out.get(0); if (fullHttpResponse.status() == HttpResponseStatus.SWITCHING_PROTOCOLS) &#123; Http2FrameCodec http2FrameCodec = Http2FrameCodecBuilder.forClient().build(); //httpRequestEncoder放在最前面删除是因为，在http2FrameCodec被添加时，http2FrameCodec会发送一个Http2序言和http2Setting的ByteBuf //如果这里不删除的话，http2FrameCodec发送Http2序言和http2Setting的ByteBuf时，因为httpRequestEncoder在http2FrameCodec前面 //所以Http2序言和http2Setting的ByteBuf会被交给httpRequestEncoder处理，而httpRequestEncoder无法处理ByteBuf，就会出现问题 //而如果在添加http2FrameCodec之前删除的话，http2FrameCodec在发送Http2序言和http2Setting时，这两种消息就会被直接交给HeadContext处理 //当然，如果http2FrameCodec可以被添加到httpRequestEncoder之前，也可以不用删除，因为按照顺序， //http2FrameCodec发送Http2序言和http2Setting的ByteBuf就不会交到httpRequestEncoder处理 ctx.pipeline().remove(httpRequestEncoder); ctx.pipeline().addLast(http2FrameCodec).addLast(new Http2ClientHandler()).remove(this).remove(httpResponseDecoder); //httpResponseDecoder放到最后删是因为删除入站通道处理程序，会直接处理没处理的消息，因为除了升级响应以外， //还有一个Http2Setting，因为httpResponseDecoder处理不了，所以会保持ByteBuf的状态，所以httpResponseDecoder持有三条消息， //分别是httpResponse、lastEmptyContent、以及ByteBuf状态的Http2Setting，但是到现在还只处理到lastEmptyContent //所以这时候删除httpResponseDecoder，ByteBuf状态的Http2Setting还没有处理，所以删除的时候，会将ByteBuf状态的Http2Setting交到下一个handler处理， //调用删除方法时，httpResponseDecoder后面就是http2FrameCodec，而http2FrameCodec可以解析ByteBuf状态的Http2Setting //假设调用的是addFirst(http2FrameCodec)，那么在删除httpResponseDecoder时，http2FrameCodec就在httpResponseDecoder前面 //http2FrameCodec就收不到httpResponseDecoder的ByteBuf状态的Http2Setting，就会出现问题 &#125; &#125; &#125; &#125; @ChannelHandler.Sharable static class Http2ClientHandler extends Http2ChannelDuplexHandler &#123; @Override protected void handlerAdded0(ChannelHandlerContext ctx) throws Exception &#123; SendHandler.sendHandler((line) -&gt; &#123; Http2Headers headers = new DefaultHttp2Headers() .scheme(&quot;http&quot;) .method(&quot;GET&quot;) .path(&quot;/query&quot;) .set(HttpHeaderNames.CONTENT_TYPE, ContentType.JSON.toString(CharsetUtil.UTF_8)) .set(HttpHeaderNames.CONTENT_LENGTH, String.valueOf(line.length())) .authority(HOST); Http2FrameStream stream = newStream(); DefaultHttp2HeadersFrame headersFrame = new DefaultHttp2HeadersFrame(headers).stream(stream); Http2DataFrame http2DataFrame = new DefaultHttp2DataFrame(Unpooled.copiedBuffer(line, CharsetUtil.UTF_8), true).stream(stream); ctx.writeAndFlush(headersFrame); ctx.writeAndFlush(http2DataFrame); &#125;); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof Http2DataFrame) &#123; // 处理HTTP/2响应数据 Http2DataFrame dataFrame = (Http2DataFrame) msg; String content = dataFrame.content().toString(CharsetUtil.UTF_8); System.out.println(&quot;Received response: &quot; + content + &quot; : &quot; + dataFrame.stream().id()); &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125; &#125; static class SendHandler &#123; private Consumer&lt;String&gt; consumer; private final Thread sendThread; private static SendHandler sendHandler; public static SendHandler sendHandler() &#123; if (sendHandler == null) &#123; sendHandler = new SendHandler(); &#125; return sendHandler; &#125; public static SendHandler sendHandler(Consumer&lt;String&gt; consumer) &#123; if (sendHandler == null) &#123; sendHandler = new SendHandler(consumer); &#125; else &#123; sendHandler.setConsumer(consumer); &#125; return sendHandler; &#125; private SendHandler() &#123; this(System.out::println); &#125; private SendHandler(Consumer&lt;String&gt; consumer) &#123; this.consumer = consumer; BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(System.in)); sendThread = new Thread(() -&gt; &#123; try &#123; while (true) &#123; String line = bufferedReader.readLine(); if (Thread.currentThread().isInterrupted()) &#123; break; &#125; this.consumer.accept(line); &#125; &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; &#125;); sendThread.start(); &#125; public void shutdown() &#123; sendThread.interrupt(); &#125; public void setConsumer(Consumer&lt;String&gt; consumer) &#123; this.consumer = consumer; &#125; &#125;&#125; 这部分代码整体逻辑就是客户端提交一个http2的升级请求，如果返回的响应的状态码是101，则后续通过http2的逻辑发送请求以及接收响应。netty本身已经实现了一个HttpClientUpgradeHandler类，实现逻辑大致和这部分代码类似 http2客户端这里的http2客户端没有使用加密，按道理一般的http2默认是加密的，这里的代码使用到了Http2StreamChannelBootstrap和Http2StreamChannel，可参考学习 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public class Http2Client &#123; private static final String HOST = &quot;127.0.0.1&quot;; private static final int PORT = 8080; public static void main(String[] args) throws Exception &#123; // 创建EventLoopGroup EventLoopGroup group = new NioEventLoopGroup(); try &#123; // 创建Bootstrap，并配置相关参数 Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.SO_KEEPALIVE, true) .remoteAddress(new InetSocketAddress(HOST, PORT)) .handler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; ch.pipeline() // 添加HTTP/2帧编解码器 .addLast(Http2FrameCodecBuilder.forClient().build()) //添加Http/2多路复用处理器，new ChannelInboundHandlerAdapter()只有在被动接收信息的时候才生效，例如服务端接收客户端的信息 .addLast(new Http2MultiplexHandler(new ChannelInboundHandlerAdapter())); &#125; &#125;); // 连接服务器 ChannelFuture channelFuture = bootstrap.connect().sync(); Channel channel = channelFuture.channel(); new Thread(() -&gt; &#123; Http2StreamChannelBootstrap http2StreamChannelBootstrap = new Http2StreamChannelBootstrap(channel); BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(System.in)); while (true) &#123; String line; try &#123; line = bufferedReader.readLine(); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; Http2StreamChannel streamChannel = http2StreamChannelBootstrap.open().syncUninterruptibly().getNow(); streamChannel.pipeline().addLast(new Http2ClientHandler()); Http2Headers headers = new DefaultHttp2Headers() .method(&quot;GET&quot;) .path(&quot;/query&quot;) .scheme(&quot;http&quot;) .set(HttpHeaderNames.CONTENT_TYPE, ContentType.JSON.toString(CharsetUtil.UTF_8)) .set(HttpHeaderNames.CONTENT_LENGTH, String.valueOf(line.length())) .authority(HOST); DefaultHttp2HeadersFrame headersFrame = new DefaultHttp2HeadersFrame(headers).stream(streamChannel.stream()); Http2DataFrame http2DataFrame = new DefaultHttp2DataFrame(Unpooled.copiedBuffer(line, CharsetUtil.UTF_8), true).stream(streamChannel.stream()); streamChannel.writeAndFlush(headersFrame); streamChannel.writeAndFlush(http2DataFrame); &#125; &#125;).start(); // 关闭连接 channel.closeFuture().sync(); &#125; finally &#123; // 关闭EventLoopGroup group.shutdownGracefully(); &#125; &#125; @ChannelHandler.Sharable static class Http2ClientHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof Http2DataFrame) &#123; // 处理HTTP/2响应数据 Http2DataFrame dataFrame = (Http2DataFrame) msg; String content = dataFrame.content().toString(CharsetUtil.UTF_8); System.out.println(&quot;Received response: &quot; + content + &quot; : &quot; + dataFrame.stream().id()); ctx.channel().close();//关闭创建的Http2StreamChannel &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125; &#125;&#125; https&#x2F;http2(ssl&#x2F;tls)客户端访问https的http2，需要加上加密，而且还需要配置应用层协议协商（ALPN），并且设置支持的协议包括h2、http&#x2F;1.1，服务端会根据自身配置返回一个支持的协议并且后续按照该协议进行通讯，如果不配置应用层协议协商，那么会按照服务端配置的默认协议进行通讯，这个时候就很有可能出现客户端和服务端协议不一致的问题，比如服务端默认协议是http&#x2F;1.1，而如果这个时候客户端按照http2协议进行请求，当客户端发送setting帧时，收到服务端的消息还是http1.1格式的报文，就会出现问题。除了ALPN，NPN也是协议协商，只是NPN基本被ALPN取代了。下面的代码同时支持http&#x2F;1.1和http2，通过userEventTriggered获取ALPN协商的结果，然后修改客户端支持的协议 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210package com.example.netty.client;import cn.hutool.http.ContentType;import io.netty.bootstrap.Bootstrap;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.*;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.nio.NioSocketChannel;import io.netty.handler.codec.http.*;import io.netty.handler.codec.http2.*;import io.netty.handler.ssl.*;import io.netty.handler.ssl.util.InsecureTrustManagerFactory;import io.netty.util.CharsetUtil;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.net.InetSocketAddress;import java.util.HashMap;import java.util.Map;public class MyHttpClient &#123; private static final String HOST = &quot;127.0.0.1&quot;; private static final int PORT = 8080; public static void main(String[] args) throws Exception &#123; // 创建EventLoopGroup EventLoopGroup group = new NioEventLoopGroup(); // 构建SSL上下文 SslContext sslContext = SslContextBuilder.forClient() .sslProvider(SslProvider.OPENSSL) .trustManager(InsecureTrustManagerFactory.INSTANCE)//如果服务端使用非认证的证书，必须使用该代码 .applicationProtocolConfig(new ApplicationProtocolConfig( ApplicationProtocolConfig.Protocol.ALPN, ApplicationProtocolConfig.SelectorFailureBehavior.NO_ADVERTISE, ApplicationProtocolConfig.SelectedListenerFailureBehavior.ACCEPT, ApplicationProtocolNames.HTTP_1_1, ApplicationProtocolNames.HTTP_2)) .build(); try &#123; // 创建Bootstrap，并配置相关参数 Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.SO_KEEPALIVE, true) .remoteAddress(new InetSocketAddress(HOST, PORT)) .handler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; ch.pipeline() .addLast(sslContext.newHandler(ch.alloc())) // 添加HTTP/2帧编解码器 .addLast(new FrontHandler()); &#125; &#125;); // 连接服务器 ChannelFuture channelFuture = bootstrap.connect().sync(); Channel channel = channelFuture.channel(); new Thread(() -&gt; &#123; BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(System.in)); while (true) &#123; String line; try &#123; line = bufferedReader.readLine(); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; channel.writeAndFlush(line); &#125; &#125;).start(); // 关闭连接，阻塞直到通道关闭 channel.closeFuture().sync(); &#125; finally &#123; // 关闭EventLoopGroup group.shutdownGracefully(); &#125; &#125; static class FrontHandler extends ChannelInboundHandlerAdapter &#123; private final HttpClientCodec httpClientCodec; private final HttpObjectAggregator httpObjectAggregator; private final HttpClientHandler httpClientHandler; private final Http2FrameCodec http2FrameCodec; private final Http2ClientHandler http2ClientHandler; public FrontHandler() &#123; this.httpClientCodec = new HttpClientCodec(); this.httpObjectAggregator = new HttpObjectAggregator(10240); this.httpClientHandler = new HttpClientHandler(); this.http2FrameCodec = Http2FrameCodecBuilder.forClient().build(); this.http2ClientHandler = new Http2ClientHandler(); &#125; @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123; ctx.pipeline().addLast(httpClientCodec, httpObjectAggregator, httpClientHandler); &#125; //sslHandler处理完协议协商后，会触发SslHandshakeCompletionEvent，可以通过SslHandshakeCompletionEvent修改客户端使用协议 @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (evt instanceof SslHandshakeCompletionEvent)&#123; SslHandler sslHandler = ctx.pipeline().get(SslHandler.class); String protocol = sslHandler.applicationProtocol(); if (protocol.equals(ApplicationProtocolNames.HTTP_2)) &#123; ctx.pipeline().remove(httpClientHandler).remove(httpObjectAggregator).remove(httpClientCodec) .addLast(http2FrameCodec, http2ClientHandler) .remove(this); &#125; else &#123; ctx.pipeline().remove(this); &#125; &#125; &#125; &#125; @ChannelHandler.Sharable static class Http2ClientHandler extends Http2ChannelDuplexHandler &#123; private Map&lt;Integer, ByteBuf&gt; byteBufMap = new HashMap&lt;&gt;(); Http2ClientHandler() &#123; &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof Http2DataFrame) &#123; // 处理HTTP/2响应数据 Http2DataFrame dataFrame = (Http2DataFrame) msg; int id = dataFrame.stream().id(); ByteBuf byteBuf = byteBufMap.get(id); if (byteBuf == null)&#123; byteBuf = dataFrame.content(); byteBufMap.put(id, byteBuf); &#125;else&#123; byteBuf.writeBytes(dataFrame.content()); &#125; if (dataFrame.isEndStream())&#123; String content = byteBuf.toString(CharsetUtil.UTF_8); System.out.println(&quot;Received response: &quot; + content + &quot; : &quot; + id); byteBufMap.remove(id); &#125; &#125; &#125; @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123; String message = (String) msg; Http2FrameStream http2FrameStream = newStream(); Http2Headers headers = new DefaultHttp2Headers() .method(&quot;GET&quot;) .path(&quot;/activity/servicetime&quot;) .scheme(&quot;https&quot;) .authority(HOST + &quot;:&quot; + PORT) .set(HttpHeaderNames.CONTENT_TYPE, ContentType.JSON.toString(CharsetUtil.UTF_8)) .set(HttpHeaderNames.CONTENT_LENGTH, String.valueOf(message.length())); DefaultHttp2HeadersFrame headersFrame = new DefaultHttp2HeadersFrame(headers).stream(http2FrameStream); Http2DataFrame http2DataFrame = new DefaultHttp2DataFrame(Unpooled.copiedBuffer(message, CharsetUtil.UTF_8), true).stream(http2FrameStream); ctx.write(headersFrame); ctx.writeAndFlush(http2DataFrame); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125; &#125; @ChannelHandler.Sharable static class HttpClientHandler extends ChannelDuplexHandler &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof FullHttpMessage) &#123; System.out.println(((FullHttpMessage) msg).content().toString(CharsetUtil.UTF_8)); &#125; &#125; @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123; String message = (String) msg; DefaultFullHttpRequest httpRequest = new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.POST, &quot;/activity/servicetime&quot;, Unpooled.wrappedBuffer(message.getBytes())); httpRequest.headers().set(HttpHeaderNames.HOST, HOST + &quot;:&quot; + PORT); httpRequest.headers().set(HttpHeaderNames.CONTENT_LENGTH, message.length()); httpRequest.headers().set(HttpHeaderNames.CONNECTION, &quot;keep-alive&quot;); ctx.writeAndFlush(httpRequest); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); &#125; &#125;&#125; 应用层协议协商是在建立TLS连接时就确定好的，不是在http请求时才确定的，所以在浏览器请求的时候看不到相关的信息，只能通过抓包查看TLS建立连接时的信息查看，下面是浏览器和服务器建立连接时的应用层协议协商，其中client hello是浏览器发送给服务器的，可以看到，浏览器支持h2和http&#x2F;1.1，server hello是服务器发送给浏览器的，可以看到，服务器决定按照h2进行通讯。Application-Layer Protocol Negotiation是ALPN全拼","categories":["Netty"]},{"title":"RabbiMQ集群","path":"/2025/01/07/RabbiMQ集群/","content":"由于 Erlang 语言的分布式特性，RabbitMQ 自然地支持集群部署。RabbitMQ 集群可以提供高可用性、可伸缩性和容错能力。 集群搭建集群搭建有两种方式，一种是通过命令的方式手动添加，一种是通过配置的方式添加无论是命令方式还是配置方式，都需要保证所有节点.erlang.cookie的内容一致，直接复制.erlang.cookie文件，或者复制里面的内容都是可以的，具体路径参考官方文档Windows：%HOMEDRIVE%%HOMEPATH%.erlang.cookieLinux：&#x2F;var&#x2F;lib&#x2F;rabbitmq&#x2F;.erlang.cookie 命令方式123rabbitmqctl stop_apprabbitmqctl join_cluster rabbit@&lt;hostname&gt;rabbitmqctl start_app 通过命令方式需要注意 一是需要注意hostname必须是被加入rabbitmq的主机名，或者说必须是被加入rabbitmq的名字 二是需要配置hosts，因为加入集群，需要可以直接访问到被加入rabbitmq的主机，这里最好每个节点都配置好其他的ip，以避免意外情况，如果只用docker容器，可以通过在启动命令中加入“–link”参数配置容器的hosts 配置方式配置方式可参考https://www.rabbitmq.com/docs/cluster-formation rabbitmq提供了很多种发现机制，比如配置文件里面配置好 12345cluster_formation.peer_discovery_backend = rabbit_peer_discovery_classic_configcluster_formation.classic_config.nodes.1 = rabbit@&lt;hostname1&gt;cluster_formation.classic_config.nodes.2 = rabbit@&lt;hostname2&gt;cluster_formation.classic_config.nodes.2 = rabbit@&lt;hostname3&gt; 通过配置方式需要注意两点 一是和命令方式一样，需要配置hosts，而且集群中每台服务器都配置，以避免意外情况 二是需要注意通过配置文件配置节点，只会在首次启动尝试加入集群，这里的首次启动指的是安装后的首次启动，后发现是mnesia数据库构建之前启动，即如果删除rabbitmq本地mensia数据库后，再次启动也会尝试加入集群。rabbitmq其他发现机制没有该问题，比如使用Consul 集群特点 节点间通信： 集群中的每个节点都是独立的RabbitMQ实例，它们通过网络相互通信。 节点之间共享元数据，如队列、交换器、绑定、用户和权限信息。 队列位置： 当消息被发布到队列时，消息实际只存储在创建队列的节点上。 其他节点上只保留队列的元数据，而不包含消息的实际内容。 消息处理： 消费者可以连接到集群中的任意节点来消费消息。 如果消费者连接的节点不是队列所在的节点，那么该节点会代理请求到队列所在的节点。 高可用性限制： 如果存储有队列的节点发生故障，该队列将变得不可用，直到该节点恢复或重新创建队列。 为了解决这个问题，通常会结合使用镜像队列或其他高可用性策略。 性能优势： 普通集群可以通过水平扩展增加消息处理能力，提高整体吞吐量。 由于消息不跨节点复制，因此减少了网络带宽和存储资源的需求。 需要注意，以上内容中所说的队列仅指普通队列，因为rabbitmq在3.8版本中引入仲裁队列，需要区分开来 节点运行时会保存一份当前存活节点，因意外重新上线后，会尝试从之前保存的存活节点同步信息（这里不是指队列数据，同步队列数据是之后的事），因为最新的元数据肯定在之前存活的节点之一上面，如果同步失败，则无法正常启动 从上面两图可以看出，一个节点存储了queue队列数据信息，一个节点没有存储queue队列数据信息 镜像队列官方参考文档 镜像队列是普通队列的高可用模式，主要是完善了普通集群下，普通队列不同步队列数据的问题，但是也因为数据同步，导致了更大的网络开销 配置镜像队列通过配置策略实现 其中： name：策略名 pattern：模式（正则表达式模式），设置匹配匹配哪些队列，设置“.*”表示匹配全部 apply to：应用于，选择应用于队列还是交换机或者两者都选择， priority：优先级，在多个策略的情况下适用 definition：定义，设置参数。下面列出了可配置的参数，例如针对所有队列有，Max Length，Max Length bytes等，还有针对不同队列的参数。HA mode参数就是经典队列的对象模式：all、exactly、nodesHA sync mode参数就是设置是否自动同步，这里的自动同步针对的是哪些新加入的节点，以及重新上线的节点（重新上线的节点会将队列清空） 特点 主从架构： 每个镜像队列有一个主节点（Master）和零个或多个从节点（Slaves）。 所有对队列的操作首先发生在主节点上，然后由主节点将操作的结果同步到所有从节点。 主节点负责处理队列的写入（发布）和读取（消费）操作。 Policy配置： 镜像队列通常是通过策略（Policy）在RabbitMQ中配置的。 策略可以指定队列的镜像级别，比如可以设置队列必须在所有节点上镜像，或者只在特定数量的节点上镜像。 高可用性： 如果主节点发生故障，RabbitMQ会自动选择一个从节点作为新的主节点，从而保证了队列的连续可用性。但是对于未同步的从节点成为新的主节点受很多条件和参数控制，比如当主动关闭主节点时，未同步的从节点无法升级为主节点 性能考量： 尽管镜像队列提高了高可用性，但同时也增加了网络通信和磁盘I&#x2F;O的开销，因为每条消息都需要在多个节点间复制。 因此，镜像队列的使用应该基于对高可用性和性能需求的平衡。 宕机清空： 当一个节点下线，然后恢复上线之后，它保存的所有从队列的镜像数据都会丢失，这是为了防止发生了网络分区等情况导致的数据问题。如果此时设置HA sync mode参数为automatic，那么会自动同步，如果设置为manual，那么需要技术人员衡量是否同步老数据。在同步的问题上，新加入的节点同理 一致确认 当生产者开启confirm或者事务时，提交到rabbitmq的消息需要应用到所有节点才会返回确认给生产者 同步阻塞 当队列进行同步操作时，队列上的其他行为都将被阻塞 除了上面这些，还有几点 rabbitmq 创建镜像策略的时候不会对宕机节点上已经存在的队列生效，宕机节点重新上线后也不会生效 rabbitmq 镜像的节点关系可以对换，如果主节点掉线，镜像节点会升级为主节点，如果前主节点重新上线，将会成为镜像节点 从上面两图可以看出，之前没有队列的节点，也存在队列了 仲裁队列官方参考文档 在镜像队列最新官方文档最上方提到了镜像队列已被弃用，被仲裁队列所代替。RabbitMQ 的仲裁队列（Quorum Queue）是自版本 3.8.0 引入的一种高可用性队列类型，它作为镜像队列（Mirrored Queue）的替代方案，提供了改进的数据复制和恢复能力。仲裁队列的设计目标是减少故障转移时间，使用Raft协议提升队列的高可用性和数据的安全性。 创建 创建仲裁队列只需在创建队列时，选择type为quorum即可 如果是Spring RabbitMQ，则通过设置参数”x-queue-type”即可 12345@Bean(TEST_QUORUM)public Queue testQuorum()&#123; Map&lt;String, Object&gt; param = MapBuilder.create(new HashMap&lt;String, Object&gt;()).put(&quot;x-queue-type&quot;, &quot;quorum&quot;).build(); return new Queue(TEST_QUORUM, true, false, false, param);&#125; 特点镜像队列很多特点与镜像队列一致，比如主从架构、高可用性、数据冗余和一致性等，但是解决了镜像队列很多问题，比如上面提到的宕机清空、一致确认、同步阻塞等，并且提供了一些新的特性 宕机不清空 基于raft算法的特性，仲裁队列不需要考虑网络分区等意外情况，所以它不需要像镜像队列一样在节点上线时清空数据，而只需要根据主节点的信息，在原来信息的基础上，同步增量的信息即可。不过新加入集群的节点需要像镜像队列一样同步 一致确认简化 基于raft算法的特性，仲裁队列的生产者确认机制不再需要应用到所有节点上在返回个生产者，只需要应用于法定节点（根据raft算法，一般是节点的一半（向上取整）），就可以返回给生产者 同步不阻塞 仲裁队列优化了镜像队列同步阻塞的问题，节点下线重新上线后的同步不会阻塞节点 有害消息处理 对于多次消费者消费失败的消息，仲裁队列会识别出来，消息将被删除或死信（如果配置了死信交换机），这种机制类似于rocketmq 严格磁盘保存 仲裁队列在执行任何操作之前将所有数据保存到磁盘 存活节点数量要求 由于raft算法的要求，仲裁队列存活的节点数量必须达到raft算法法定数量才能使用，否则不可用，如果无法恢复到raft算法法定数量，则改仲裁队列永久不可用 一致性问题 因为仲裁队列的发布确认模式，只需要应用于法定数量就可以返回，所以写操作并非强一致性的，而是通过raft算法中的一些其他约定来保证一致性但是仲裁队列主节点选举时是不可用的，这一操作是强一致性的，并且由于raft算法的特性，主节点选举往往需要一定的时间","categories":["RabbitMQ"]},{"title":"Wireshark","path":"/2025/01/07/Wireshark/","content":"适配器捕获对于Wireshark无法捕获的适配器，可能是因为适配器本身配置问题，需要下面的配置需要打开，Wireshark才能捕获到 捕获https以及http2(ssl&#x2F;tls)参考文档:https://zhuanlan.zhihu.com/p/700758636 因为ssl&#x2F;tls涉及到加密，所以正常情况下Wireshark无法捕获到，会出现下面的情况 这是因为ssl是加密了的，无法访问到具体内容，也就无法确定使用的协议，这个时候可以使用浏览器的ssl日志功能实现查看，通过设置SSLKEYLOGFILE环境变量，浏览器在访问SSL&#x2F;TLS网站时将对应的密钥保存到本地文件中，有了这个日志文件之后Wireshark就可以将报文进行解密了，这里环境变量的设置方法就不举例了，设置完重启浏览器即可（最好使用谷歌或者火狐浏览器） 设置完环境变量后，就是设置Wiresharkle，设置打开菜单栏“编辑”——“首选项”——“Protocols”——“TLS”，将文件路径设置为上面系统环境变量SSLKEYLOGFILE设置的路径 除了上面这一步，我本地发现还需要配置另一步才生效，除了TLS，还需要配置http的ssl&#x2F;tls的端口为实际的端口 配置完成后，再访问https或者http2(ssl&#x2F;tls)后，就发现Wireshark可以正常解析","categories":["软件使用"]},{"title":"Spring Boot整合RabbitMQ","path":"/2025/01/07/Spring Boot整合RabbitMQ/","content":"依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 生产者配置123456server.port=8091#这里容易和15672搞混 15672是rabbitmq web管理插件的http端口spring.rabbitmq.addresses=127.0.0.1:5672spring.rabbitmq.username=guestspring.rabbitmq.password=guest 配置类这个类主要用于配置rabbitmq的交换机、队列和路由绑定，不一定需要配置在生产者端，可以单独实现一个配置端，也可以直接在rabbitmq端配置好而不需要额外的配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Configurationpublic class TopicRabbitConfig &#123; //绑定键 private final static String MAN = &quot;topic.man&quot;; private final static String WOMAN = &quot;topic.woman&quot;; private final static String EXCHANGE = &quot;topicExchange&quot;; @Bean(MAN) public Queue manQueue() &#123; // name:队列名称 // durable:是否持久化,默认是false,持久化队列：会被存储在磁盘上，当消息代理重启时仍然存在，暂存队列：当前连接有效 // exclusive:默认也是false，代表是否独占，如果未true，只能被当前创建的连接使用，而且当连接关闭后队列即被删除。此参考优先级高于durable // autoDelete:是否自动删除，当没有生产者或者消费者使用此队列，该队列会自动删除。 return new Queue(TopicRabbitConfig.MAN, true, false, false); &#125; @Bean(WOMAN) public Queue womanQueue() &#123; return new Queue(TopicRabbitConfig.WOMAN); &#125; @Bean(EXCHANGE) TopicExchange exchange() &#123; // name:交换机名称 // durable:是否持久化,默认是false,持久化队列：会被存储在磁盘上，当消息代理重启时仍然存在，暂存队列：当前连接有效 // autoDelete:是否自动删除，当没有生产者或者消费者使用此队列，该队列会自动删除。 return new TopicExchange(EXCHANGE, true, false); &#125; //#匹配零个或多个单词,*匹配单个单词 //将firstQueue和topicExchange绑定,而且绑定的键值为topic.man //这样只要是消息携带的路由键是topic.man,才会分发到该队列 @Bean Binding bindingExchangeMessage(@Qualifier(MAN) Queue queue, @Qualifier(EXCHANGE) TopicExchange exchange) &#123; return BindingBuilder.bind(queue).to(exchange).with(MAN); &#125; //#匹配零个或多个单词,*匹配单个单词 //将secondQueue和topicExchange绑定,而且绑定的键值为用上通配路由键规则topic.# //这样只要是消息携带的路由键是以topic.开头,都会分发到该队列 @Bean Binding bindingExchangeMessage2(@Qualifier(WOMAN) Queue queue, @Qualifier(EXCHANGE) TopicExchange exchange) &#123; return BindingBuilder.bind(queue).to(exchange).with(&quot;topic.#&quot;); &#125;&#125; 发送消息类12345678910111213141516171819202122@RestControllerpublic class TopicSender &#123; @Autowired private RabbitTemplate rabbitTemplate; @GetMapping(&quot;/send&quot;) public void send(String messageStr, String routingKey)&#123; String messageId = String.valueOf(UUID.randomUUID()); String messageData = &quot;test message, hello!&quot;; String createTime = LocalDateTime.now().format(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;)); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;messageId&quot;, messageId); map.put(&quot;messageData&quot;, messageData); map.put(&quot;createTime&quot;, createTime); map.put(&quot;sex&quot;,&quot;man&quot;); map.put(&quot;message&quot;, messageStr); String message = JSON.toJSONString(map); //将消息携带绑定键值：TestDirectRouting 发送到交换机TestDirectExchange rabbitTemplate.convertAndSend(&quot;topicExchange&quot;, routingKey, message); &#125;&#125; 消费者配置12345678server.port=8092spring.application.name=rabbit-consumerspring.rabbitmq.addresses=127.0.0.1:5672spring.rabbitmq.username=guestspring.rabbitmq.password=guest#开启手动签收spring.rabbitmq.listener.simple.acknowledge-mode=manual 监听类1234567891011121314151617181920212223242526@Componentpublic class TopicManReceiver &#123; private Logger log = LoggerFactory.getLogger(TopicManReceiver.class); @RabbitListener(queues = &quot;topic.man&quot;) public void processMan(Message message, Channel channel) &#123; log.info(&quot;man message is &#123;&#125;&quot;, message); try &#123; //参数一：签收消息的编号 参数二：是否批量签收，比如签收了编号为4的消息，但是前面的0，1，2，3 都没有签收，则MQ若是批量的签收，它会把0，1，2，3 都签收 channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @RabbitListener(queues = &quot;topic.woman&quot;) public void processWoman(Message message, Channel channel) &#123; log.info(&quot;woman message is &#123;&#125;&quot;, message); try &#123; channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 测试用浏览器访问http://127.0.0.1:8091/send?message=132465&amp;routingKey=topic.man可以看到processMan与processWoman方法同时被触发，这是因为topicExchange与topic.woman队列的绑定键是topic.#，所以topicExchange所有路由键以topic.开头的消息都会被发送到topic.woman队列。关于路由键，举个小例子队列Q1 绑定键为 .TT. 队列Q2绑定键为 TT.#如果一条消息携带的路由键为 A.TT.B，那么队列Q1将会收到；如果一条消息携带的路由键为TT.AA.BB，那么队列Q2将会收到；用浏览器访问http://127.0.0.1:8091/send?message=132465&amp;routingKey=topic.woman我们可以看到只有processWoman被触发，因为消息不会被发送到topic.man队列上了注：若队列中的消息没有被消费者消费，则消息会暂存在队列中直到由消费者消费，所以存在消息堆积的情况。上述代码中，设置了手动签收关于手动签收方法：channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); 参数一：签收消息的编号 参数二：是否批量签收，比如签收了编号为4的消息，但是前面的0，1，2，3 都没有签收，则MQ若是批量的签收，它会把0，1，2，3 都签收 channel.basicReject(tag, false); 参数一：签收消息的编号 参数二：失败后消息不重新放回队列 @RabbitListener当@RabbitListener放在类上时 1234567891011121314151617@Component@RabbitListener(queues = &quot;topic.woman&quot;)public class TopicWomanReceiver &#123; private Logger log = LoggerFactory.getLogger(TopicWomanReceiver.class); @RabbitHandler public String process(Message message, Channel channel) &#123; log.info(&quot;woman message is &#123;&#125;&quot;, message); try &#123; channel.basicAck((Long)message.getHeaders().get(AmqpHeaders.DELIVERY_TAG), false); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return &quot;hello world,too&quot;; &#125;&#125; 生产者发送消息可以看到，因为监听方法接受的参数类型为Message，程序报了无法处理String的错误，但是之前@RabbitListener放在方法上时，监听器是可以处理String类型的消息的，在手动签收的机制下，使用Message是必须的，所以手动签收下将@RabbitListener放在类上不可行","categories":["RabbitMQ"]},{"title":"Http2 Header头部压缩算法","path":"/2025/01/07/Http2 Header头部压缩算法/","content":"前言在这里将结合netty的io.netty.handler.codec.http2.HpackDecoder#decode(io.netty.buffer.ByteBuf, io.netty.handler.codec.http2.HpackDecoder.Http2HeadersSink)方法理解，http2 header头部压缩，使用hpack算法，简单来讲就是使用静态表和动态表对头部进行索引 静态表：静态表就是http2事先约定好的一些常用的头部，比如”:status”, “404”、”accept-encoding”, “gzip, deflate”等。 动态表：而动态表就是在传递数据时，连接双方通过协议约定，将静态表中没有的头部添加到动态表中。动态表的索引值是排在静态表之后的，也就是说动态表的第一个索引值，是静态表最大索引值加一，这样就可以直接传递索引值，而不需要表明时静态表还是动态表。动态表是连接相关联的，也就是说一个服务端口，每有一个http2连接，就有一个动态表，所以同样的两个服务之间，建立的http2连接越少越好，动态表的利用率就越高，动态表的初始大小可以在Setting帧中设置SETTINGS_HEADER_TABLE_SIZE来控制 传递数据的形式http2 header可以传送两种数据，分别是int，和string，也就是数值和字符串 数值如果需要传递某一个的http2 header在静态表或者动态表中存在，那么对于该http2 header只需要传递一个索引值即可 传递的数据由若干个字节组成，一字节有八位，http2 header中每个八位字节可以单独起作用，在表示数值形式时，如果只表示正数的话，一个八位字节可以表示0-255，当然http2 header的八位字节不能八位全部作为数据，在八位字节需要启到不同的作用时，八位中会有不同的高位需要作为标识，而其他的低位作为数据，我们用N代表可以作为数据的位数，至于是哪些情况，N又是多少，下面会详细讲到，比如数值作为索引，数值作为name数据长度等。示例如下图，三个高位作为标识，而五位低位作为数据，即N为5 这种模式就会存在两个情况 八位字节中作为数据的位数足够表示我们需要传递的数值，比如当我们需要传递数值50的时候，而N为5的情况下，能够表示的最大数值为63，那么就足够表示数值50 八位字节中作为数据的位数不足够表示我们需要传递的数值，比如当我们需要传递数值200的时候，而N为5的情况下就不足够表示200,那么这种情况下，就将当前八位字节的数据位全部置为1，表示先当前八位字节能表示的最大值，我们要传递的数值减去该字节最大值剩余的值在后面加入几位进行编码 后续字节的编码规则为，将需要编码的数值用二进制表示，并且将二进制以七位为一组进行分割，从右往左依次放入到后续字节中，是七位而不是八位是因为字节的最高位需要作为标识，判断当前编码是否结束，最后的字节的最高位置为0，表示编码结束，前面字节的最高位置为1。 比如值为200，而N为5的情况下，当前字节数据位全部置为1，表示63，而200-63&#x3D;137，137则在后面添加几个字节进行编码，137的二进制表示为10001001，以七位分割得到1，0001001，按照从右往左依次添加，并且最后一个字节最高位置为0，其余字节最高位置为1的规则，那么后续就需要两个字节，分别为10001001、00000001，我们传递数值200完整的三个字节为???11111、10001001、00000001 下面是netty对数值进行编码的代码实现 123456789101112131415161718private static void encodeInteger(ByteBuf out, int mask, int n, long i) &#123; assert n &gt;= 0 &amp;&amp; n &lt;= 8 : &quot;N: &quot; + n; int nbits = 255 &gt;&gt;&gt; 8 - n; if (i &lt; (long)nbits) &#123; out.writeByte((int)((long)mask | i)); &#125; else &#123; out.writeByte(mask | nbits); long length; for(length = i - (long)nbits; (length &amp; -128L) != 0L; length &gt;&gt;&gt;= 7) &#123; out.writeByte((int)(length &amp; 127L | 128L)); &#125; out.writeByte((int)length); &#125;&#125; 字符串如果某个http2 header不在静态表或者动态表中，那么就会存在一下几种情况 对该header的value没有索引，但是对该header的name有索引，那么只有value涉及到字符串编码 对该header的value和name都没有索引，那么name和value都需要涉及到字符串编码 字符串的编码由两部分组成，第一部分是数值，是字符串长度的数值编码，可以让解码器知道后面的数据中有多少是当前字符串，在这里的数值编码N为7，因为最高位需要标识字符串编码是否使用到了霍夫曼编码，最高位为1标识使用了霍夫曼编码，最高位为0反之，第二部分就是字符串的编码 hpack算法对字符串编码，有两种编码方式，一种是直接编码，即将字符串转为字节数组，另一种是通过霍夫曼编码，使用霍夫曼的前提，字符串的长度大于设定的阈值并且使用霍夫曼编码后的数据小于正常编码 上图就是一个字符串编码的示例，H就是代表是否采用霍夫曼编码，当然实际情况中，字符串部分几乎不可能是一个字节 下面是netty实现的字符串编码 12345678910111213141516171819202122private void encodeLiteral(ByteBuf out, CharSequence name, CharSequence value, HpackUtil.IndexType indexType, int nameIndex) &#123; boolean nameIndexValid = nameIndex != -1; switch (indexType) &#123; case INCREMENTAL: encodeInteger(out, 64, 6, nameIndexValid ? nameIndex : 0); break; case NONE: encodeInteger(out, 0, 4, nameIndexValid ? nameIndex : 0); break; case NEVER: encodeInteger(out, 16, 4, nameIndexValid ? nameIndex : 0); break; default: throw new Error(&quot;should not reach here&quot;); &#125; if (!nameIndexValid) &#123; this.encodeStringLiteral(out, name); &#125; this.encodeStringLiteral(out, value);&#125; 12345678910111213141516private void encodeStringLiteral(ByteBuf out, CharSequence string) &#123; int huffmanLength; if (string.length() &gt;= this.huffCodeThreshold &amp;&amp; (huffmanLength = this.hpackHuffmanEncoder.getEncodedLength(string)) &lt; string.length()) &#123; encodeInteger(out, 128, 7, huffmanLength); this.hpackHuffmanEncoder.encode(out, string); &#125; else &#123; encodeInteger(out, 0, 7, string.length()); if (string instanceof AsciiString) &#123; AsciiString asciiString = (AsciiString)string; out.writeBytes(asciiString.array(), asciiString.arrayOffset(), asciiString.length()); &#125; else &#123; out.writeCharSequence(string, CharsetUtil.ISO_8859_1); &#125; &#125;&#125; http2 header不同情况header索引当header的name和value都有索引的情况下，只需要传递一个数值即可，这种情况数值编码的N为7，并且最高位位1 header增量索引header name有索引在header name有索引的情况下，那么name就由索引值代替，即直接用数值编码，而value则使用字符串编码，由于是增量的，需要标明该header需要添加到动态表，这种情况下name的数值编码的N为6，最高的两位为01 header name无索引在header name无索引的情况下，比如自己自定义了一个header，那么name和value都需要使用字符串编码，由于是增量的，需要标明该header需要添加到动态表，这种情况下该header的第一个字节用于标识，和name有索引的情况一样，字节的最高两位为01，但是后6位为全为0，这个字节后面跟上name和value的字符串编码 header非增量索引非增量索引有两个状态，none和never，这两个状态都不会将索引添加到动态表 header name有索引在header name有索引的情况下，那么name就由索引值代替，即直接用数值编码，而value则使用字符串编码，由于是非增量的，表明该header不添加到动态表，这种情况下name的数值编码的N为4，最高的四位为0000（none）和0001（never） header name无索引在header name无索引的情况下，比如自己自定义了一个header，那么name和value都需要使用字符串编码，由于是非增量的，表明该header不添加到动态表，这种情况下该header的第一个字节用于标识，和name有索引的情况一样，字节的最高的四位为0000（none）和0001（never），但是后4位为全为0，这个字节后面跟上name和value的字符串编码 更新动态表大小除了在Setting 帧中设置SETTINGS_HEADER_TABLE_SIZE，http2 header还可以通过传递一个数值通知更新动态表大小，这个数值的N为7，最高的三位为001，用于标识该数值用于更新动态表表大小 图解下面是不同情况的简单图解，图中所有情况对应的数值编码的N为除最高几位标识符以外的位数，基本文字介绍 索引：指http2 header的name和value有完整的索引 name有索引的增量索引：指http2 header的name有索引，但是value没有索引，会将该header添加到动态表 name无索引的增量索引：指http2 header的name无索引，并且value没有索引，会将该header添加到动态表 name有索引的非增量索引：指http2 header的name有索引，但是value没有索引，不将该header添加到动态表 name无索引的非增量索引：指http2 header的name无索引，并且value没有索引，不将该header添加到动态表 incremental：http2 header的索引类型，代表增量索引 none：http2 header的索引类型，代表无索引 never：http2 header的索引类型，代表不使用索引 netty头部压缩相关方法可以结合以下netty实现的http2 header头部压缩解码方法理解 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139private void decode(ByteBuf in, Http2HeadersSink sink) throws Http2Exception &#123; int index = 0; int nameLength = 0; int valueLength = 0; byte state = 0; boolean huffmanEncoded = false; AsciiString name = null; HpackUtil.IndexType indexType = IndexType.NONE; while(in.isReadable()) &#123; byte b; HpackHeaderField indexedHeader; switch (state) &#123; case 0: b = in.readByte(); if (this.maxDynamicTableSizeChangeRequired &amp;&amp; (b &amp; 224) != 32) &#123; throw MAX_DYNAMIC_TABLE_SIZE_CHANGE_REQUIRED; &#125; if (b &lt; 0) &#123; index = b &amp; 127; switch (index) &#123; case 0: throw DECODE_ILLEGAL_INDEX_VALUE; case 127: state = 1; continue; default: indexedHeader = this.getIndexedHeader(index); sink.appendToHeaderList((AsciiString)indexedHeader.name, (AsciiString)indexedHeader.value); &#125; &#125; else if ((b &amp; 64) == 64) &#123; indexType = IndexType.INCREMENTAL; index = b &amp; 63; switch (index) &#123; case 0: state = 3; continue; case 63: state = 2; continue; default: name = this.readName(index); nameLength = name.length(); state = 6; &#125; &#125; else &#123; if ((b &amp; 32) == 32) &#123; throw Http2Exception.connectionError(Http2Error.COMPRESSION_ERROR, &quot;Dynamic table size update must happen at the beginning of the header block&quot;, new Object[0]); &#125; indexType = (b &amp; 16) == 16 ? IndexType.NEVER : IndexType.NONE; index = b &amp; 15; switch (index) &#123; case 0: state = 3; continue; case 15: state = 2; continue; default: name = this.readName(index); nameLength = name.length(); state = 6; &#125; &#125; break; case 1: indexedHeader = this.getIndexedHeader(decodeULE128(in, index)); sink.appendToHeaderList((AsciiString)indexedHeader.name, (AsciiString)indexedHeader.value); state = 0; break; case 2: name = this.readName(decodeULE128(in, index)); nameLength = name.length(); state = 6; break; case 3: b = in.readByte(); huffmanEncoded = (b &amp; 128) == 128; index = b &amp; 127; if (index == 127) &#123; state = 4; &#125; else &#123; nameLength = index; state = 5; &#125; break; case 4: nameLength = decodeULE128(in, index); state = 5; break; case 5: if (in.readableBytes() &lt; nameLength) &#123; throw notEnoughDataException(in); &#125; name = this.readStringLiteral(in, nameLength, huffmanEncoded); state = 6; break; case 6: b = in.readByte(); huffmanEncoded = (b &amp; 128) == 128; index = b &amp; 127; switch (index) &#123; case 0: this.insertHeader(sink, name, AsciiString.EMPTY_STRING, indexType); state = 0; continue; case 127: state = 7; continue; default: valueLength = index; state = 8; continue; &#125; case 7: valueLength = decodeULE128(in, index); state = 8; break; case 8: if (in.readableBytes() &lt; valueLength) &#123; throw notEnoughDataException(in); &#125; AsciiString value = this.readStringLiteral(in, valueLength, huffmanEncoded); this.insertHeader(sink, name, value, indexType); state = 0; break; default: throw new Error(&quot;should not reach here state: &quot; + state); &#125; &#125; if (state != 0) &#123; throw Http2Exception.connectionError(Http2Error.COMPRESSION_ERROR, &quot;Incomplete header block fragment.&quot;, new Object[0]); &#125;&#125; netty http2头部压缩是HpackEncoder类实现的，它实现了hpack算法 1234567891011121314151617181920212223242526272829303132333435363738private void encodeHeader(ByteBuf out, CharSequence name, CharSequence value, boolean sensitive, long headerSize) &#123; int nameIndex; if (sensitive) &#123; nameIndex = this.getNameIndex(name); this.encodeLiteral(out, name, value, IndexType.NEVER, nameIndex); &#125; else &#123; int staticTableIndex; if (this.maxHeaderTableSize == 0L) &#123; nameIndex = HpackStaticTable.getIndexInsensitive(name, value); if (nameIndex == -1) &#123; staticTableIndex = HpackStaticTable.getIndex(name); this.encodeLiteral(out, name, value, IndexType.NONE, staticTableIndex); &#125; else &#123; encodeInteger(out, 128, 7, nameIndex); &#125; &#125; else if (headerSize &gt; this.maxHeaderTableSize) &#123; nameIndex = this.getNameIndex(name); this.encodeLiteral(out, name, value, IndexType.NONE, nameIndex); &#125; else &#123; HeaderEntry headerField = this.getEntryInsensitive(name, value); if (headerField != null) &#123; staticTableIndex = this.getIndex(headerField.index) + HpackStaticTable.length; encodeInteger(out, 128, 7, staticTableIndex); &#125; else &#123; staticTableIndex = HpackStaticTable.getIndexInsensitive(name, value); if (staticTableIndex != -1) &#123; encodeInteger(out, 128, 7, staticTableIndex); &#125; else &#123; this.ensureCapacity(headerSize); this.encodeLiteral(out, name, value, IndexType.INCREMENTAL, this.getNameIndex(name)); this.add(name, value, headerSize); &#125; &#125; &#125; &#125;&#125; 12345678910111213141516171819202122232425262728static int getIndexInsensitive(CharSequence name, CharSequence value) &#123; int index = getIndex(name); if (index == -1) &#123; return -1; &#125; else &#123; HpackHeaderField entry = getEntry(index); if (HpackUtil.equalsVariableTime(value, entry.value)) &#123; return index; &#125; else &#123; ++index; while(index &lt;= MAX_SAME_NAME_FIELD_INDEX) &#123; entry = getEntry(index); if (!HpackUtil.equalsVariableTime(name, entry.name)) &#123; return -1; &#125; if (HpackUtil.equalsVariableTime(value, entry.value)) &#123; return index; &#125; ++index; &#125; return -1; &#125; &#125;&#125; 这两个方法简单讲就是通过header name和header value获取索引值，如果获取成功，直接返回索引值，可以极大的减少数据大小","categories":["计算机网络"]},{"title":"Nginx长连接","path":"/2025/01/07/Nginx长连接/","content":"客户端长连接Nginx与客户端是默认长连接的，在http请求中，一般情况下，客户端不会主动关闭tcp连接，所以tcp连接完全受到Nginx控制，一些配置可以设置连接的属性 keepalive_disable ：设置不与哪些浏览器建立长连接，默认值为msie6（禁用与旧版本MSIE的保持活动连接），可选值还有safari （在macOS和类似macOS的操作系统上禁用与safari和类似safari的浏览器的保持活动连接），none（启用与所有浏览器的保持活动连接） keepalive_requests：设置一个长连接上最大请求数量，默认值为1000 keepalive_time：长连接最大时间，默认为1小时 keepalive_timeout：长连接超时时间，默认为75秒，与keepalive_time不同的是，keepalive_timeout是两次信息传输最大的间隔时间，如果间隔时间超过它，就会断开连接 服务端长连接与客户端不同，Nginx与服务端之间默认不会保持长连接，在请求完成之后，就会关闭连接，需要通过upstream开启长连接，也就是如果需要和服务端打开长连接必须使用到upstream，所有相关长连接的配置也都是在upstream下面的 12345678910111213141516upstream server &#123; server 127.0.0.1:8081; keepalive 16;&#125;server &#123; ... location /http/ &#123; proxy_pass http://server; proxy_http_version 1.1; proxy_set_header Connection &quot;&quot;; ... &#125;&#125; keepalive：最大保持长连接数，这个配置是没有默认值，一旦配置就相当于打开了与服务端的长连接，而具体的值就是Nginx与服务端可以保持多少个长连接，如果已经达到配置的值，那么新的连接在请求完之后会自动关闭。在开启长连接的情况下，在转发http请求时时需要加上proxy_http_version 1.1、proxy_set_header Connection “”配置或者proxy_set_header Connection “Keep-Alive”，这是因为无论客户端的Connection请求头是什么，Nginx代理转发后会变成close，所以需要显式设置代理Connection请求头 keepalive_requests：设置一个长连接上最大请求数量，默认值为1000 keepalive_time：长连接最大时间，默认为1小时 keepalive_timeout：长连接超时时间，默认60秒，与keepalive_time不同的是，keepalive_timeout是两次信息传输最大的间隔时间，如果间隔时间超过它，就会断开连接","categories":["Nginx"]},{"title":"Spring Boot整合ElasticSearch","path":"/2025/01/07/Spring Boot整合ElasticSearch/","content":"准备依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;version&gt;2.3.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; 版本对应很重要，下面是版本对应关系，我的elasticsearch是7.X的，所以用2.3.x的springboot参考地址 配置12345#开启 Elasticsearch 仓库spring.data.elasticsearch.repositories.enabled=truespring.elasticsearch.rest.uris=127.0.0.1:9200 #ES默认只支持通过127.0.0.1访问spring.elasticsearch.rest.username=elasticspring.elasticsearch.rest.password=123456 CRUDspring boot将基本的增删改查已经封装好了，只需定义entity和mapper即可 entity 123456789101112131415161718192021222324252627@Data@NoArgsConstructor@AllArgsConstructor//注：createIndex为true时，若此索引不存在，则新建索引，并且还可以修改索引，@Document为索引的属性，下面的@Field就是映射的属性@Document(indexName = &quot;article&quot;, createIndex = true)public class EsArticle &#123; @Id @Field(type = FieldType.Keyword) private String articleId; @Field(type = FieldType.Text, analyzer = &quot;ik_smart&quot;) private String title; @Field(type = FieldType.Keyword) private String classification; @Field(type = FieldType.Keyword) private List&lt;String&gt; tags; @Field(type = FieldType.Text, analyzer = &quot;ik_smart&quot;) private String content; @Field(type = FieldType.Date, format = DateFormat.custom,pattern =&quot;yyyy-MM-dd HH:mm:ss&quot;) @JsonFormat(pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;) private Date inputDate;&#125; mapper 123public interface EsArticleMapper extends ElasticsearchRepository&lt;EsArticle, String&gt; &#123;&#125; &#x2F;&#x2F;注：引入EsArticleMapper类就可以使用增删改查等基本操作了 自定义查询在实际操作中，普通的查询肯定无法满足我们的需求，spring boot提供了三种自定义查询的方式 根据方法名这种方式有点类似jpa，既根据列名以及特定的组合词语达到自定义的效果参考地址 手写查询语句该方式是利用@Query接口实现自定义语句 mapper 123456789101112131415161718192021public interface EsArticleMapper extends ElasticsearchRepository&lt;EsArticle, String&gt; &#123; @Query(&quot;&#123; &quot; + &quot; \\&quot;bool\\&quot;: &#123; &quot; + &quot; \\&quot;must\\&quot;: [ &quot; + &quot; &#123; &quot; + &quot; \\&quot;match\\&quot;: &#123; &quot; + &quot; \\&quot;title\\&quot;: \\&quot;?0\\&quot; &quot; + &quot; &#125; &quot; + &quot; &#125;, &quot; + &quot; &#123; &quot; + &quot; \\&quot;match\\&quot;: &#123; &quot; + &quot; \\&quot;content\\&quot;: \\&quot;?1\\&quot; &quot; + &quot; &#125; &quot; + &quot; &#125; &quot; + &quot; ] &quot; + &quot; &#125; &quot; + &quot;&#125;&quot;) Page&lt;EsArticle&gt; query(String title, String content, Pageable pageable);&#125; &#x2F;&#x2F;注：这里的Pageable 和 Page是为了实现分页的效果，@Query中的语句是query下级语句，不包括query，否则会报错 Service 12345678910111213141516@Componentpublic class EsArticleQuery &#123; @Autowired private EsArticleMapper esArticleMapper; public PageResult queryByTitleAndContent(String title, String content) throws IOException &#123; PageResult pageResult = PageResult.init(); Pageable pageable = PageRequest.of(pageResult.getPage(), pageResult.getRows()); Page&lt;EsArticle&gt; esArticlePage = esArticleMapper.query(title, content, pageable); pageResult.setTotal(esArticlePage.getTotalElements()); pageResult.setData(esArticlePage.getContent()); return pageResult; &#125;&#125; 使用RestHighLevelClientRestHighLevelClient的功能非常强大，可以通过各种方法和类实现自定义的效果，甚至可以自定义删除与更新 Service 12345678910111213141516171819202122232425@Componentpublic class EsArticleQuery &#123; @Autowired private RestHighLevelClient client; public PageResult queryByTitleAndContent(String title, String content) throws IOException &#123; PageResult pageResult = PageResult.init(); BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); boolQueryBuilder.must(QueryBuilders.matchQuery(&quot;title&quot;, title)); boolQueryBuilder.must(QueryBuilders.matchQuery(&quot;content&quot;, content)); SearchRequest searchRequest = new SearchRequest(&quot;article&quot;); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder().query(boolQueryBuilder); searchSourceBuilder.from(pageResult.getFrom()); searchSourceBuilder.size(pageResult.getRows()); searchRequest.source(searchSourceBuilder); SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT); SearchHit[] hits = searchResponse.getHits().getHits(); List&lt;EsArticle&gt; esArticleList = Arrays.stream(hits).map(hit -&gt; JSONUtil.toBean(hit.getSourceAsString(), EsArticle.class)).collect(Collectors.toList()); pageResult.setTotal(searchResponse.getHits().getTotalHits().value); pageResult.setData(esArticleList); return pageResult; &#125;&#125; &#x2F;&#x2F;注：这里与方法二手写查询语句是一样的效果，可对比观察备注1：方法二与方法三的完整语句 12345678910111213141516171819&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;Spring&quot; &#125; &#125;,&#123; &quot;match&quot;:&#123; &quot;content&quot;:&quot;Spring&quot; &#125; &#125; ] &#125; &#125;, &quot;from&quot;:0, &quot;size&quot;:10&#125; 自定义聚合查询自定义聚合查询只是在上述三种方法稍微改进一下，不在过多阐述","categories":["ElasticSearch"]},{"title":"Spring Boot整合RocketMQ","path":"/2025/01/07/Spring Boot整合RocketMQ/","content":"RemotingRocketMQ在5.0后为了适应多个语言以及考虑到性能等问题，引入了GRPC，不过5.0中依然保留了对Remoting协议的支持，5.0的新组件Proxy中包含了支持Remoting和GRPC两个端口，使用Remoting作为通讯协议的话，可以使用已经支持Spring Boot的客户端版本 依赖12345678&lt;!-- Apache RocketMQ存在远程命令执行高风险漏洞，漏洞编号为CVE-2023-33246 --&gt;&lt;!-- 影响版本: 5.0.0 &lt;= Apache RocketMQ &lt; 5.1.1 4.0.0 &lt;= Apache RocketMQ &lt; 4.9.6 --&gt;&lt;!-- 和RabbitMQ、Kafka不同，Spring没有集成RocketMQ，rocketmq-spring-boot-starter是RocketMQ集成了Spring Boot以适应Spring Boot环境，集成了Spring Messaging --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt; 生产者配置1234rocketmq: name-server: 127.0.0.1:9876 producer: group: test-group 上面是两个生产者必须的配置，缺一不可，这是因为RocketMQTemplate实例化必需要这两个参数，具体可以参考org.apache.rocketmq.spring.autoconfigure.RocketMQAutoConfiguration 代码1234567891011public class MessageService &#123; @Autowired private RocketMQTemplate rocketMQTemplate; public void sendMessage(String message)&#123; Message&lt;String&gt; messaging = MessageBuilder.withPayload(message).build(); rocketMQTemplate.send(RocketConfig.TEST_TOPIC, messaging); &#125;&#125; 一般情况下，直接使用rocketMQTemplate发送消息即可，支持单方向发送，同步发送，异步发送，这里的Message是spring-messaging的内容，spring-rabbitmq和spring-kafka都使用到了这个类 消费者配置1@RocketMQMessageListener(consumerGroup = &quot;test-group&quot;, topic = RocketConfig.TEST_TOPIC) @RocketMQMessageListener注解中可以配置单个监听器的部分配置 12345rocketmq: name-server: 127.0.0.1:9876 consumer: pull-batch-size: 10 topic: test-group yaml中配置消费者的全局配置，并且其中大部分配置只支持通过yaml的方式配置 代码12345678910@Component@RocketMQMessageListener(consumerGroup = &quot;test-group&quot;, topic = RocketConfig.TEST_TOPIC)public class MessageListener implements RocketMQListener&lt;String&gt; &#123; @Override public void onMessage(String message) &#123; System.out.println(message); &#125;&#125; 消费者直接实现RocketMQListener即可，底层具体逻辑是先将消息转为String，然后再通过org.springframework.messaging.converter.MessageConverter#fromMessage方法转为具体的类型 1234567891011121314151617private Object doConvertMessage(MessageExt messageExt) &#123; if (!Objects.equals(this.messageType, MessageExt.class) &amp;&amp; !Objects.equals(this.messageType, org.apache.rocketmq.common.message.Message.class)) &#123; String str = new String(messageExt.getBody(), Charset.forName(this.charset)); if (Objects.equals(this.messageType, String.class)) &#123; return str; &#125; else &#123; try &#123; return this.messageType instanceof Class ? this.getMessageConverter().fromMessage(MessageBuilder.withPayload(str).build(), (Class)this.messageType) : ((SmartMessageConverter)this.getMessageConverter()).fromMessage(MessageBuilder.withPayload(str).build(), (Class)((ParameterizedType)this.messageType).getRawType(), this.methodParameter); &#125; catch (Exception var4) &#123; log.info(&quot;convert failed. str:&#123;&#125;, msgType:&#123;&#125;&quot;, str, this.messageType); throw new RuntimeException(&quot;cannot convert message to &quot; + this.messageType, var4); &#125; &#125; &#125; else &#123; return messageExt; &#125;&#125; 事务消息介绍官方文档：https://rocketmq.apache.org/zh/docs/featureBehavior/04transactionmessage RocketMQ的事务消息可以理解为一种半消息，需要通过二次确认才能确定是否可以发送给消费者，分为以下几步 发送事务消息到RocketMQ 执行本地事务 根据本地事务执行情况，提交二次确认到RocketMQ，如果RocketMQ没有收到二次确认，它会主动请求生产者，检查确认，检查确认可以保证二次确认可以成功到达RocketMQ RocketMQ事务消息保证了发送消息和本地事务执行两个动作状态的一致性，事务消息不支持异步发送 RocketMQ和RabbitMQ的事务不太一样，RocketMQ的事务是针对单条消息，而RabbitMQ和数据库事务一样，针对的是多个操作 代码RocketMQ的事务消息，就是加上事务监听器，先发送消息，再通过事务监听器发送二次确认，并且事务监听器支持检查确认 123456789101112@Servicepublic class MessageService &#123; @Autowired private RocketMQTemplate rocketMQTemplate; public void sendMessage(String message)&#123; Message&lt;String&gt; messaging = MessageBuilder.withPayload(message).build(); rocketMQTemplate.sendMessageInTransaction(RocketConfig.TEST_TOPIC, messaging, null); &#125;&#125; 1234567891011121314@RocketMQTransactionListenerpublic class TransactionListener implements RocketMQLocalTransactionListener &#123; @Override public RocketMQLocalTransactionState executeLocalTransaction(org.springframework.messaging.Message message, Object o) &#123; System.out.println(&quot;运行本地事务&quot;); return RocketMQLocalTransactionState.COMMIT; &#125; @Override public RocketMQLocalTransactionState checkLocalTransaction(org.springframework.messaging.Message message) &#123; return RocketMQLocalTransactionState.COMMIT; &#125;&#125; 加上@RocketMQTransactionListener注解，就是全局定义事务监听器默认会给所有名称为“rocketMQTemplate”的RocketMQTemplate的bean实例设置这个事务监听器并且同一个RocketMQTemplate实例不能设置两个RocketMQLocalTransactionListener，不然会报错 由于这里RocketMQTemplate和DefaultMQProducer都交给Spring管理了，设置多个事务监听器不太方便如果需要为不同的业务设置不同的RocketMQ事务监听器，个人认为定义一个事务监听器，然后在这个事务监听器中对不同的业务进行不同的处理或者通过rocketMQTemplate.getProducer().getDefaultMQProducerImpl().sendMessageInTransaction这种方式发送消息并指定事务监听器，其中的getDefaultMQProducerImpl已经被标注为已弃用了，不过还可以将rocketMQTemplate.getProducer()作为参数，调用new DefaultMQProducerImpl(producer)的构造方法构造一个新的DefaultMQProducerImpl实例 延申为了保证一致性，还有一个思路，不使用事务消息，不过将发送消息这一步放到业务的最后一步，发送成功即提交本地事务，发送失败即回滚本地事务，但是有几个问题 如果本地事务执行时间非常久，相应的回滚也会非常久，如果发送消息失败而导致业务回滚，那么对性能是极大的浪费，而使用事务消息没有执行顺序的限制，完全可以将发送消息靠前执行 如果发送消息时间非常久，那么本地事务和发送消息两个步骤顺序执行会很费时间，而使用事务消息，两个步骤异步执行也可以保证最后的一致性 GRPC依赖对于GRPC，官方client并未提供Spring Bean方式接入的示例，只能使用原生的client，在使用过程中，可以直接使用或者自己嵌入到Spring 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client-java&lt;/artifactId&gt; &lt;version&gt;5.0.7&lt;/version&gt;&lt;/dependency&gt; 生产者由于是原生的client，所以没有Spring相关配置 代码org.apache.rocketmq.client.java.example包中提供了一些构建生产者，发送消息的示例，下面是其中一个构造生产者和发送消息的一个例子，这里需要注意，使用GRPC的话，必须配置Proxy的GRPC端口，不再是NameServer的地址了 12345678910111213141516171819202122232425262728private static Producer buildProducer(TransactionChecker checker, String... topics) throws ClientException &#123; ClientServiceProvider provider = ClientServiceProvider.loadService(); SessionCredentialsProvider sessionCredentialsProvider = new StaticSessionCredentialsProvider(&quot;yourAccessKey&quot;, &quot;yourSecretKey&quot;); ClientConfiguration clientConfiguration = ClientConfiguration.newBuilder().setEndpoints(&quot;foobar.com:8080&quot;).setCredentialProvider(sessionCredentialsProvider).build(); ProducerBuilder builder = provider.newProducerBuilder().setClientConfiguration(clientConfiguration).setTopics(topics); if (checker != null) &#123; builder.setTransactionChecker(checker); &#125; return builder.build();&#125;public static void main(String[] args) throws ClientException &#123; ClientServiceProvider provider = ClientServiceProvider.loadService(); String topic = &quot;yourNormalTopic&quot;; Producer producer = ProducerSingleton.getInstance(new String[]&#123;topic&#125;); byte[] body = &quot;This is a normal message for Apache RocketMQ&quot;.getBytes(StandardCharsets.UTF_8); String tag = &quot;yourMessageTagA&quot;; Message message = provider.newMessageBuilder().setTopic(topic).setTag(tag).setKeys(new String[]&#123;&quot;yourMessageKey-1c151062f96e&quot;&#125;).setBody(body).build(); try &#123; SendReceipt sendReceipt = producer.send(message); log.info(&quot;Send message successfully, messageId=&#123;&#125;&quot;, sendReceipt.getMessageId()); &#125; catch (Throwable var8) &#123; log.error(&quot;Failed to send message&quot;, var8); &#125;&#125; 消费者由于是原生的client，所以没有Spring相关配置 代码和生产者一样，org.apache.rocketmq.client.java.example包总也有很多消费者的示例，包括推模式，拉模式，同消费，异步消费等，下面是一个推模式同步消费的一个例子，使用GRPC的话，必须配置Proxy的GRPC端口，不再是NameServer的地址了 123456789101112131415161718public static void main(String[] args) throws ClientException, InterruptedException, IOException &#123; ClientServiceProvider provider = ClientServiceProvider.loadService(); String accessKey = &quot;yourAccessKey&quot;; String secretKey = &quot;yourSecretKey&quot;; SessionCredentialsProvider sessionCredentialsProvider = new StaticSessionCredentialsProvider(accessKey, secretKey); String endpoints = &quot;foobar.com:8080&quot;; ClientConfiguration clientConfiguration = ClientConfiguration.newBuilder().setEndpoints(endpoints).setCredentialProvider(sessionCredentialsProvider).build(); String tag = &quot;yourMessageTagA&quot;; FilterExpression filterExpression = new FilterExpression(tag, FilterExpressionType.TAG); String consumerGroup = &quot;yourConsumerGroup&quot;; String topic = &quot;yourTopic&quot;; PushConsumer pushConsumer = provider.newPushConsumerBuilder().setClientConfiguration(clientConfiguration).setConsumerGroup(consumerGroup).setSubscriptionExpressions(Collections.singletonMap(topic, filterExpression)).setMessageListener((messageView) -&gt; &#123; log.info(&quot;Consume message=&#123;&#125;&quot;, messageView); return ConsumeResult.SUCCESS; &#125;).build(); Thread.sleep(Long.MAX_VALUE); pushConsumer.close();&#125; 事务消息代码下面是org.apache.rocketmq.client.java.example包中对于事务消息的一个例子 1234567891011121314151617181920212223public static void main(String[] args) throws ClientException &#123; ClientServiceProvider provider = ClientServiceProvider.loadService(); String topic = &quot;yourTransactionTopic&quot;; TransactionChecker checker = (messageView) -&gt; &#123; log.info(&quot;Receive transactional message check, message=&#123;&#125;&quot;, messageView); return TransactionResolution.COMMIT; &#125;; Producer producer = ProducerSingleton.getTransactionalInstance(checker, new String[]&#123;topic&#125;); Transaction transaction = producer.beginTransaction(); byte[] body = &quot;This is a transaction message for Apache RocketMQ&quot;.getBytes(StandardCharsets.UTF_8); String tag = &quot;yourMessageTagA&quot;; Message message = provider.newMessageBuilder().setTopic(topic).setTag(tag).setKeys(new String[]&#123;&quot;yourMessageKey-565ef26f5727&quot;&#125;).setBody(body).build(); try &#123; SendReceipt sendReceipt = producer.send(message, transaction); log.info(&quot;Send transaction message successfully, messageId=&#123;&#125;&quot;, sendReceipt.getMessageId()); &#125; catch (Throwable var10) &#123; log.error(&quot;Failed to send message&quot;, var10); return; &#125; transaction.commit();&#125; 这段代码可以看出来，这里的事务消息实现了多消息事务，它的实现原理是每次发送消息后，将消息保存下来，最后commit的时候，将每条事务消息依次提交，通过这种方式实现了类似于RabbitMQ以及数据库的事务机制，实现了多条消息同时提交或者同时回滚，下面是commit方法的代码 123456789101112131415public void commit() throws ClientException &#123; if (this.messageSendReceiptMap.isEmpty()) &#123; throw new IllegalStateException(&quot;Transactional message has not been sent yet&quot;); &#125; else &#123; Iterator var1 = this.messageSendReceiptMap.entrySet().iterator(); while(var1.hasNext()) &#123; Map.Entry&lt;PublishingMessageImpl, SendReceiptImpl&gt; entry = (Map.Entry)var1.next(); PublishingMessageImpl publishingMessage = (PublishingMessageImpl)entry.getKey(); SendReceiptImpl sendReceipt = (SendReceiptImpl)entry.getValue(); this.producerImpl.endTransaction(sendReceipt.getEndpoints(), new GeneralMessageImpl(publishingMessage), sendReceipt.getMessageId(), sendReceipt.getTransactionId(), TransactionResolution.COMMIT, TransactionSource.SOURCE_CLIENT); &#125; &#125;&#125; 测试这里主要是看一下是否用到了GRPC 可以看出来，确实使用到了GRPC","categories":["RocketMQ"]},{"title":"Bat命令记录","path":"/2025/01/07/Bat命令记录/","content":"start与start cmd的区别首先需要知道，cmd是start命令的一个参数，与start命令其他参数并不冲突start xxx.exe和start cmd xxx.exe的区别：start相当于就是双击的效果，start cmd相当于打开一个新的cmd并且执行命令举个例子，nginx.exe，start nginx.exe就是一个窗口闪一下，就像双击nginx.exe，而start cmd nginx.exe就是打开一个cmd窗口执行nginx.exe，就像打开一个cmd窗口，执行nginx.exe start命令相关参数1start [&quot;title&quot;] [/d path] [/i] [/min] [/max] [/separate | /shared] [/low | /normal | /high | /realtime] [/wait] [/b] [command/program] [parameters] “title”: 可选参数，指定窗口标题。 &#x2F;d path: 可选参数，指定启动程序的工作目录。 &#x2F;i: 可选参数，以新窗口中的分离模式启动程序。 &#x2F;min: 可选参数，启动程序时最小化窗口。 &#x2F;max: 可选参数，启动程序时最大化窗口。 &#x2F;separate | &#x2F;shared: 可选参数，指定启动程序时使用的窗口类型。&#x2F;separate 表示在新的独立窗口中启动程序（默认值），&#x2F;shared 表示在共享控制台窗口中启动程序。 &#x2F;low | &#x2F;normal | &#x2F;high | &#x2F;realtime: 可选参数，指定启动程序时使用的进程优先级。&#x2F;low 表示低优先级，&#x2F;normal 表示正常优先级（默认值），&#x2F;high 表示高优先级，&#x2F;realtime 表示实时优先级。 &#x2F;wait: 可选参数，等待程序结束后再退出。 &#x2F;b: 可选参数，以后台模式启动程序。 原文链接：https://blog.csdn.net/m0_47406832&#x2F;article&#x2F;details&#x2F;130379434 cmd命令12@echo offstart cmd &lt;/c或者/k&gt; &quot;command&quot; @echo off：下面的命令都不在窗口中打印，直到遇到@echo on，@echo on下面的命令会打印 start：打开一个新窗口执行命令，并且不会关闭窗口 cmd：打开一个新的cmd窗口，但是不加参数不会在新窗口执行后面的命令 &#x2F;c：在新的cmd窗口执行&#x2F;c后面的命令，执行完关闭窗口 &#x2F;k：在新的cmd窗口执行&#x2F;c后面的命令，执行完不关闭窗口 “command”：可执行命令，包括exe等文件 for语句123set newcd=%cd% //将%cd%赋给newcd，%cd%代表的是当前目录set newpath=%newcd:\\=\\\\% //将newcd中的\\换成\\\\for /f &quot;skip=1 tokens=1&quot; %%i in (&#x27;wmic process where &quot;ExecutablePath=&#x27;%newpath%\\ ginx.exe&#x27;&quot; get ProcessId ^| findstr /R /V &quot;^$&quot;&#x27;) do ( taskkill /F /PID %%i ) skip&#x3D;1：跳过结果第一行 tokens&#x3D;1：获取结果的第一列 %%i in：将获取的结果赋给%%i wmic process where “ExecutablePath&#x3D;’%newpath% ginx.exe’” get ProcessId ^| findstr &#x2F;R &#x2F;V “^$”：执行命令，并且跳过空行(findstr &#x2F;R &#x2F;V “^$”)，在cmd中执行的时候，不需要加’^’，但是在for命令中需要 if语句 if语句中可以包含很多语句，但是它有一个特点，就是整个if块的语句（包括else）都是在一起执行的，如下 if “test” &#x3D;&#x3D; “test” ( set one&#x3D;one set two&#x3D;two ) set one&#x3D;one set two&#x3D;two 但是这样就有一个问题，因为是在一起执行，那么if块中读取变量，在运行到if的时候所有变量就都确定好了，也就是说if语句中对同一个变量**自修改赋值**是不行的，如下 if “test” &#x3D;&#x3D; “test” ( set one&#x3D;one set one&#x3D;%one% two ) echo %one% 如上所示if中的第二个set，并没有等前一句set执行完在读取%one%，而是在执行的一瞬间读取one，如果向要在if块中**自修改赋值**，一是使用goto语句，这样可以跳出if，二是通过变量延迟，如下 setlocal EnableDelayedExpansion if “test” &#x3D;&#x3D; “test” ( set one&#x3D;one set one&#x3D;!one! two ) echo %one% 通过setlocal EnableDelayedExpansion开启变量延迟，并且读取变量时，将%%改为!!，哪怕一起执行多条语句，变量也只会在执行到当前语句的时候读取","categories":["知识累积"]},{"title":"Maven打包相关知识","path":"/2025/01/07/Maven打包相关知识/","content":"maven生命周期 上图所示，就是平时maven所有的执行方式，之前只知道clean是清除方法，install是打包方法等，但其实除了clean，下面的是按顺序执行的，比如执行test，会先执行validate、compile，后面的方法同理。 那它们每个都是什么意思： clean：清除项目构建结果 validate：验证项目 compile：编译项目源码，包括配置文件等 test：编译测试代码，运行项目测试 package：将项目打包成可发布的格式，如jar、war verify：对生成的包进行验证 install：将项目构建结果发布到本地仓库或者远程仓库 site：生成项目站点文件 deploy：将项目构建结果部署到远程仓库或服务器 它们每个阶段都会根据规则执行相应的插件，比如compile阶段会执行maven-resources-plugin、maven-compiler-plugin等，只要引入了特定的插件，在执行到某个阶段时就会执行这个插件。有些插件是无法单独执行的，比如maven-jar-plugin等打包插件，如果没有编译的源码，是无法执行的，或者打包出来的包有问题，还有maven-install-plugin，如果没有前面的构建，也无法正常发布。下面是执行instal时，执行的阶段及对应的插件，有些阶段没有对应的插件，所以没有执行 123456789101112131415161718192021------------------------------------compile[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ SzbaDrainAgeManage ---[INFO] [INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ SzbaDrainAgeManage ---[INFO] ------------------------------------test[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ SzbaDrainAgeManage [INFO] [INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ SzbaDrainAgeManage ---[INFO] [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ SzbaDrainAgeManage ---[INFO] ------------------------------------package[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ SzbaDrainAgeManage ---[INFO] [INFO] --- spring-boot-maven-plugin:2.2.6.RELEASE:repackage (default) @ SzbaDrainAgeManage ---[INFO] [INFO] --- maven-assembly-plugin:3.1.1:single (make-assembly) @ SzbaDrainAgeManage ---[INFO] ------------------------------------install[INFO] --- maven-install-plugin:2.4:install (default-install) @ SzbaDrainAgeManage --- maven packagemaven package是打包执行包的时候，是比较重要的一个步骤，它包括一个引入第三方包的过程，这里一般只会引入maven定义的依赖包，自己手动添加的第三方依赖包是无法被一起打包的，哪怕通过一些方法将手动引入的第三方包一起打包，也很有可能出现一些出乎意料的问题，所以最好不用手动引入第三方包（包括system的方式） maven profiles配置profile配置可以选择不同的环境打包，像下面的配置，就有两个选择，第一个fat是使用spring-boot-maven-plugin打包，spring-boot-maven-plugin映入了maven-shade-plugin，所以会打包出一个超级jar包，即可运行jar文件中包括了主程序以及maven依赖包，第二个build使用maven-jar-plugin和maven-assembly-plugin，maven-jar-plugin会生成一个可执行jar包，但是不会包括第三方包，所以无法直接执行，而maven-assembly-plugin会将maven-jar-plugin和第三方包，以及自定义的一些文件一起打包成压缩包，并且通过配置使maven-jar-plugin生成的jar可以运行 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;fat&lt;/id&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.gisinfo.sand.SandApplication&lt;/mainClass&gt; &lt;!-- &lt;fork&gt;true&lt;/fork&gt;--&gt; &lt;jvmArguments&gt;-Dfile.encoding=UTF-8&lt;/jvmArguments&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;build&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- 指定启动类，将依赖打成外部jar包 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;!-- 生成的jar中，不要包含pom.xml和pom.properties这两个文件 --&gt; &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt; &lt;manifest&gt; &lt;!-- 是否要把第三方jar加入到类构建路径 --&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;!-- 外部依赖jar包的最终位置 --&gt; &lt;!-- 因为我们将第三方jar和本项目jar放在同一个目录下，这里就使用./ --&gt; &lt;classpathPrefix&gt;./&lt;/classpathPrefix&gt; &lt;!-- 项目启动类 --&gt; &lt;mainClass&gt;com.gisinfo.sand.SandApplication&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;!--主要使用的是maven提供的assembly插件完成--&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.1&lt;/version&gt; &lt;configuration&gt; &lt;descriptors&gt; &lt;!--具体的配置文件--&gt; &lt;descriptor&gt;src/main/assembly/assembly.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;!--绑定到maven操作类型上--&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;!--执行目标，不同的插件有不同的执行目标，运行一次--&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/profile&gt;&lt;/profiles&gt; maven-assembly-pluginmaven-assembly-plugin虽然在package阶段执行，但是并不会生成可发布的格式（jar、war），而是根据配置生成分发包(zip、tar.gz等)，所以通常需要和其他package阶段的插件一起使用，比如maven-jar-plugin等，下面是assembly插件引入配置 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;!-- 生成的jar中，不要包含pom.xml和pom.properties这两个文件 --&gt; &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt; &lt;manifest&gt; &lt;!-- 是否要把第三方jar加入到类构建路径 --&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;!-- 外部依赖jar包的最终位置 --&gt; &lt;!-- 因为我们将第三方jar和本项目jar放在同一个目录下，这里就使用./ --&gt; &lt;classpathPrefix&gt;./&lt;/classpathPrefix&gt; &lt;!-- 项目启动类 --&gt; &lt;mainClass&gt;com.gisinfo.sand.SandApplication&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt;&lt;/plugin&gt;&lt;plugin&gt; &lt;!--主要使用的是maven提供的assembly插件完成--&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.1&lt;/version&gt; &lt;configuration&gt; &lt;descriptors&gt; &lt;!--具体的配置文件--&gt; &lt;descriptor&gt;src/main/assembly/assembly.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;!--绑定到maven操作类型上--&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;!--执行目标，不同的插件有不同的执行目标，运行一次--&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980&lt;assembly&gt; &lt;id&gt;bin&lt;/id&gt; &lt;formats&gt; &lt;format&gt;zip&lt;/format&gt;&lt;!--把配置文件和jar包等压缩成什么文件格式，这里可以有：zip，tar等--&gt; &lt;/formats&gt; &lt;includeBaseDirectory&gt;true&lt;/includeBaseDirectory&gt; &lt;!--第三方依赖设置--&gt; &lt;dependencySets&gt; &lt;dependencySet&gt; &lt;!-- 不使用项目的artifact，第三方jar不要解压，打包进zip文件的lib目录 --&gt; &lt;useProjectArtifact&gt;false&lt;/useProjectArtifact&gt; &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt; &lt;unpack&gt;false&lt;/unpack&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;!--文件设置--&gt; &lt;fileSets&gt; &lt;!-- 0755-&gt;即用户具有读/写/执行权限，组用户和其它用户具有读写权限； 0644-&gt;即用户具有读写权限，组用户和其它用户具有只读权限； --&gt; &lt;!-- 将src/main/assembly/bin目录下的所有文件输出到打包后的bin目录中 --&gt; &lt;fileSet&gt; &lt;directory&gt;src/main/assembly/bin&lt;/directory&gt; &lt;outputDirectory&gt;bin&lt;/outputDirectory&gt; &lt;fileMode&gt;0755&lt;/fileMode&gt; &lt;!--如果是脚本，一定要改为unix.如果是在windows上面编码，会出现dos编写问题--&gt; &lt;lineEnding&gt;unix&lt;/lineEnding&gt; &lt;filtered&gt;true&lt;/filtered&gt;&lt;!-- 是否进行属性替换，脚本中参数变量为pom的profiles中properties的值(该配置，是把mvn中属性值映射生成到sh文件中，如： $&#123;package-name&#125;) --&gt; &lt;/fileSet&gt; &lt;!-- 将src/main/assembly/config目录下的所有文件输出到打包后的config目录中 --&gt; &lt;fileSet&gt; &lt;directory&gt;src/main/assembly/config&lt;/directory&gt; &lt;outputDirectory&gt;config&lt;/outputDirectory&gt; &lt;fileMode&gt;0644&lt;/fileMode&gt; &lt;/fileSet&gt; &lt;!-- 将src/main/resources下配置文件打包到config目录 --&gt; &lt;fileSet&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;outputDirectory&gt;/config&lt;/outputDirectory&gt; &lt;!-- &lt;includes&gt;--&gt; &lt;!-- &lt;include&gt;**/*.xml&lt;/include&gt;--&gt; &lt;!-- &lt;include&gt;**/*.properties&lt;/include&gt;--&gt; &lt;!-- &lt;include&gt;**/*.yml&lt;/include&gt;--&gt; &lt;!-- &lt;/includes&gt;--&gt; &lt;filtered&gt;true&lt;/filtered&gt;&lt;!-- 是否进行属性替换 --&gt; &lt;/fileSet&gt; &lt;!-- 将项目启动jar打包到lib目录中 --&gt; &lt;fileSet&gt; &lt;!-- &lt;directory&gt;target&lt;/directory&gt;--&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;*.jar&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;!-- 将项目说明文档打包到docs目录中 --&gt; &lt;fileSet&gt; &lt;directory&gt;.&lt;/directory&gt; &lt;outputDirectory&gt;docs&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;*.md&lt;/include&gt; &lt;/includes&gt; &lt;fileMode&gt;0644&lt;/fileMode&gt; &lt;/fileSet&gt; &lt;fileSet&gt; &lt;directory&gt;docs&lt;/directory&gt; &lt;outputDirectory&gt;docs&lt;/outputDirectory&gt; &lt;fileMode&gt;0644&lt;/fileMode&gt; &lt;/fileSet&gt; &lt;fileSet&gt; &lt;directory&gt;src/main/assembly/docs&lt;/directory&gt; &lt;outputDirectory&gt;docs&lt;/outputDirectory&gt; &lt;fileMode&gt;0644&lt;/fileMode&gt; &lt;/fileSet&gt; &lt;/fileSets&gt;&lt;/assembly&gt; 引入上述配置后，在package阶段会自动生成一个zip文件，这个zip文件包括项目执行jar包、第三方依赖包（maven依赖）、配置等 -Dspring.config.locationjava -Dspring.config.location&#x3D;&#x2F;config -jar xxx.jar spring.config.location是设置spring配置文件路径的，仅针对spring相关配置文件，自定义配置文件需要使用org.springframework.core.env.PropertyResolver#getProperty(“spring.config.location”)路径。 没有配置spring.config.location时，spring默认读取项目classpath（jar包项目类文件的根目录）目录配置文件，但是getProperty(“spring.config.location”)为空，所以如果项目中使用spring.config.location，需要加入判空逻辑，除了classpath，默认还有其他路径，并且优先级更高，分别为 jar包所在目录下的config文件夹 jar包所在目录 jar包classpath目录 优先级从上往下 -Dlogging.config-Dlogging.config是Java系统属性，用于配置日志配置文件地址，spring boot也是用到它，如果不配置 -Dlogging.config，那么会使用classpath:&#x2F;xxx.xml，spring boot默认使用的是Logback，也就是logback-spring.xml，可以在启动时配置logback-spring.xml的位置，示例：-Dlogging.config&#x3D;.&#x2F;config&#x2F;logback-spring.xml Java读取资源相关方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public String test() &#123; System.out.println(environment.getActiveProfiles()); System.out.println(environment.getDefaultProfiles()); System.out.println(&quot;this.getClass().getClassLoader().getResourceAsStream&quot;); try &#123; System.out.println(IoUtil.read(this.getClass().getClassLoader().getResourceAsStream(&quot;test.txt&quot;), CharsetUtil.UTF_8)); &#125;catch (Exception e)&#123; System.out.println(&quot;fail&quot;); &#125; System.out.println(&quot;this.getClass().getResourceAsStream&quot;); try &#123; System.out.println(IoUtil.read(this.getClass().getResourceAsStream(&quot;/test.txt&quot;), CharsetUtil.UTF_8));//这里的斜杠是必须的 &#125;catch (Exception e)&#123; System.out.println(&quot;fail&quot;); &#125; System.out.println(&quot;resourceLoader.getResource&quot;); try &#123; System.out.println(IoUtil.read(resourceLoader.getResource(&quot;classpath:test.txt&quot;).getInputStream(), CharsetUtil.UTF_8)); System.out.println(IoUtil.read(resourceLoader.getResource(&quot;file:C:\\\\Users\\\\pengtong\\\\Desktop\\\\test.txt&quot;).getInputStream(), CharsetUtil.UTF_8)); &#125;catch (Exception e)&#123; System.out.println(&quot;fail&quot;); &#125; System.out.println(&quot;ResourceUtils.getFile&quot;); try &#123; System.out.println(IoUtil.read(new FileInputStream(ResourceUtils.getFile(&quot;classpath:test.txt&quot;)), CharsetUtil.UTF_8)); System.out.println(IoUtil.read(resourceLoader.getResource(&quot;file:C:/Users/pengtong/Desktop/test.txt&quot;).getInputStream(), CharsetUtil.UTF_8)); &#125;catch (Exception e)&#123; System.out.println(&quot;fail&quot;); &#125; System.out.println(&quot;applicationContext.getResource&quot;); try &#123; System.out.println(IoUtil.read(applicationContext.getResource(&quot;classpath:test.txt&quot;).getInputStream(), CharsetUtil.UTF_8)); System.out.println(IoUtil.read(resourceLoader.getResource(&quot;file:C:/Users/pengtong/Desktop/test.txt&quot;).getInputStream(), CharsetUtil.UTF_8)); &#125;catch (Exception e)&#123; System.out.println(&quot;fail&quot;); &#125; System.out.println(&quot;new File&quot;); try &#123; System.out.println(IoUtil.read(new FileInputStream(new File(&quot;src/main/resources/test.txt&quot;)), CharsetUtil.UTF_8)); &#125;catch (Exception e)&#123; System.out.println(&quot;fail&quot;); &#125; System.out.println(&quot;Paths.get&quot;); try &#123; System.out.println(IoUtil.read(new FileInputStream(Paths.get(&quot;src/main/resources/test.txt&quot;).toFile()), CharsetUtil.UTF_8)); &#125;catch (Exception e)&#123; System.out.println(&quot;fail&quot;); &#125; System.out.println(&quot;new ClassPathResource&quot;); try &#123; System.out.println(IoUtil.read(new ClassPathResource(&quot;test.txt&quot;).getInputStream(), CharsetUtil.UTF_8)); &#125;catch (Exception e)&#123; System.out.println(&quot;fail&quot;); &#125; System.out.println(&quot;&quot;); System.out.println(test); return test; &#125; 代码中所有classpath:+相对路径可以换成file:+绝对路径，底层其实就是使用了java.net.URL，所以和new File()有所区别","categories":["部署运维"]},{"title":"RabbitMQ","path":"/2025/01/07/RabbitMQ/","content":"官网RabbitMQ: One broker to queue them all | RabbitMQ GitHub - rabbitmq&#x2F;rabbitmq-website: RabbitMQ website 消息队列的意义 解耦：如果使用传统的服务调用，生产者需要通过调用消费者的接口达到将数据传送给消费者的目的，但是如果当一台消费者不需要该数据了或者有另外一台机器也需要该数据，则需要修改生产者内部代码，耦合性太强，如果使用消息队列，生产者只需要将数据放在队列中，而无需关心谁来读取这条数据 异步：如果服务A完成某个业务功能需要通过陆续调用服务B，C，D的接口才能完成，而服务A不想因为调用服务B，C，D的接口耽误下面的业务的进行，这个时候可以使用消息队列，将消息放入队列中，然后继续往下执行代码 削峰填谷：如果某一时段服务A请求量巨大可能会导致服务A奔溃，这种情况可以先将请求放入队列中而不需要让服务A一次性处理所有请求 RabbitMQ安装rabbitmq安装首先需要安装erlang，而且是有版本要求的，可以通过https://www.rabbitmq.com/docs/which-erlang查看具体版本对应关系 安装erlang 进入https://erlang.org/download/找到对应的系统和版本下载安装 配置环境变量 测试 安装RabbitMQ 进入https://github.com/rabbitmq/rabbitmq-server/releases找到合适的系统和版本下载安装 启动rabbitmq RabbitMQ配置rabbitmq配置文件的地址有点特殊，不像其他中间件，rabbitmq的配置文件是根据系统环境变量确定的，在未配置的情况下使用默认配置rabbitmq配置默认地址，rabbitmq配置可选项以及默认配置参考rabbitmq配置可选项以及默认配置 RabbitMQ可视化插件1. 列出可用插件 首先，你可以查看已安装但未启用以及已启用的所有插件。在命令行中，进入RabbitMQ的sbin目录（例如，cd &#x2F;usr&#x2F;sbin 或者根据你的安装路径），然后运行： 1rabbitmq-plugins list 这将列出所有插件的状态，标记为 [E*] 的是已启用的插件，而 [ ] 或其他表示未启用。 2. 启用插件 要启用一个插件，使用rabbitmq-plugins enable命令后面跟插件的名字。要启用RabbitMQ Management插件（提供了Web管理界面），可以运行： 1rabbitmq-plugins enable rabbitmq_management 3. 重启RabbitMQ服务 可视化插件在启用后需要重启RabbitMQ服务才能生效。访问默认为地址为&lt;ip&gt;:15672 RabbitMQ结构对于RabbitMQ而言，最关键的东西就是交换机，路由和队列，交换机负责接收生产者的消息，路由负责绑定交换机和队列，队列负责存储消息等待消费者消费 消息顺序性从RabbitMQ的结构来看，消息从生产者到消费者的过程中，生产者只能将消息提交给一个Exchange，Exchange可以根据路由将消息发送给一个或多个Queue，Queue只能将消息推送给一个消费者。所以想要实现RabbitMQ消息的顺序性，可以根据全局顺序性和局部顺序性做出不同的调整，这里默认生产者和消费者同步推送和同步消费，异步推送或者异步消费必然会影响顺序性 全局顺序性：在全局顺序性的情况下，必须要保证每条消息都按照顺序传递，那么只能有一个生产者，一个队列，一个消费者 局部顺序性：在局部顺序性的情况下，即将消息分类别保证顺序性，则只需要保证同一类别的消息由同一个生产者推送，并且进入同一个队列，并且由同一个消费者消费即可 要保证同一类别的消息由同一个生产者推送，第一步很好实现 要保证同一类别的消息进入同一个队列，可以通过设置Exchange以及合适的路由键，控制同一类消息进入同一个队列 要保证同一类别的消息由同一个消费者消费，因为队列的一条消息只能推送给一个消费者，多个消费者会造成随机推送，所以对应的队列只能有一个消费者 消息持久化消息持久配置 RabbitMQ持久化涉及到交换机持久化、队列持久化、消息持久化三个部分，RabbitMQ使用Mnesia数据库存储队列、交换机等元数据，消息由RabbitMQ本身负责持久化 交换机持久化：交换机持久化需要将交换机的durable属性配置为true，在spring-amqp中，可以在交换机构造函数中设置durable属性 123public TopicExchange(String name, boolean durable, boolean autoDelete) &#123; super(name, durable, autoDelete);&#125; 队列持久化：队列持久化需要将队列的durable属性配置为true，在spring-amqp中，可以在队列构造函数中设置durable属性 123public Queue(String name, boolean durable) &#123; this(name, durable, false, false, (Map)null);&#125; 消息持久化：消息持久化即在发布消息时，需要将消息的deliveryMode属性设置为2，在spring-amqp中，MessageProperties类的deliveryMode属性默认是2，即发送到消息如果不做特殊处理，是默认持久化的 12345//这是MessageProperties中的一个静态代码块，用于设置deliveryMode和priority属性static &#123; DEFAULT_DELIVERY_MODE = MessageDeliveryMode.PERSISTENT; DEFAULT_PRIORITY = 0;&#125; 12345678910public static int toInt(MessageDeliveryMode mode) &#123; switch (mode) &#123; case NON_PERSISTENT: return 1; case PERSISTENT: return 2; default: return -1; &#125;&#125; 消息存储文件 持久化参考链接 路径配置参考链接 经典队列 以Windows为例，RabbitMQ经典队列消息持久化主要存在于“%RABBITMQ_MNESIA_DIR%\\msg_stores\\vhosts&lt;vhosts-name&gt;”下面 其中 msg_store_persistent：存放rabbitmq持久化消息文件，文件名格式为“数字.rdq”，持久化消息在到达队列是写入磁盘,同时会在内存中保存一份备份,当内存紧张时,消息将会从内存中消除.存储到内存中主要目的是提高一定效率 msg_store_transient：存放rabbitmq非持久化消息文件，文件名格式为“数字.rdq”，非持久化消息一般只存在内存中,当内存压力大时,将会进行刷盘操作,以缓解内存压力 queues：存放每个队列的消息索引文件，文件名格式为“数字.idx”，自 RabbitMQ 3.5.0 版本起，小消息（内容、属性及 headers 总长度小于特定阈值，默认为 4096 字节）会直接存储在 idx 文件中，而非单独存放在消息存储中。这样可以减少一次磁盘写操作，提高性能。此行为可以通过配置项 queue_index_embed_msgs_below 控制。 当idx文件中记录的消息被消费时，会被标记，当idx文件记录的所有消息都被消费时，idx文件会被删除，虽然此时idx被删除了，但如果是持久化消息，msg_store_persistent中的rdq文件不会收到影响，即消息本身不会被删除 仲裁队列 以Windows为例，RabbitMQ经典队列消息持久化主要存在于“%RABBITMQ_MNESIA_DIR%\\quorum&lt;vhosts-name&gt;”下面，与经典队列不同，仲裁队列在存储路径上，不区分虚拟主机，但是如果两个虚拟机创建同一名称的仲裁队列，在路径表现上，名称是不一样的 其中 wal文件，仲裁队列的预写文件，是所有队列共享的文件，它既刷入磁盘也存在于内存中，但是当大小达到阈值时，消息会被写入对应队列的段文件中用来释放内存，所以段文件不存在内存中，这里的阈值可以通过raft.wal_max_size_bytes配置控制，默认值是64MiB segment文件：上面提到的段文件，存放在每个队列对应的文件夹当中，名称是”数字.segment”，有消息条数据限制，超过限制后，在原先文件名加一生成一个新文件，这个限制可以通过raft.segment_max_entries控制，默认值是4096，最大不能超过65535 消息模式参考文档 工作模式：直接将消息投递到队列，这种方式是通过逻辑交换机实现的，逻辑交换机是RabbitMQ为每个新创建的队列自动绑定的一个特殊交换机。每个队列在创建时自动绑定到默认交换机上。这个绑定的Routing Key就是队列的名称。如果生产者发送消息时不指定Exchange（或者明确指定为默认交换机），并且提供了Routing Key，那么RabbitMQ会将这个Routing Key视为队列名，并尝试将消息直接发送到对应的队列中。 发布订阅模式：将一个消息投递到多个队列，进而实现将同一条消息投递到多个消费者，这种方式是通过扇形交换机实现的。扇形交换机会忽略路由键，将接收到的消息广播到与之绑定的所有队列。这种类型的交换机适用于发布&#x2F;订阅模式，其中消息需要被多个消费者接收。 直连模式：可以通过指定routeKey将消息投递到特定的一个或多个队列，进而实现将同一条消息投递到多个消费者，这种方式是通过直连交换机实现的，它在扇形交换机的基础上多了一层选择 路由模式：在直连模式的基础上实现了更加的灵活的方式，routeKey支持使用通配符（*和#），允许更灵活的路由规则 消费模式RabbitMQ的消费模式主要包括两种：推模式（Push）和拉模式（Pull）。 推模式（Push）：在推模式中，RabbitMQ会主动将消息推送给消费者。这一过程是通过调用basic.Consume方法实现的。当消费者调用此方法时，它会订阅队列，此后RabbitMQ就会开始向消费者推送消息。推送的消息数量可以受到Basic.Qos（Quality of Service）设置的限制，用来控制消费者预取的消息数量，防止消费者处理能力不足时消息堆积。推模式简化了消息处理流程，适用于大多数需要高效实时处理消息的场景。在spring-amqp中通过channel.basicConsume方法 拉模式（Pull）：拉模式则是消费者主动从RabbitMQ拉取消息的过程，通常通过调用basic.Get方法来实现。在拉模式下，消费者决定何时从队列中请求消息，每次请求通常只获取一条消息。尽管可以循环调用basic.Get来模拟持续接收消息的行为，但这并不推荐，因为它会显著降低RabbitMQ的性能。拉模式给予消费者更多的控制权，但在大多数场景下不如推模式高效。在spring-amqp中通过channel.basicGet方法 选择推还是拉模式主要取决于应用的需求： 推模式适用于需要实时处理消息且对消息处理有较高效率要求的应用场景，因为它可以减少消息处理的延迟。 拉模式适用于那些消费者需要更多控制权，比如按需处理消息，或者资源有限，希望在处理完一条消息后再获取下一条的场景。 在实际应用中，推模式更为常见，因为它能更好地利用消息队列的异步处理能力和提高系统的响应速度。然而，在某些特殊需求下，拉模式也能提供更加灵活的控制选项。 此外，在Kafka、RocketMQ、RabbitMQ中，只有RabbitMQ真正实现了推模式，RocketMQ的推模式实际上还是通过拉模式实现的，而Kafka没有推模式，这一点让RabbitMQ在低延迟方面有优势 消息过滤RabbitMQ 提供了几种消息过滤机制来帮助消费者精确订阅他们所需要的数据。以下是一些主要的消息过滤方式： 基于路由键（Routing Key）的过滤： RabbitMQ 中的基本消息路由是通过交换机（Exchange）和路由键实现的。生产者发送消息到交换机时会指定一个路由键，而消费者通过队列与交换机绑定时也会指定一个或多个绑定键（Binding Key）。交换机会根据路由键和绑定键的精确匹配将消息路由到对应的队列。这意味着，消费者可以通过设置合适的绑定键来过滤掉不感兴趣的消息。 基于消息属性的过滤： RabbitMQ 支持消息属性（Message Properties），这些属性可以是发布消息时自定义的元数据。虽然RabbitMQ本身不直接提供基于消息属性的过滤，但可以通过插件或消费者逻辑来实现。例如，可以编写一个插件或消费者代码，检查消息的属性并据此决定是否接收处理消息。 Topic Exchange 的模式匹配： 使用topic类型的交换机可以实现更复杂的基于模式的过滤。在这种模式下，绑定键和路由键可以包含通配符（和#），允许更灵活的匹配规则。例如，#.orange.可以匹配所有包含.orange.的消息，而lazy.#可以匹配所有以lazy.开头的消息。 消息选择器（Message Selectors）： 虽然不是RabbitMQ原生支持的功能，但可以通过AMQP协议的消息选择器功能在消息消费时根据消息内容的属性进行过滤。不过，这种方式相比其他过滤机制来说效率较低，因为需要消费者逐一检查消息内容。 插件辅助过滤： 有时候，为了实现更高级的过滤逻辑，可以使用第三方插件，比如消息去重插件或其他自定义插件，这些插件可以提供额外的过滤功能。 在设计消息过滤策略时，需要平衡过滤的精确度和系统的性能，同时也要考虑易用性和可维护性。根据业务需求选择最合适的过滤方式是至关重要的。 消息丢失消息丢失主要从生产者、MQ、消费者三者考虑消息丢失的情况 生产者解决消息丢失问题主要有两种方式 事务：生产者发送数据之前开启 RabbitMQ 事务channel.txSelect，然后发送消 息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息；如果收到了消息，那么可以提交事务channel.txCommit，类似我们数据库数据库事务机制。 confirm模式：用于确认消息是否已经成功到达了交换机（Exchange），也可以理解为确认消息是否成功到达MQ。生产者实例可以在发送消息前可以开启confirm模式，打开confirm模式后，每个被投递到这个channel的消息都会分配一个唯一ID标识，当消息写入RabbitMQ之后，RabbitMQ会回传一个ack消息给生产者，ack消息包含消息的唯一ID标识，这样生产者就能知道消息被准确收到；如果RabbitMQ因为自身内部错误导致消息丢失，就会回传一个nack消息给生产者，这样就会调用一个我们处理nack消息的回调函数，在这个回调函数中我们可以写一些消息重发逻辑。除了confirm还有一个renturn模式，用于确认消息是否从交换机成功到达队列，主要用于检查消息路由失败，如路由键错误或队列不存在等情况。renturn模式检查的是MQ内部的问题 MQ解决消息丢失问题主要通过持久化解决 无论是生产端也好还是消费端也好，在声明queue（队列）以及exchange（交换机）的时候将它们设置为可持久化的。除此之外，在生产者发送消息时，将消息的deliveryMode设置成持久化的，这样RabbitMQ就会将消息持久化到磁盘上，即使MQ宕机了，重启后也能从磁盘上恢复消息数据。这种方案一般是配合生产者的confirm模式共同使用，只有当消息被持久化到磁盘后，MQ才会发送ack消息通知生产端。如果需要进一步的保障，还可以使用集群、镜像队列、仲裁队列等 消费者解决消息丢失问题主要通过ack机制解决 默认的消息确认机制是消费者一收到消息，就会回一个ack消息给MQ，并且MQ一收到消费端的ack消息，就会将消息从内存或磁盘中移除。我们可以在消费者订阅队列时，关闭autoAck，关闭后消费端不会一收到消息会回ack，而是在业务处理完后，需要手动调用方法发送ack消息给MQ：channel.basicAck()，MQ也会一直等待直到消费端调用basicAck，回复确认消息后，才会将消息从内存或磁盘中移除。 集群架构RabbiMQ集群 消息积压处理 RabbitMQ 中的消息积压可以从很多方面考虑解决问题，比如在代码层面优化消费者代码逻辑，提升消费速度，或者直接提升硬件资源，提升消费速度，从RabbitMQ来考虑，可以有以下几个方法 增加消费者数量： 基于RabbitMQ一个队列可以负载多个消费者的特性，可以通过增加更多的消费者来提高消息的处理速度，从而减少队列中的积压。确保你的消费者程序能够并行处理消息。 使用优先级队列： 如果某些消息比其他消息更重要，可以使用优先级队列来确保这些消息被优先处理。 消息批处理： 允许消费者一次获取多条消息，而不是一条一条地处理。这可以通过设置 **&lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;prefetch_count&lt;/font&gt;** 参数来实现，它告诉 RabbitMQ 在等待确认前可以发送给消费者多少消息。 处理消息积压时，重要的是要根据具体的应用场景和资源限制选择最合适的方法。同时，持续监控系统性能和消息队列状态对于预防未来的问题也是至关重要的。 消息事务RabbitMQ支持消息事务在事务模式下，你可以将一系列的消息发布操作组合成一个原子性的操作。这意味着如果其中任何一个消息发布失败，整个事务都将被回滚，所有之前发布的消息都不会被提交。事务模式使用以下步骤： 调用 &lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;channel.txSelect()&lt;/font&gt; 来开启一个事务。 发布一条或多条消息到队列或交换机。 调用 &lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;channel.txCommit()&lt;/font&gt; 来提交事务，这将使所有消息都被提交。 如果在任何时候发生错误，可以调用 &lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;channel.txRollback()&lt;/font&gt; 来回滚事务，取消所有之前的操作。 延时队列1. 使用死信队列（DLX） 在 RabbitMQ 中，可以通过设置队列属性中的 &lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;x-message-ttl&lt;/font&gt; 参数来指定消息的最大存活时间。当消息的 TTL 过期后，它会被发送到预先配置的死信交换机（DLX），从而可以被路由到另一个队列供后续处理。 为了实现延时队列，你需要： 创建一个带有 TTL 设置的队列。 配置一个 DLX（死信交换机）。 将原队列与 DLX 绑定。 2. 使用 **&lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;rabbitmq_delayed_message_exchange&lt;/font&gt;** 插件 另一种实现延时队列的方法是使用 &lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;rabbitmq_delayed_message_exchange&lt;/font&gt; 插件。这个插件提供了一种类型的交换机——&lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;x-delayed-message&lt;/font&gt;，它能将消息延迟一定的时间后再发送给绑定的队列。 要使用这个插件： 首先，确保你已经安装了 &lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;rabbitmq_delayed_message_exchange&lt;/font&gt; 插件。可以通过在命令行运行 &lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;rabbitmq-plugins enable rabbitmq_delayed_message_exchange&lt;/font&gt; 来启用它。 创建一个类型为 &lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;x-delayed-message&lt;/font&gt; 的交换机。 在发送消息时，通过设置消息头部的 &lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;x-delay&lt;/font&gt; 字段来指定延迟时间（单位为毫秒）。 该插件内部实现机制基于 RabbitMQ 的消息存储和定时任务调度实现","categories":["RabbitMQ"]},{"title":"Zookeeper基本概念","path":"/2025/01/07/Zookeeper基本概念/","content":"数据结构 基本结构以znode为数据节点的层次化的多叉树形结构，每个znode由stat（状态信息）和data（具体数据）组成 znode 4 种类型 持久（PERSISTENT）节点 ：一旦创建就一直存在即使 ZooKeeper 集群宕机，直到将其删除。 临时（EPHEMERAL）节点 ：临时节点的生命周期是与 客户端会话（session） 绑定的，会话消失则节点消失 。并且，临时节点只能做叶子节点 ，不能创建子节点。这一特点在分布式中非常有用，比如很多中间件将zookeeper作为服务中心，临时节点有很大的功劳，比如中间件一个节点下线，那么zookeeper中的临时节点会因为会话关闭而被删除，基于watcher机制将通知中间件其他节点，时效性很高 持久顺序（PERSISTENT_SEQUENTIAL）节点 ：除了具有持久（PERSISTENT）节点的特性之外， 子节点的名称还具有顺序性。比如 &#x2F;node1&#x2F;app0000000001 、&#x2F;node1&#x2F;app0000000002 。 临时顺序（EPHEMERAL_SEQUENTIAL）节点 ：除了具备临时（EPHEMERAL）节点的特性之外，子节点的名称还具有顺序性。 znode状态信息解释 znode 状态信息 解释 cZxid create ZXID，即该数据节点被创建时的事务 id ctime create time，即该节点的创建时间 mZxid modified ZXID，即该节点最终一次更新时的事务 id mtime modified time，即该节点最后一次的更新时间 pZxid 该节点的子节点列表最后一次修改时的事务 id，只有子节点列表变更才会更新 pZxid，子节点内容变更不会更新 cversion 子节点版本号，当前节点的子节点每次变化时值增加 1 dataVersion 数据节点内容版本号，节点创建时为 0，每更新一次节点内容(不管内容有无变化)该版本号的值增加 1 aclVersion 节点的 ACL 版本号，表示该节点 ACL 信息变更次数 ephemeralOwner 创建该临时节点的会话的 sessionId；如果当前节点为持久节点，则 ephemeralOwner&#x3D;0 dataLength 数据节点内容长度 numChildren 当前节点的子节点个数 zookeeper 写入过程每次客户端对zookeeper进行更新时，会先写磁盘的事务日志，再把数据存入内存数据库中，后面定期会对内存数据库做一次快照存入磁盘 Watcher机制 **Watcher（事件监听器），是 ZooKeeper 中的一个很重要的特性。ZooKeeper 允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去，该机制是 ZooKeeper 实现分布式协调服务的重要特性。** ZooKeeper 集群集群角色 ZooKeeper 中没有选择传统的 Master/Slave 概念，而是引入了 Leader、Follower 和 Observer 三种角色。如下图所示 Leader：为客户端提供读和写的服务，负责投票的发起和决议，更新系统状态。 Follow：为客户端提供读服务，如果是写服务则转发给 Leader。参与选举过程中的投票。 Observer：为客户端提供读服务，如果是写服务则转发给 Leader。也不参与“过半写成功”策略。不参与选举过程中的投票。 服务器状态 LOOKING ：寻找 Leader。 LEADING ：Leader 状态，对应的节点为 Leader。 FOLLOWING ：Follower 状态，对应的节点为 Follower。 OBSERVING ：Observer 状态，对应节点为 Observer，该节点不参与 Leader 选举。 过半机制 ZooKeeper 集群在宕掉几个 ZooKeeper 服务器之后，如果剩下的 ZooKeeper 服务器个数大于宕掉的个数的话整个 ZooKeeper 才依然可用。 所以设置zookeeper集群机器数最好为奇数，因为2n 和 2n-1 的容忍度是一样的，都是 n-1。 比如假如我们有 3 台，那么最大允许宕掉 1 台 ZooKeeper 服务器，如果我们有 4 台的的时候也同样只允许宕掉 1 台。 假如我们有 5 台，那么最大允许宕掉 2 台 ZooKeeper 服务器，如果我们有 6 台的的时候也同样只允许宕掉 2 台。综上，何必增加那一个不必要的 ZooKeeper 呢？ 过半机制还可以防止集群脑裂（既整个集群因为网络等原因分成了两个或多个小集群，而每个小集群都会选举出自己的leader，当整个集群回复通信的时候，就会出现多个leader的情况），而过半机制的存在，让整个集群哪怕出现故障也最多仅有一个小集群可以存活 Zookeeper命令参考文章 ls命令查看目录下的节点信息ls [-s] [-w] [-R] path -s：展示出节点的详细信息和状态信息 -w：添加watch（监听子节点变化） -R：展示节点的级联（包括自己和子节点） stat命令查看目录下状态信息stat [-w] path -w：添加watch create命令创建节点，默认持久节点create [-s] [-e] [-c] [-t ttl] path [data] [acl] -s：有序节点 -e：临时节点 -t：带过期时间节点，比如：create ‐t 10 &#x2F;ttl，需要在 zoo.cfg中添加 extendedTypesEnabled&#x3D;true 开启，不能用于临时节点 set命令修改节点内容set [-s] [-v version] path data -s：更新节点并显示状态信息 -v：指定数据版本号，如果指定版本号与当前版本号不一致，则更新失败，如set -v 1 &#x2F;v “hello” get命令 获取节点内容get [-s] [-w] path -s：获取节点内容以及状态信息 -w：添加一个watch（监听节点数据变化） delete命令删除节点delete [-v version] path -v：指定数据版本号，如果指定版本号与当前版本号不一致，则删除失败，如delete -v 1 &#x2F;v “hello” deleteall命令级联删除该节点和子节点deleteall path [-b batch size] addWatch命令在 Zookeeper 3.6.0版本之后，客户端可以在节点上创建永久监听，永久监听在被触发后不会被删除。addWatch [-m mode] path -m:指定模式 PERSISTENT：该节点的数据变化以及子节点的变化会触发相应事件，子节点的数据变化不会触发。 PERSISTENT_RECURSIVE：该节点的数据变化以及所有子孙节点的目录或者数据变化都会触发相应事件。 其他命令 history：显示最近执行的11条命令的历史记录 getAllChildrenNumber：获取节点下的所有子孙节点数量 getEphemerals：获取当前客户端创建的所有临时节点 ACL scheme：代表采用某种权限机制 id：代表允许访问的用户 permissions：代表权限（组合字符串） scheme：权限策略 world : world下只有一个id，即只有一个用户，也就是anyone，那么组合的写法就是world:anyone:[permissions]。 world:anyone 代表任何人，zookeeper 中对所有人有权限的结点就是属于 world:anyone 的。 auth：代表认证登录，需要注册用户有权限就可以，使用的是明文密码，形式为auth:user:password:[permissions]。它不需要 id, 只要是通过 authentication 的 user 都有权限（zookeeper 支持通过 kerberos来进行 authencation，也支持 username&#x2F;password 形式的 authentication)。 digest：需要对密码加密才能访问，使用的是加密密码，组合形式为digest: username:BASE64(SHA1(password)) :[permissions]。 ip：它对应的 id 为客户机的 IP 地址，设置的时候可以设置一个 ip 段，此时限制ip进行访问。比如ip:192.168.1.1:[permissions] super：代表超级管理员，拥有所有的权限 id：用户id 是验证模式，不同的 scheme，id 的值也不一样。默认为anyone。 scheme 为 auth 时，id为：username:password scheme 为 digest 时，id为：username:BASE64(SHA1(password)) scheme 为 ip 时，id为：客户端的 ip 地址。 scheme 为 world 时，id为：anyone。 permission：权限Zookeeper定义了五种权限： CREATE(c)：创建子节点的权限。允许创建子节点； DELETE(d)：删除节点的权限。允许删除子节点； READ(r)：读取节点数据的权限。允许从节点获取数据并列出其子节点； WRITE(w)：修改节点数据的权限。允许为节点设置数据； ADMIN(a)：设置子节点权限的权限，允许为节点设置权限。 CREATE、READ、WRITE、DELETE、ADMIN 也就是增、删、改、查、管理权限，这 5 种权限简写为 crwda（即单词的首字符缩写）。 getAcl命令查看指定节点 ACL信息getAcl [-s] path -s：查看节点详细信息 setAcl命令设置指定节点的ACL 信息setAcl [-s] [-v version] [-R] path acl addauth命令addauth命令：添加认证用户命令格式：addauth scheme auth scheme：（digest：是授权方式）格式为：digest username:password auth：就是分配权限， crwda。如果不写时表示创建用户，可以通过setAcl命令来设置权限 Zookeeper 集群搭建配置zoo.cfg需要加入以下配置 1234567#不同节点需要配置不同的端口，ip不同的话不用考虑端口clientPort=2181#2001为集群通信端口，3001为集群选举端口，observer（观察者身份）server.1=127.0.0.1:2001:3001server.2=127.0.0.1:2002:3002server.3=127.0.0.1:2003:3003#server.4=127.0.0.1:2004:3004:observer","categories":["Zookeeper"]},{"title":"RocketMQ","path":"/2025/01/07/RocketMQ/","content":"官网为什么选择RocketMQ | RocketMQ GitHub - apache&#x2F;rocketmq: Apache RocketMQ is a cloud native messaging and streaming platform, making it simple to build event-driven applications. RocketMQ安装下载可以到RocketMQ官网选择合适的版本下载：https://rocketmq.apache.org/download也可以到RocketMQ github下载：https://github.com/apache/rocketmq 启动之前先设置好环境变量ROCKETMQ_HOME：&lt;rocketmq安装目录&gt; 启动NameServer启动 1&lt;rocketmq安装目录&gt;\\bin\\mqnamesrv.cmd Broker启动 123&lt;rocketmq安装目录&gt;\\bin\\mqbroker.cmd -c &lt;配置文件地址&gt; -n &lt;NameServer地址&gt;//注：除了使用-n参数外，也可以使用NAMESRV_ADDR环境变量配置NameServer地址//注：除了使用 Proxy启动 12&lt;rocketmq安装目录&gt;\\bin\\mqproxy.cmd -pc &lt;配置文件地址&gt; -n &lt;NameServer地址&gt;//注：除了使用-n参数外，也可以使用NAMESRV_ADDR环境变量配置NameServer地址 配置官方文档中并没有提供全面配置参考，所以只能通过源码查看全面的配置项，源码中每个组件都有一个单独的配置类，变量名就对应配置文件中的配置项 源码全限定类名 配置文件路径 配置文件名 NameServer org.apache.rocketmq.common.namesrv.NamesrvConfig userhome&#x2F;namesrv&#x2F; namesrv.properties Broker org.apache.rocketmq.common.BrokerConfigorg.apache.rocketmq.store.config.MessageStoreConfig rabbitmq目录&#x2F;conf broker.conf Proxy org.apache.rocketmq.proxy.config.ProxyConfig rabbitmq目录&#x2F;conf rmq-proxy.json 可视化RocketMQ可视化源码下载地址：https://github.com/apache/rocketmq-dashboard下载后修改application.properties文件rocketmq.config.namesrvAddr配置为上面NameServer的地址，然后打包运行即可 RocketMQ结构 NameServer：负责存储集群元数据，维护了 Broker 地址等信息，通常以集群的方式部署，但是它是无状态的，各实例间相互不进行信息通讯，每个实例维护同样的数据 Broker：主要负责消息的存储、投递和查询以及服务高可用保证。 Proxy：客户端和服务端之间的代理层，提供了额外的安全性和功能增强，Proxy使用GRPC解决了多语言使用RocketMQ的问题，如果在Java环境下使用Remoting协议，该组件不是必须的 生产者：向Broker或者Proxy发送消息 生产者组：多个生产者构成的生产者组，主要作用是当其中一个生产者发送完事务消息后宕机了，Broker可以通过检查同生产者组中的其他生产者以确认事务状态 消费者：从Broker或者Proxy消费消息 消费者组：多个消费者组成的消费者组，是Topic向消费者发送消息的一个逻辑分组，Topic会将消息发送给所有订阅的消费者组，然后消费者组内部根据消息模式，如果是广播模式组内则所有消费者都消费，如果是集群模式则根据负载均衡选择一个消费者消费，负载均衡分为两种 消息粒度的负载均衡，5.0开始支持，简单来说就是单个队列可以将消息按照负载策略投递到消费者组内多个消费者，如果topic有多个队列，每个队列都是这种模式 队列粒度的负载均衡，简单来说就是单个队列只支持将消息发送给固定的消费者，这里的负载均衡指的是，同一个topic下的队列对于一个消费者组都将分配一个消费者，如果消费者少于队列，则多个队列分配同一个消费者，如果消费者多于队列，则每个队列分配一个消费者后，剩余消费者将空闲，如果消费者出现问题，比如下线了，那么将重新分配 Topic：消息主题，消息传输和存储的顶层容器（逻辑容器），用于标识同一类业务逻辑的消息，可以理解为消息分组，所有消息都会属于一个Topic，生产者以Topic为目标投递消息，消费者也以Topic为目标消费消息，5.0开始，特定类型的消息只能投递到特定类型的Topic Queue：消息队列，消息存储和传输的实际容器，也是消息的最小存储单元，Topic由多个队列组成，消息储存在队列，而队列属于Topic，物理意义上，生产者的消息直接投递到队列，而消费者直接从队列获取消息 消息顺序性从RocketMQ的结构来看，消息的传递简单来说就是从生产者推送到队列，队列再推送到消费者，只是这两步都受到很多逻辑的控制，而且消息的顺序性又涉及到全局顺序性和局部顺序性，这里默认生产者同步生成和消费者同步消费 全局顺序性：全局顺序性的要求下，那么RocketMQ只能有一个生产者，一个队列，一个消费者 局部顺序性：局部顺序性的要求下，即将按类别保证消息顺序性，那么要保证同一类别消息从同一生产者生产，并且投递到同一队列，再由同一消费者消费 保证同一类别消息由同一生产者生产，这一步很好保证 保证同一类别消息进入同一队列，RocketMQ支持在发送消息时就确定投递到哪个队列，不过并不是直接设置某个消息，而是为生产者设置一个队列选择器，我们自定义实现设置队列的逻辑，5.0支持顺序消息，可以设置消息分组，同一分组的消息，按顺序投递，不过底层就是通过对消息分组的名称进行hash取模以确定队列 12345public MessageQueueImpl takeMessageQueueByMessageGroup(String messageGroup) &#123; long hashCode = Hashing.sipHash24().hashBytes(messageGroup.getBytes(StandardCharsets.UTF_8)).asLong(); int index = LongMath.mod(hashCode, this.messageQueues.size()); return (MessageQueueImpl)this.messageQueues.get(index);&#125; 3. 要保证由同一消费者消费，要考虑消费者组内是否使用到了消息粒度的负载均衡，因为消息粒度的负载均衡下，队列可能随机将消息投递到某一个消费者，队列粒度的负载均衡不存在这个问题，或者直接控制消费者组内部只有一个消费者 消息持久性RocketMQ具体持久化的路径默认为userhome&#x2F;store，windows中为UserProfile环境变量，想自定义的话可通过storePathRootDir配置项配置 其中比较重要的三个持久文件是CommitLog，ConsumeQueue，IndexFile CommitLog：消息的实际存储文件，设计原则是保证高吞吐量，它是一个顺序写磁盘的过程，非常适合于利用现代存储设备的顺序写优势，使用到了内存映射技术（mmap），默认固定大小为1个G，原因是因为内存映射技术对于大小有限制，CommitLog文件是全局的 ConsumeQueue：提供了一种快速访问消息的手段，它记录了消息在CommitLog中的offset和size以及消息tag的hashcode，每条消息的信息占用的大小相同，所以只需要根据消费位点以及信息占用大小，就可以非常快速的定位到消息信息在ConsumeQueue的位置，进而快速从CommitLog中找到消息，它同样是顺序写并且使用到了内存映射技术，每个队列都有一个ConsumeQueue文件 IndexFile：结构有点类似HashMap，使用消息的Key作为索引，提供了一种通过Key快速访问消息的手段，如果消息没有Key，那么不会向IndexFile写入，IndexFile也是全局的，参考文档 除了以上三个，还有一些其他的持久化文件，具体可进入目录中查看，这里额外介绍一下consumerOffset.json文件，默认在config目录下，这个文件存储的就是消费位点，记录了Topic对应每个订阅的消费者组在每个队列的消费位点 消息模式 集群消息：这方方式可以实现类似ActiveMQ负载均衡客户端的功能，同一个ConsumerGroup下的所有Consumer已负载均衡的方式消费消息。比较特殊的是，这种方式可以支持生产端先发送消息到Broker，消费端再订阅主题进行消费，比较灵活。RocketMQ默认为该模式 广播消息：在这种模式下，生产端发送到Topic下的消息，会被订阅了该Topic的所有Consumer消费，即使它们处于同一个ConsumerGroup 消费模式官方文档：https://rocketmq.apache.org/zh/docs/featureBehavior/06consumertype Apache RocketMQ 提供了两种消费消息的方式：Pull（拉取）消费和Push（推送）消费。尽管术语上存在区别，但实际上，在RocketMQ中所谓的Push消费也是一种基于Pull机制的实现。 Push（推送）消费 虽然被称为“Push”，但实际上RocketMQ的Push消费模型更像是一种智能化的Pull模型。通过一个长轮询线程，异步拉取消息，再提交给消费线程 特点： 自动拉取：当消息到达时，Broker会通知Consumer，由Consumer主动去拉取。 异步处理：消息到达后，Consumer可以在后台异步处理消息。 简化编程模型：开发者只需要关心消息处理逻辑，不需要频繁地编写拉取消息的代码。 Pull（拉取）消费 Pull消费模式下，消费者主动向Broker请求消息，决定何时拉取以及拉取多少消息。这种方式给予了消费者更多的控制权。 特点： 主动权在消费者：消费者可以根据自己的处理能力主动向Broker拉取消息。 灵活控制：消费者可以根据实际负载情况灵活地控制拉取消息的速度和数量。 流量控制：能够更好地控制消息的处理速率，避免因为瞬时大量消息涌入而导致系统过载。 实现机制 尽管Push模式表面上看起来是由Broker主动推送消息给Consumer，但实际上，RocketMQ依然依赖于Pull机制来实现消息消费。 消息过滤官方文档：https://rocketmq.apache.org/zh/docs/featureBehavior/07messagefilter 基于标签（Tag）的过滤： 在 RocketMQ 中，生产者可以为每条消息设置一个或多个标签（Tag），而消费者则可以通过指定特定的标签来过滤消息。这是最基本的过滤方式，通常用于根据消息的主题或类别来筛选消息。由于ConsumerQueue中就包含了Tag的hashcode，所以通过Tag过滤，在ConsumerQueue可以实现第一次过滤，但是由于hashcode可能会发生hash碰撞，所以拿到消息后，还需要再过滤一次 SQL 表达式过滤： SQL92 模式的过滤允许消费者使用类似于 SQL 的语法来定义更为复杂的过滤条件。这种方式提供了比基于标签过滤更强的表达能力，允许在生产者自定义属性，在消费者端编写过滤条件。 消息丢失生产者可通过设置同步发送保证消息成功到达Broker 同步发送：使用同步发送模式，即&lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;sendSync&lt;/font&gt;方法。这种模式下，发送消息后，会阻塞等待broker的回复，异步发送可以异步接收broker的回复，但是同步发送安全性更高，单向发送是最不安全的，无法确定消息是否成功推送到 Broker可通过同步刷盘以及搭建集群保证 同步刷盘：即消息到达broker后，等待刷盘完成后才会生产者，如果在没有刷盘之前broker就下线了，那么对生产者而言，这条消息是没有推送成功的，那么在broker上线之后，它会尝试继续推送，如果刷盘之后broker宕机，但是消息已经持久化了，重新上线后，仍然可以被消费 搭建集群：如果觉得单机节点还不够安全，还可以采取多副本的模式，rocketmq支持一主多从，多主多从，在消息复制方面，rocketmq支持同步复制（也叫同步双写）以及异步复制，同步复制会保证消息复制给所有从节点后才返回给生产者 消费者可通过手动应答应答保证消息被消费者消费 手动应答：消费者消费完消息后，手动向Broker确认消息已被成功消费。如果消费过程中出现问题，消费者不应确认消息消费，以便消息可以被重新消费。这种模式下只要broker没有收到消费者的应答，就会继续尝试推送，当然，超过一定次数，就会被认为是死信消息 集群架构RocketMQ集群 消息积压处理 RocketMQ 中的消息积压可以从很多方面考虑解决问题，比如在代码层面优化消费者代码逻辑，提升消费速度，或者直接提升硬件资源，提升消费速度，从RocketMQ来考虑，可以考虑以下几点 增加消费者数量，这里需要注意RocketMQ消费者组负载均衡的方式： 如果是消息粒度的负载均衡，基于一个队列可以负载多个消费者的特性，可以通过增加更多的消费者来提高消息的处理速度，从而减少队列中的积压。确保你的消费者程序能够并行处理消息。 如果是队列粒度的负载均衡，就得判断消费者的数量了，如果消费者的数量已经等于甚至大于队列的数量，多余的消费者就无法发挥作用了，这时候最好的方法就是通过消费者将消息转移到新的Topic中，尽可能的多一点队列，这样就可以分配更多的消费者，提升消费速度 消息批处理： 允许消费者一次获取多条消息，而不是一条一条地处理。 处理消息积压时，重要的是要根据具体的应用场景和资源限制选择最合适的方法。同时，持续监控系统性能和消息队列状态对于预防未来的问题也是至关重要的。 消息事务Spring Boot整合RocketMQ 延时队列RocketMQ延时队列 附件","categories":["RocketMQ"]},{"title":"RocketMQ集群","path":"/2025/01/07/RocketMQ集群/","content":"集群搭建基于NameServer，RocketMQ搭建集群比较简单，通过少许配置即可完成 RocketMQ对于搭建集群给出了示例配置，在安装目录就可以看到 2m-2s-async：普通集群，二主二从，异步复制 2m-2s-sync：普通集群，二主二从，同步复制 2m-noslave：普通集群，二主无从，异步复制，不过实际文件夹中多了一个broker-trace container：container集群，二主二从，同步复制，RocketMQ 5.0 引入了 BrokerContainer 的概念，一个 BrokerContainer 中可以部署多个 Broker，这些 Broker 拥有独立的端口，功能完全独立，可以通过 admin 来增加或减少 Broker controller：controller集群，文件夹中主要包含了controller组件集群搭建，为了dledger模式存在的问题，RocketMQ 5.0以后推出了Controller模式 dledger：dledger集群，为了解决普通集群无法主备切换的问题，文件夹中给出了三个节点的示例，可以理解为一主二从 普通集群这里以二主二从的同步复制举例 配置需要注意，逻辑上来讲，主节点和对应的从节点构成的是一个Broker，对于客户端或者服务端来说，是集群中的一个Broker 12345678910brokerClusterName=DefaultCluster #集群名称brokerName=broker-a #节点名称，主从节点的节点名称相同，以确定主从关系brokerId=0 #节点id，0表示主节点 大于0表示从节点，需要和brokerRole对应namesrvAddr=127.0.0.1:9876 #NameServer地址deleteWhen=04 #磁盘文件空间充足情况下，默认每天什么时候执行删除过期文件，默认04表示凌晨4点fileReservedTime=48 #文件保留时间，默认72小时，表示非当前写文件最后一次更新时间加上filereservedtime小于当前时间，该文件将被清理brokerRole=SYNC_MASTER #节点角色，SYNC_MASTER，代表为主节点，并且为同步复制flushDiskType=ASYNC_FLUSH #刷盘策略，ASYNC_FLUSH为异步刷盘storePathRootDir=D:/store-a #持久化目录，如果是同一台机器部署测试，每个节点都需要配置一个目录listenPort=10110 #监听端口，如果是同一台机器部署测试，各节点的端口需要间隔大一点，因为rocketmq同时会占用相邻的几个节点 12345678910brokerClusterName=DefaultCluster #集群名称brokerName=broker-a #节点名称，主从节点的节点名称相同，以确定主从关系brokerId=1 #节点id，0表示主节点 大于0表示从节点，需要和brokerRole对应namesrvAddr=127.0.0.1:9876 #NameServer地址deleteWhen=04 #磁盘文件空间充足情况下，默认每天什么时候执行删除过期文件，默认04表示凌晨4点fileReservedTime=48 #文件保留时间，默认72小时，表示非当前写文件最后一次更新时间加上filereservedtime小于当前时间，该文件将被清理brokerRole=SLAVE #节点角色，SLAVE为从节点flushDiskType=ASYNC_FLUSH #刷盘策略，ASYNC_FLUSH为异步刷盘storePathRootDir=D:/store-a-s #持久化目录，如果是同一台机器部署测试，每个节点都需要配置一个目录listenPort=10210 #监听端口，如果是同一台机器部署测试，各节点的端口需要间隔大一点，因为rocketmq同时会占用相邻的几个节点 集群b和集群a配置类似，只有节点名称不相同，另外单机测试部署的话，storePathRootDir和listenPort两个配置也需要注意 有了配置文件之后，使用命令mqbroker.cmd -c &lt;对应的配置文件&gt;分别启动对应节点即可，部署完通过dashboard查看，可以看到以下内容 特点 消息处理： 支持负载均衡，写入消息时，会负载到不同的broker，一条消息可能写入broker-a，也可能写入broker-b，这样可以减轻每个节点的压力，并且支持水平扩展 只有主节点可以处理写入请求，写入主节点后，再同步给从节点 从节点支持处理读取请求，但是有限制，需要slaveReadEnable配置为true，并且未读取的消息超过RocketMQ可以占用物理内存（受accessMessageInMemoryMaxRatio参数控制）时（此时因为内存放不下，会需要读取硬盘，影响性能），会从从节点读取 高可用性限制： 普通集群不支持故障转移，如果主节点挂掉了，从节点无法升级主节点，该Broker无法继续提供服务，对于整个rocketmq集群来说会丢失部分消息，并且会加大其他borker的压力 dledger集群官方参考文档：https://rocketmq.apache.org/zh/docs/bestPractice/02dledger dledger集群和普通集群的区别是故障转移，由于dledger集群采用raft算法，对于节点数量有要求，结构上只有这一点区别，其余结构是一样的。持久化方面，由于引入raft算法，commitlog日志和rocketmq原本的文件结构是不一样的 配置由于dledger集群采用raft算法选主，所以不需要brokerId和flushDiskType等涉及角色的配置 12345678910brokerClusterName = RaftCluster #集群名称brokerName=RaftNode00 #节点名称，参考普通集群namesrvAddr=127.0.0.1:9876 #NameServer地址enableDLegerCommitLog=true #是否启动 DLedger\tdLegerGroup=RaftNode00 #DLedger Raft Group的名字，建议和 brokerName 保持一致dLegerSelfId=n0 #节点id, 必须属于dLegerPeers中的一个，同 Group 内各个节点要唯一sendMessageThreadPoolNums=16 #发送线程个数，建议配置成 Cpu 核数dLegerPeers=n0-127.0.0.1:40911;n1-127.0.0.1:40912;n2-127.0.0.1:40913 #DLedger Group 内各节点的端口信息，同一个 Group 内的各个节点配置必须要保证一致listenPort=10110 #监听端口号storePathRootDir=D:\\store-n0 #持久化目录 12345678910brokerClusterName = RaftCluster #集群名称brokerName=RaftNode00 #节点名称，参考普通集群namesrvAddr=127.0.0.1:9876 #NameServer地址enableDLegerCommitLog=true #是否启动 DLedger\tdLegerGroup=RaftNode00 #DLedger Raft Group的名字，建议和 brokerName 保持一致dLegerSelfId=n1 #节点id, 必须属于dLegerPeers中的一个，同 Group 内各个节点要唯一sendMessageThreadPoolNums=16 #发送线程个数，建议配置成 Cpu 核数dLegerPeers=n0-127.0.0.1:40911;n1-127.0.0.1:40912;n2-127.0.0.1:40913 #DLedger Group 内各节点的端口信息，同一个 Group 内的各个节点配置必须要保证一致listenPort=10210 #监听端口号storePathRootDir=D:\\store-n1 #持久化目录 12345678910brokerClusterName = RaftCluster #集群名称brokerName=RaftNode00 #节点名称，参考普通集群namesrvAddr=127.0.0.1:9876 #NameServer地址enableDLegerCommitLog=true #是否启动 DLedger\tdLegerGroup=RaftNode00 #DLedger Raft Group的名字，建议和 brokerName 保持一致dLegerSelfId=n1 #节点id, 必须属于dLegerPeers中的一个，同 Group 内各个节点要唯一sendMessageThreadPoolNums=16 #发送线程个数，建议配置成 Cpu 核数dLegerPeers=n0-127.0.0.1:40911;n1-127.0.0.1:40912;n2-127.0.0.1:40913 #DLedger Group 内各节点的端口信息，同一个 Group 内的各个节点配置必须要保证一致listenPort=10210 #监听端口号storePathRootDir=D:\\store-n1 #持久化目录 除了选主方面以及dLeger特有的配置，其余配置都一样。这里的举例是三个节点构成一个broker，但是dLeger仍然支持多个broker，这一点和普通集群是一样的 有了配置文件之后，使用命令mqbroker.cmd -c &lt;对应的配置文件&gt;分别启动对应节点即可，部署完通过dashboard查看，可以看到以下内容 特点 消息复制 在消息处理方面，dledger集群和普通集群是一致的，支持多broker负载均衡，以及水平扩展，在读、写请求方面也是一致的，但是dledger模式下，持久化文件发生了变化，比普通集群更加复杂 高可用性 dledger集群支持故障转移，主节点掉线后，通过raft算法从从节点中选出一个升为主节点 数量限制 由于采用raft算法，dledger集群下一个broker起码有三个节点才能实现故障转移，即起码三节点才能接受主节点下线 节点复制 由于采用raft算法，基于多数派协议，主节点收到消息后，将消息复制给从节点并且需要收到半数以上的从节点的回复才能返回确认给客户端，相当于一种折中的同步复制，并且是强制的 controller集群官方参考文档：https://github.com/apache/rocketmq/tree/develop/docs/cn/controller controller集群的出现是为了解决dledger集群的问题，以下是官网的介绍 这里之所以叫它为controller集群是因为引入了一个新的组件：controller，它替代了dledger模式故障转移的功能，可以理解为，在普通集群中引入controller即可实现故障转移，而不需要再使用dledger模式，controller组件集群本身使用的是raft算法，所以也会受限于raft算法的一些约束，比如节点数量等，不过raft算法只针对controller组件本身的主从切换，即故障转移的能力，但是只要controller主节点还在，仍然可以为broker组件服务 配置controller组件可以单独部署，也可以部署在nameserver上，这里为了不和nameserver混淆，采用controller单独部署，如果想和nameserver部署在一起，也可以参考示例文件 123456controllerDLegerGroup = group1 #DLedger Raft Group 的名字，同一个 DLedger Raft Group 保持一致即可controllerDLegerPeers = n0-127.0.0.1:9878;n1-127.0.0.1:9868;n2-127.0.0.1:9858 #DLedger Group 内各节点的端口信息，同一个 Group 内的各个节点配置必须要保证一致controllerDLegerSelfId = n0 #节点 id，必须属于 controllerDLegerPeers 中的一个；同 Group 内各个节点要唯一controllerStorePath = D:\\controller-n0 #controller 日志存储位置。controller 是有状态的，controller 重启或宕机需要依靠日志来恢复数据，该目录非常重要，不可以轻易删除enableElectUncleanMaster = false #是否可以从 SyncStateSet 以外选举 Master，若为 true，可能会选取数据落后的副本作为 Master 而丢失消息，默认为 falsenotifyBrokerRoleChanged = true #当 Broker 副本组上角色发生变化时是否主动通知，默认为 true 1234controllerDLegerGroup = group1 #DLedger Raft Group 的名字，同一个 DLedger Raft Group 保持一致即可controllerDLegerPeers = n0-127.0.0.1:9878;n1-127.0.0.1:9868;n2-127.0.0.1:9858 #DLedger Group 内各节点的端口信息，同一个 Group 内的各个节点配置必须要保证一致controllerDLegerSelfId = n1 #节点 id，必须属于 controllerDLegerPeers 中的一个；同 Group 内各个节点要唯一controllerStorePath = D:\\controller-n1 #controller 日志存储位置。controller 是有状态的，controller 重启或宕机需要依靠日志来恢复数据，该目录非常重要，不可以轻易删除 1234controllerDLegerGroup = group1 #DLedger Raft Group 的名字，同一个 DLedger Raft Group 保持一致即可controllerDLegerPeers = n0-127.0.0.1:9878;n1-127.0.0.1:9868;n2-127.0.0.1:9858 #DLedger Group 内各节点的端口信息，同一个 Group 内的各个节点配置必须要保证一致controllerDLegerSelfId = n2 #节点 id，必须属于 controllerDLegerPeers 中的一个；同 Group 内各个节点要唯一controllerStorePath = D:\\controller-n2 #controller 日志存储位置。controller 是有状态的，controller 重启或宕机需要依靠日志来恢复数据，该目录非常重要，不可以轻易删除 controller配置完，使用mqcontroller.cmd -c &lt;配置文件&gt;分别启动即可 配置broker，这里只构建一个broker，两个节点，这里因为使用controller的主备切换功能，所以不需要角色相关配置，这里仅展示重要配置 12345678brokerClusterName = DefaultClusterbrokerName = broker-aenableControllerMode = true #roker controller 模式的总开关，只有该值为 true，自动主动切换模式才会打开。默认为 falsecontrollerAddr = 127.0.0.1:9878;127.0.0.1:9868;127.0.0.1:9858 #controller 的地址，多个 controller 中间用分号隔开namesrvAddr = 127.0.0.1:9876 #nameserver的地址allAckInSyncStateSet = true #若该值为 true，则一条消息需要复制到 SyncStateSet 中的每一个副本才会向客户端返回成功，可以保证消息不丢失。默认为 falselistenPort = 30911storePathRootDir=D:\\store-n0 12345678brokerClusterName = DefaultClusterbrokerName = broker-aenableControllerMode = true #roker controller 模式的总开关，只有该值为 true，自动主从切换模式才会打开。默认为 falsecontrollerAddr = 127.0.0.1:9878;127.0.0.1:9868;127.0.0.1:9858 #controller 的地址，多个 controller 中间用分号隔开namesrvAddr = 127.0.0.1:9876 #nameserver的地址allAckInSyncStateSet = true #若该值为 true，则一条消息需要复制到 SyncStateSet 中的每一个副本才会向客户端返回成功，可以保证消息不丢失。默认为 falselistenPort = 30921storePathRootDir=D:\\store-n1 配置完broker后，使用mqbroker.cmd -c &lt;配置文件&gt; 分别启动即可，部署完通过dashboard查看 问题这次部署过程中遇到一个问题，全部启动之后，dashboard查询不到集群信息，mqadmin也查询不到broker信息，然后通过broker日志发现这个报错： fail to send registerBrokerToController request to controller 解决办法：https://blog.csdn.net/u010600106/article/details/140011027 应该是controller的注册信息出现了问题，所以需要将相关文件删除 特点controller集群下的broker和普通集群除了实现了故障转移，其他都是一样，所以在升级、迁移方面都非常方便 消息处理 在消息处理方面，controller集群和普通集群是一样的，并且持久化和普通集群也是一样的，所以在文件处理方面，比dledger模式更有优势 高可用性 和dledger集群一样支持broker故障转移，但是dledger集群是通过改造broker实现的，但是系统复杂度也随之变大，所以导致了不少新的问题，而controller集群在普通集群的基础上引入controller组件实现故障转移，虽然引入了新的组件，但是由于可以使用之前的代码，系统复杂度要比dledger模式小很多 数量要求 由于采用raft算法，controller组件要实现自身的故障转移仍然需要起码三个节点，但是对于broker的故障转移，controller组件哪怕只有一个主节点也可以实现，实际情况broker一般都会比controller多得多，所以在这一点上，controller比dledger系统复杂度也小了很多 节点复制 由于controller集群实际上可以理解为普通集群+controller组件，所以在节点复制方面，和普通集群是一样的，可以通过参数控制同步复制还是异步复制，比dledger模式要灵活 container集群container集群主要目的是为了提高单节点资源利用率，实现方法为在单节点上部署多个broker，节点内的多个broker是完全隔离的，但是会复用线程、网络等资源，提高了资源利用率 rocketmq&#x2F;docs&#x2F;cn&#x2F;BrokerContainer.md at develop · apache&#x2F;rocketmq","categories":["RocketMQ"]},{"title":"Kafka","path":"/2025/01/07/Kafka/","content":"官网Kafka官网 GitHub - apache&#x2F;kafka: Mirror of Apache Kafka 中文版本（版本比较低，可以稍微参考）： Apache Kafka Kafka安装下载官网下载：https://kafka.apache.org/downloads 启动基于KRaft模式启动Kafka Kafka早期只支持使用zookeeper作为协调者，kafka2.8.0开始，出现了KRaft代替zookeeper，KRaft下分为两种身份，一种是controller，负责管理集群，一种broker，负责存储数据，一个节点可以同时是两种身份，也可以只是其中一种，通过配置文件控制这里先介绍一下config\\kraft目录下三个配置文件，三个文件除了具体配置不同外，并无区别 broker.properties：仅以broker身份启动 controller.properties：仅以controller身份启动 server.properties：同时以controller、broker身份启动 这里的环境是windows，所以进入kafka的bin\\windows目录执行相关命令 生成集群id，这里不一定需要通过该命令，保证不同集群id不一样即可 1kafka-storage.bat random-uuid 格式化日志目录，这里的KAFKA_CLUSTER_ID就是上面的id，具体的目录日志在配置文件中 1kafka-storage.bat format -t &lt;KAFKA_CLUSTER_ID&gt; -c ..\\..\\config\\kraft\\server.properties 启动kafka 1kafka-server-start.bat ..\\..\\config\\kraft\\server.properties 启动遇到的问题 第一个问题就是Java版本的问题，最新的kafka已经不支持Java8了（可能之前就不支持了），所以这一点需要注意 第二个问题就是kafka命令的问题，kafka-run-class.bat对于classpath是将每一个jar包的名称都拼接起来，有可能导致命令过长而执行失败，可将相关命令直接改为以下命令，具体查看kafka-run-class.bat文件 1set CLASSPATH=%CLASSPATH%;%BASE_DIR%&quot;\\libs\\*&quot; 配置官方相关配置介绍文档：https://kafka.apache.org/documentation/#configuration 中文介绍（版本比较低）：https://kafka1x.apachecn.org/documentation.html#configuration 可视化Kafka官方并没有推出可视化工具，这里使用开源工具KafkaKing 官方地址：https://blog.ysboke.cn/posts/tools/kafka-king 下载地址：https://github.com/Bronya0/Kafka-King/releases 下载后，直接启动exe文件即可 Kafka结构 Broker：主要负责消息的存储、投递和查询以及服务高可用保证。 生产者：向Broker发送消息，Kafka为了提高性能，生产者的消息不会直接推送给Broker，而是先暂存在内存中，等到一定的时机，再批量发送给Broker，生产者可以通过batch.size和linger.ms控制时机参考文档：https://zhuanlan.zhihu.com/p/482447582 消费者：从Broker消费消息 消费者组：多个消费者组成的消费者组，是Topic向消费者发送消息的一个逻辑分组，Topic会将消息发送给所有订阅的消费者组，同一个topic下的Partition对于一个消费者组都将分配一个消费者，如果消费者少于Partition，则多个Partition分配同一个消费者，如果消费者多于Partition，则每个Partition分配一个消费者后，剩余消费者将空闲，如果有消费者组内有新的消费者或者有消费者出现问题，比如下线了，那么将重新分配 Topic：消息主题，类似RocketMQ的Topic，消息传输和存储的顶层容器（逻辑容器），用于标识同一类业务逻辑的消息，可以理解为消息分组，所有消息都会属于一个Topic，生产者以Topic为目标投递消息，消费者也以Topic为目标消费消息，5.0开始，特定类型的消息只能投递到特定类型的Topic Partition：分区，类似RocketMQ的Queue，消息存储和传输的实际容器，也是消息的最小存储单元，Topic由多个Partition组成，消息储存在Partition，而Partition属于Topic，物理意义上，生产者的消息直接投递到Partition，而消费者直接从Partition获取消息。不同的是，Kafka的每个Broker只会包含Topic中的部分Partition（即不会重复），而RocketMQ中的每个Broker都会包含Topic的所有队列 Replica：副本，可以理解为Partition的拷贝，并且Kafka支持分区故障转移Partition下线后，副本可以晋升为Partition，Kafka与RocketMQ不同的地方之一，Kafka的副本是基于分区的，而RocketMQ的副本是基于节点的，基于此特性，Kafka的Broker都是一个节点，但是它们不是互相独立的，而RocketMQ的Broker一般由多个节点组成，但是不同的Broker都是互相独立的 消息顺序性从Kafka的结构来看，消息的传递简单来说就是从生产者推送到分区，分区再推送到消费者，只是这两步都受到很多逻辑的控制，而且消息的顺序性又涉及到全局顺序性和局部顺序性，这里默认生产者同步生成和消费者同步消费 全局顺序性：全局顺序性的要求下，那么Kafka只能有一个生产者，一个分区，一个消费者 局部顺序性：局部顺序性的要求下，即将按类别保证消息顺序性，那么要保证同一类别消息从同一生产者生产，并且投递到同一分区，再由同一消费者消费 保证同一类别消息由同一生产者生产，这一步很好保证 保证同一类别消息进入同一分区，Kafka支持在发送消息时就确定投递到哪个分区，不过并不是直接设置某个消息，而是为生产者设置一个分区选择器，我们自定义实现分区选择的逻辑 12345678910111213141516public class CustomizePartitioner implements Partitioner &#123; @Override public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) &#123; return Integer.valueOf((String)value) % 4; &#125; @Override public void close() &#123; &#125; @Override public void configure(Map&lt;String, ?&gt; configs) &#123; &#125;&#125; 3. 要保证由同一消费者消费，由于Kafka消费者组内，保证只有一个消费者消费一个分区的内容，所以这一步是很好实现 消息持久性参考文档：https://zhuanlan.zhihu.com/p/420963323 Kafka持久化主要包括log、index、timeindex三个文件，这三个文件都是分区下面 log：消息的实际存储文件，类似于RocketMQ的CommitLog，但是kafka的每个分区的消息都直接存储在分区文件夹下面的log文件，而RocketMQ单节点所有主题、队列的消息都是存储在统一的文件夹中，这一点有点不同 index：索引文件，类似于RocketMQ的ConsumeQueue，但只包括两个值，一个是消息偏移量（offset），另一个是消息在log中的位置（position），并且由于index采用的稀疏结构（不会存储每一条消息的索引），所以不能像RocketMQ一样，通过计算位置获取索引，只能通过二分查找，根据offset找到一个具体的的position或者范围，在到log文件中进行查找 timeindex：Kafka提供的一种通过时间查询消息的方式，也只有两个值，一个是时间，另一个是消息偏移量（offset），也是稀疏结构，查询过程先通过二分查找找到具体的offset或者范围，在通过查询出的offset到index查询具体的position或者范围，在到log文件中进行查找 Kafka关于偏移量的持久化，在早期的Kafka版本中，是保存在zookeeper中，后期的版本会将偏移量推送到一个名为__consumer_offsets的主题中 消息模式发布-订阅模式 (Publish-Subscribe) Kafka是在消费者组的基础上实现的发布-订阅模式，不同的消费者组订阅同一个主题，每个消费者组可以独立地读取主题中的消息，而不会影响其他消费者组 点对点模式 (Point-to-Point) 在消费者组内部，消费者接收消息是点对点模式，即对于主题中的一条消息，只会被消费者组内部一个消费者读取，具体的实现是主题中的同一个分区的消息只会被消费者组内的同一个消费者读取，即分区与消费者是多对一的关系，在分区或者消费者发生变化时，会重新分配 消费模式虽然Kafka和RocketMQ本质上都只支持pull模式，但是Kafka的pull模式和RocketMQ有一点区别 RocketMQ的pull模式是将偏移量存储在Broker，拉取时要先从Broker获取偏移量后再执行获取消息的流程 而Kafka的pull模式是将偏移量存储在消费者，消费者在拉取时会带上偏移量直接拉取，并且由于Kafka不存在消费者负载消费同一个分区的情况，所以Kafka消费者自己管理偏移量是很简单的&#x2F;&#x2F;注：偏移量虽然是由消费者自己管理，但是会持久到Kafka，具体实现是将偏移量推送到Kafka一个名为“__consumer_offsets”的主题中以持久，消费者重启时从这个主题中获取之前的偏移量 Kafka本身只支持pull模式，在官网中也给出了具体理由 总结一下为： push模式下，Broker如果消息推送过快，可能超出消费者的消费能力，容易出现不可控的情况 pull模式对于批量消费的场景非常有用，这更符合Kafka的设计 对于pull模式的弊端，可以通过长轮询（如果没有消息，Broker会将请求挂起，直到有消息或者超时才返回）解决 消息过滤Kafka并没有直接提供给像RocketMQ那种通过tag或者sql过滤的方式，只能自己在消费者端编写过滤代码，不过spring-kafka提供了模板，还是比较方便的，除了自己编写过滤代码，还可以考虑使用以下两种方案 使用Kafka Streams：Kafka Streams 是一个用于构建实时数据处理应用程序的轻量级 Java 库。它允许开发者直接在 Kafka 中处理数据流，支持复杂的转换、聚合和连接操作，并且可以嵌入到任何 Java 应用程序中，无需额外的集群部署。Kafka Streams 提供了容错性和可扩展性，确保数据处理的一致性和可靠性。可以引入Kafka Streams以实现复杂的过滤 KSQL：KSQL 是一个用于 Apache Kafka 的流式 SQL 引擎，它允许用户通过 SQL 语句来查询、处理和分析实时数据流。KSQL 提供了类似于传统 SQL 的语法，使得开发者可以轻松地进行复杂的流处理操作，而无需编写底层的流处理代码 消息丢失生产者可通过设置生产者的acks参数保证消息成功到达Broker acks包括三个参数：0，1，-1 0：Kafka不返回确认给生产者，容易丢消息 1：Kafka在leader确认之后就返回确认给生产者，会丢消息，因为光leader确认，如果ISR中的副本没有完全确认的话，该消息不会被认为写入成功 -1：alls，Kafka会在leader和所有ISR中的副本都确认之后才返回确认给生产者 Broker可通过设置刷盘策略以及搭建集群保证 Kafka不像RocketMQ支持同步刷盘，但是Kafka支持设置刷盘相关的参数，提供了基于消息数量、基于消息内存存储时间以及定期刷盘三种方式 log.flush.interval.messages：在将消息刷新到磁盘之前，在日志分区上累积的消息数量。 log.flush.interval.ms：在刷新到磁盘之前，任何topic中的消息保留在内存中的最长时间（以毫秒为单位）。如果未设置，则使用log.flush.scheduler.interval.ms中的值。 log.flush.scheduler.interval.ms：日志刷新器检查是否需要将所有日志刷新到磁盘的频率（以毫秒为单位） kafka之所以没有提供同步刷盘，是Kafka认为备份比磁盘更可靠 Kafka的设计似乎都是基于多节考虑的，所以Broker保证消息不丢更多还是要考虑通过集群的方式，Kafka在集群下通过ISR，可以对消息提供很强的保护 消费者可通过手动提交偏移量保证消息被消费者消费 手动提交偏移量：由于Kafka的消费偏移量是由消费者自己管理，只需要避免在消费失败的时候更新偏移量，所以采用手动提交偏移量，确保消费状态与偏移量的一致性这里其实不采用手动提交偏移量的话，消费者是不是在消费失败的时候，不会更新本地偏移量，更不会提交偏移量了，因为这一步对消费者来说是可控的（具体需要通过查看源码才能确定） 集群架构Kafka集群 消息积压当Kafka集群出现消息积压时，可以从很多方面考虑解决问题，比如在代码层面优化消费者代码逻辑，提升消费速度，或者提升硬件资源，提升消费速度，采用外部存储，减少Kafka压力等。从Kafka来考虑，可以考虑以下两点 增加消费者数量： 根据分区数量来增加消费者实例，使得每个消费者负责的分区更少，从而提高整体消费速率。 确保消费者组的数量不超过主题的分区数，如果已经达到了分区数，就需要修改一个或者多个消费者，将它作为中转站，将该topic的消息复制到一个新的很多分区的topic，这样就可以创建更多的消费者，复制这一步Kafka Stream似乎可以作为一个很好的选择 使用批处理技术： 使用批处理技术，批量拉取消息而不是逐条处理。 消息事务Spring Boot整合Kafka 延时消息虽然网上有很多基于Kafka实现延时消息的方案，但是Kafka本身并不支持延时消息，不仅如此，像Broker端的消息过滤，Kafka也不支持","categories":["kafka"]},{"title":"Kafka集群","path":"/2025/01/07/Kafka集群/","content":"集群搭建早期Kafka只支持使用Zookeeper来协调服务，管理集群状态以及元数据，后面的版本出现KRaft代替Zookeeper，出现了Controller节点用于协调服务，管理集群状态以及元数据 这里启动一个Controller，两个Broker测试，这里需要注意Kafka节点之间不存在主从，只有单个分区内部多个分片存在主从关系 启动第一个节点启动第一个节点，这个节点同时作为Controller、Broker，这里用server.properties作为配置模板，下面是一些主要的配置 1234567891011121314151617181920212223242526272829303132############################# 服务器基础设置 ############################## 此服务器的角色。设置此值会将我们置于 KRaft 模式中process.roles=broker,controller# 与此实例角色关联的节点 ID，不同broker的id必须不同node.id=1# 控制器集群的连接字符串，多个用逗号分隔，需要注意前面的数字递增controller.quorum.voters=1@localhost:9093############################# Socket 服务器设置 ############################## Socket 服务器监听的地址。# 组合节点（即设置了 `process.roles=broker,controller` 的节点）必须在此处列出控制器监听器。# 如果未定义代理监听器，则默认监听器将使用等于 java.net.InetAddress.getCanonicalHostName() 的主机名，# 并带有 PLAINTEXT 监听器名称和端口 9092。# 格式：# listeners = listener_name://host_name:port# 示例：# listeners = PLAINTEXT://your.host.name:9092listeners=PLAINTEXT://:9092,CONTROLLER://:9093# 代理之间通信使用的监听器名称。inter.broker.listener.name=PLAINTEXT# 代理向客户端通告的监听器名称、主机名和端口号。# 如果未设置，则使用 “listeners” 的值。advertised.listeners=PLAINTEXT://localhost:9092# 控制器使用的监听器名称列表，如果在 `listener.security.protocol.map` 中没有显式映射，默认使用 PLAINTEXT 协议# 在 KRaft 模式下，这是必需的。controller.listener.names=CONTROLLER 格式化日志目录，这里的KAFKA_CLUSTER_ID随便取一个，只要两个节点的一致即可 1kafka-storage.bat format -t &lt;KAFKA_CLUSTER_ID&gt; -c ..\\..\\config\\kraft\\server.properties 启动节点 1kafka-server-start.bat ..\\..\\config\\kraft\\server.properties 第二个节点启动第二个节点，这个节点仅作为Broker，这里用broker.properties作为配置模板，下面是一些主要的配置，主要就上面几个配置有点区别 1234567891011121314151617181920212223242526272829303132############################# 服务器基础设置 ############################## 此服务器的角色。设置此值会将我们置于 KRaft 模式中process.roles=broker,controller# 与此实例角色关联的节点 ID，不同broker的id必须不同node.id=2# 控制器集群的连接字符串，多个用逗号分隔，需要注意前面的数字递增controller.quorum.voters=1@localhost:9093############################# Socket 服务器设置 ############################## Socket 服务器监听的地址。# 组合节点（即设置了 `process.roles=broker,controller` 的节点）必须在此处列出控制器监听器。# 如果未定义代理监听器，则默认监听器将使用等于 java.net.InetAddress.getCanonicalHostName() 的主机名，# 并带有 PLAINTEXT 监听器名称和端口 9092。# 格式：# listeners = listener_name://host_name:port# 示例：# listeners = PLAINTEXT://your.host.name:9092listeners=PLAINTEXT://:9092# 代理之间通信使用的监听器名称。inter.broker.listener.name=PLAINTEXT# 代理向客户端通告的监听器名称、主机名和端口号。# 如果未设置，则使用 “listeners” 的值。advertised.listeners=PLAINTEXT://localhost:9092# 控制器使用的监听器名称列表，如果在 `listener.security.protocol.map` 中没有显式映射，默认使用 PLAINTEXT 协议# 在 KRaft 模式下，这是必需的。controller.listener.names=CONTROLLER 格式化日志目录，这里的KAFKA_CLUSTER_ID随便取一个，只要两个节点的一致即可 1kafka-storage.bat format -t &lt;KAFKA_CLUSTER_ID&gt; -c ..\\..\\config\\kraft\\server.properties 启动节点 1kafka-server-start.bat ..\\..\\config\\kraft\\server.properties 通过Kafka-King可以看到集群搭建成功了，创建一个Topic 可以看到，四个分区，0、2两个分区的leader在19092的节点上，1、3两个分区的leader在9092的节点上 集群特点同步副本机制Kafka集群，Controller通过Raft算法构成集群，所以拥有Raft算法所有特性，对于Broker，Kafka动态维护一组赶上领导者的同步副本（ISR），任何消息必须同时写入leader和ISR中的所有副本才被Kafka确认为写入成功 同步副本机制的优点Kafka之所以不采用Raft算法管理副本，主要是基于数据量的考虑，我们基于Raft协议的多数派协议可知（防止脑裂），集群必须存活至少一半的副本，才能正常运行，即如果要容忍一个副本下线，需要三个副本（这里的副本包括leader），要容忍两个副本下线，则需要五个副本，依此类推，Kafka认为对于存储大量数据的系统来说是不合适的，更适用于管理数据配置等数据量比较小的系统，例如Zookeeper 同步副本机制的缺点 首先就是分布式中的一个难题，脑裂问题，所以Kafka的选主不是副本内部进行的，而必须通过Zookeeper或者KRaft 第二个问题就是速度问题，因为Kafka的消息必须由ISR中的所有副本确认才被确认写入成功，如果ISR中的某个副本响应非常慢，则容易导致整体消息写入的响应速度，虽然Kafka生产者可以控制不等待所有ISR确认，但是这样就会损失安全性。而多数派协议只需要任意半数以上的副本确认即可，所以并不受限于某个副本的响应速度。第二个问题是Kafka没能解决的，但是Kafka认为是值得的Kafka官方还有下面一段","categories":["kafka"]},{"title":"WebSocket协议规则及使用","path":"/2025/01/07/WebSocket协议规则及使用/","content":"简介WebSocket是一种在单个TCP连接上进行全双工通信的协议，它允许客户端和服务器之间进行实时数据传输。相比传统的HTTP协议，WebSocket具有更低的延迟和更高的效率，特别适用于需要实时性的应用场景，比如在线游戏、即时通讯、股票行情等。 WebSocket协议通过在HTTP握手阶段升级到WebSocket连接，然后在建立的TCP连接上进行数据传输。 WebSocket协议的特点包括： 实时性：WebSocket允许服务器主动向客户端推送数据，实现了实时通信。 高效性：相比传统的HTTP轮询方式，WebSocket减少了通信的开销，提高了效率。 双向通信：WebSocket连接是全双工的，客户端和服务器可以同时进行数据传输。 轻量级：WebSocket协议本身相对轻量，减少了通信的开销。 通信过程 首先WebSocket是通过建立在tcp上的通信协议，所以第一步是建立TCP连接 TCP连接建立完之后，如果使用到SSL&#x2F;TLS，则建立SSL&#x2F;TLS连接 上述连接建立完之后，开始发起请求，客户端会先发送一个Http请求，携带Upgrade和Connection消息头，用于通知客户端升级为WebSocket协议，另外还会携带Sec-Websocket-Key以及Sec-Websocket-Extensions，前者用于和服务端校验连接，后者用于与服务端协商解压算法以及其他一些配置。通过下图可以看出进行WebSocket通信首次请求也是Http请求，而请求时前缀为ws&#x2F;wss是告诉浏览器这是WebSocket协议，不是普通的Http请求。因为第一步发送的Http请求，所以可以通过Nginx Http模块进行代理 服务端收到客户端发出第一个Http请求后，根据Upgrade和Connection，知道客户端需要使用WebSocket协议进行通信，然后根据Sec-Websocket-Key计算出Sec-WebSocket-Accept并且根据配置构造出Sec-WebSocket-Extensions，最后返回响应。通过下图看到，状态为101代表服务端通过了协议升级 客户端收到响应后，验证Sec-WebSocket-Accept，验证通过后，即开始后面的通信，后续就通过WebSocket协议进行消息通信，WebSocket具体内容简单来讲就是掩码以及压缩 协议内容WebSocket协议有上图红框组成 Fin：代表是否结束，WebSocket可以一次发送多个消息，Fin为true时代表本次最后一个消息 Reserved：WebSocket协议保留位，为未来的协议扩展提供了一定的灵活性和可扩展性 Per-Message Compressed：是否采用压缩，具体的压缩算法，在首次Http请求时确认 Opcode：有一个字段称为Opcode（操作码），用于指示帧的类型和用途。Opcode的取值范围是0x0至0xF，其中一些常见的Opcode包括： 0x0：表示帧是一个连续的数据帧（Continuation Frame），用于分片传输的消息中的后续片段。 0x1：表示帧是一个文本帧（Text Frame），用于传输文本数据。 0x2：表示帧是一个二进制帧（Binary Frame），用于传输二进制数据。 0x8：表示帧是一个连接关闭帧（Connection Close Frame），用于关闭WebSocket连接。 0x9：表示帧是一个Ping帧，用于检测连接是否仍然活动。 0xA：表示帧是一个Pong帧，用于对收到的Ping帧进行响应。 Mask：代表是否使用掩码，客户端向服务端发送数据是需要掩码的，而服务端向客户端发送数据是不需要掩码的，可以用来防止缓存中毒，参考地址 Payload length：内容的长度，这里的内容指的是使用掩码后的内容的长度，具体规则：如果长度小于125，则只需要一个字节，如果大长度于125，则将该部分置为126，将长度写入后两个字节，如果长度大于65535，则将该部分置为127，将长度写入后8个字节 Masking-Key：客户端自动生成的掩码 Masked payload：使用掩码后的内容 红框下面的Payload是装包软件通过掩码解析出来的内容，Line-based text data是抓包软件解压出来的内容 使用依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-websocket&lt;/artifactId&gt;&lt;/dependency&gt; 代码服务端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899@Component@ServerEndpoint(value = &quot;/connectWebSocket/&#123;userId&#125;&quot;)public class WebSocket &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); /** * 在线人数 */ public static int onlineNumber = 0; /** * 以用户的姓名为key，WebSocket为对象保存起来 */ public static Map&lt;String, WebSocket&gt; clients = new ConcurrentHashMap&lt;String, WebSocket&gt;(); /** * 会话 */ private Session session; /** * 用户名称 */ private String userId; /** * 建立连接 * * @param session */ @OnOpen public void onOpen(@PathParam(&quot;userId&quot;) String userId, Session session) &#123; onlineNumber++; logger.info(&quot;现在来连接的客户id：&quot; + session.getId() + &quot;用户名：&quot; + userId); this.userId = userId; this.session = session; //把自己的信息加入到map当中去 clients.put(userId, this); logger.info(&quot;有连接打开！ 当前在线人数&quot; + clients.size()); &#125; /** * 连接出错 * * @param session * @param error */ @OnError public void onError(Session session, Throwable error) &#123; logger.info(&quot;服务端发生了错误&quot; + error.getMessage()); error.printStackTrace(); &#125; /** * 连接关闭 */ @OnClose public void onClose() &#123; onlineNumber--; clients.remove(userId); logger.info(&quot;有连接关闭！ 当前在线人数&quot; + clients.size()); &#125; /** * 收到客户端的消息 * * @param jsonMessage json格式的消息 * @param session 会话 */ @OnMessage public void onMessage(String jsonMessage, Session session) &#123; try &#123; logger.info(&quot;来自客户端消息：&quot; + jsonMessage + &quot;客户端的id是：&quot; + session.getId()); ChatRecord chatRecord = JSONObject.parseObject(jsonMessage, ChatRecord.class); String toUserId = chatRecord.getToUserId(); if (WebSocket.isLogin(toUserId))&#123; this.sendMessageTo(chatRecord.getContent(), toUserId); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); logger.info(&quot;发生了错误了&quot;); &#125; &#125; public void sendMessageTo(String message, String toUserId) &#123; WebSocket.getWebSocket(toUserId).session.getAsyncRemote().sendText(message); &#125; public void sendMessage(String message) &#123; this.session.getAsyncRemote().sendText(message); &#125; public static synchronized WebSocket getWebSocket(String userId) &#123; return WebSocket.clients.get(userId); &#125; public static boolean isLogin(String userId)&#123; return StringUtils.isNotBlank(userId) &amp;&amp; clients.containsKey(userId); &#125;&#125; 12345678910@Configurationpublic class WebSocketStompConfig &#123; //这个bean的注册,用于扫描带有@ServerEndpoint的注解成为websocket ,如果你使用外置的tomcat就不需要该配置文件 @Bean public ServerEndpointExporter serverEndpointExporter() &#123; return new ServerEndpointExporter(); &#125;&#125; 服务端实现代码服务端底层对消息的读取、写入处理可以参考以下两个方法： org.apache.tomcat.websocket.PerMessageDeflate#getMoreData getMoreData主要实现了对消息的处理以及解压缩，掩码相关功能由专门的类处理 org.apache.tomcat.websocket.PerMessageDeflate#sendMessagePart sendMessagePart主要实现了消息的处理以及压缩，掩码相关功能由专门的类处理 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768@Overridepublic TransformationResult getMoreData(byte opCode, boolean fin, int rsv, ByteBuffer dest)throws IOException &#123; // Control frames are never compressed and may appear in the middle of // a WebSocket method. Pass them straight through. if (Util.isControl(opCode)) &#123; return next.getMoreData(opCode, fin, rsv, dest); &#125; if (!Util.isContinuation(opCode)) &#123; // First frame in new message skipDecompression = (rsv &amp; RSV_BITMASK) == 0; &#125; // Pass uncompressed frames straight through. if (skipDecompression) &#123; return next.getMoreData(opCode, fin, rsv, dest); &#125; int written; boolean usedEomBytes = false; while (dest.remaining() &gt; 0) &#123; // Space available in destination. Try and fill it. try &#123; written = inflater.inflate( dest.array(), dest.arrayOffset() + dest.position(), dest.remaining()); &#125; catch (DataFormatException e) &#123; throw new IOException(sm.getString(&quot;perMessageDeflate.deflateFailed&quot;), e); &#125; catch (NullPointerException e) &#123; throw new IOException(sm.getString(&quot;perMessageDeflate.alreadyClosed&quot;), e); &#125; dest.position(dest.position() + written); if (inflater.needsInput() &amp;&amp; !usedEomBytes ) &#123; if (dest.hasRemaining()) &#123; readBuffer.clear(); TransformationResult nextResult = next.getMoreData(opCode, fin, (rsv ^ RSV_BITMASK), readBuffer); inflater.setInput( readBuffer.array(), readBuffer.arrayOffset(), readBuffer.position()); if (TransformationResult.UNDERFLOW.equals(nextResult)) &#123; return nextResult; &#125; else if (TransformationResult.END_OF_FRAME.equals(nextResult) &amp;&amp; readBuffer.position() == 0) &#123; if (fin) &#123; inflater.setInput(EOM_BYTES); usedEomBytes = true; &#125; else &#123; return TransformationResult.END_OF_FRAME; &#125; &#125; &#125; &#125; else if (written == 0) &#123; if (fin &amp;&amp; (isServer &amp;&amp; !clientContextTakeover || !isServer &amp;&amp; !serverContextTakeover)) &#123; try &#123; inflater.reset(); &#125; catch (NullPointerException e) &#123; throw new IOException(sm.getString(&quot;perMessageDeflate.alreadyClosed&quot;), e); &#125; &#125; return TransformationResult.END_OF_FRAME; &#125; &#125; return TransformationResult.OVERFLOW;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141@Overridepublic List&lt;MessagePart&gt; sendMessagePart(List&lt;MessagePart&gt; uncompressedParts) throws IOException &#123; List&lt;MessagePart&gt; allCompressedParts = new ArrayList&lt;&gt;(); for (MessagePart uncompressedPart : uncompressedParts) &#123; byte opCode = uncompressedPart.getOpCode(); boolean emptyPart = uncompressedPart.getPayload().limit() == 0; emptyMessage = emptyMessage &amp;&amp; emptyPart; if (Util.isControl(opCode)) &#123; // Control messages can appear in the middle of other messages // and must not be compressed. Pass it straight through allCompressedParts.add(uncompressedPart); &#125; else if (emptyMessage &amp;&amp; uncompressedPart.isFin()) &#123; // Zero length messages can&#x27;t be compressed so pass the // final (empty) part straight through. allCompressedParts.add(uncompressedPart); &#125; else &#123; List&lt;MessagePart&gt; compressedParts = new ArrayList&lt;&gt;(); ByteBuffer uncompressedPayload = uncompressedPart.getPayload(); SendHandler uncompressedIntermediateHandler = uncompressedPart.getIntermediateHandler(); deflater.setInput(uncompressedPayload.array(), uncompressedPayload.arrayOffset() + uncompressedPayload.position(), uncompressedPayload.remaining()); int flush = (uncompressedPart.isFin() ? Deflater.SYNC_FLUSH : Deflater.NO_FLUSH); boolean deflateRequired = true; while (deflateRequired) &#123; ByteBuffer compressedPayload = writeBuffer; try &#123; int written = deflater.deflate(compressedPayload.array(), compressedPayload.arrayOffset() + compressedPayload.position(), compressedPayload.remaining(), flush); compressedPayload.position(compressedPayload.position() + written); &#125; catch (NullPointerException e) &#123; throw new IOException(sm.getString(&quot;perMessageDeflate.alreadyClosed&quot;), e); &#125; if (!uncompressedPart.isFin() &amp;&amp; compressedPayload.hasRemaining() &amp;&amp; deflater.needsInput()) &#123; // This message part has been fully processed by the // deflater. Fire the send handler for this message part // and move on to the next message part. break; &#125; // If this point is reached, a new compressed message part // will be created... MessagePart compressedPart; // .. and a new writeBuffer will be required. writeBuffer = ByteBuffer.allocate(Constants.DEFAULT_BUFFER_SIZE); // Flip the compressed payload ready for writing compressedPayload.flip(); boolean fin = uncompressedPart.isFin(); boolean full = compressedPayload.limit() == compressedPayload.capacity(); boolean needsInput = deflater.needsInput(); long blockingWriteTimeoutExpiry = uncompressedPart.getBlockingWriteTimeoutExpiry(); if (fin &amp;&amp; !full &amp;&amp; needsInput) &#123; // End of compressed message. Drop EOM bytes and output. compressedPayload.limit(compressedPayload.limit() - EOM_BYTES.length); compressedPart = new MessagePart(true, getRsv(uncompressedPart), opCode, compressedPayload, uncompressedIntermediateHandler, uncompressedIntermediateHandler, blockingWriteTimeoutExpiry); deflateRequired = false; startNewMessage(); &#125; else if (full &amp;&amp; !needsInput) &#123; // Write buffer full and input message not fully read. // Output and start new compressed part. compressedPart = new MessagePart(false, getRsv(uncompressedPart), opCode, compressedPayload, uncompressedIntermediateHandler, uncompressedIntermediateHandler, blockingWriteTimeoutExpiry); &#125; else if (!fin &amp;&amp; full &amp;&amp; needsInput) &#123; // Write buffer full and input message not fully read. // Output and get more data. compressedPart = new MessagePart(false, getRsv(uncompressedPart), opCode, compressedPayload, uncompressedIntermediateHandler, uncompressedIntermediateHandler, blockingWriteTimeoutExpiry); deflateRequired = false; &#125; else if (fin &amp;&amp; full &amp;&amp; needsInput) &#123; // Write buffer full. Input fully read. Deflater may be // in one of four states: // - output complete (just happened to align with end of // buffer // - in middle of EOM bytes // - about to write EOM bytes // - more data to write int eomBufferWritten; try &#123; eomBufferWritten = deflater.deflate(EOM_BUFFER, 0, EOM_BUFFER.length, Deflater.SYNC_FLUSH); &#125; catch (NullPointerException e) &#123; throw new IOException(sm.getString(&quot;perMessageDeflate.alreadyClosed&quot;), e); &#125; if (eomBufferWritten &lt; EOM_BUFFER.length) &#123; // EOM has just been completed compressedPayload.limit(compressedPayload.limit() - EOM_BYTES.length + eomBufferWritten); compressedPart = new MessagePart(true, getRsv(uncompressedPart), opCode, compressedPayload, uncompressedIntermediateHandler, uncompressedIntermediateHandler, blockingWriteTimeoutExpiry); deflateRequired = false; startNewMessage(); &#125; else &#123; // More data to write // Copy bytes to new write buffer writeBuffer.put(EOM_BUFFER, 0, eomBufferWritten); compressedPart = new MessagePart(false, getRsv(uncompressedPart), opCode, compressedPayload, uncompressedIntermediateHandler, uncompressedIntermediateHandler, blockingWriteTimeoutExpiry); &#125; &#125; else &#123; throw new IllegalStateException(sm.getString(&quot;perMessageDeflate.invalidState&quot;)); &#125; // Add the newly created compressed part to the set of parts // to pass on to the next transformation. compressedParts.add(compressedPart); &#125; SendHandler uncompressedEndHandler = uncompressedPart.getEndHandler(); int size = compressedParts.size(); if (size &gt; 0) &#123; compressedParts.get(size - 1).setEndHandler(uncompressedEndHandler); &#125; allCompressedParts.addAll(compressedParts); &#125; &#125; if (next == null) &#123; return allCompressedParts; &#125; else &#123; return next.sendMessagePart(allCompressedParts); &#125;&#125; 客户端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263var websocket = null;//判断当前浏览器是否支持WebSocketif(&#x27;WebSocket&#x27; in window)&#123; //连接WebSocket节点，这里的new WebSocket是浏览器自带的 websocket = new WebSocket(&quot;ws://localhost:8081/connectWebSocket/001&quot;);&#125;else&#123; alert(&#x27;Not support websocket&#x27;)&#125;//连接发生错误的回调方法websocket.onerror = function()&#123; setMessageInnerHTML(&quot;error&quot;);&#125;;//连接成功建立的回调方法websocket.onopen = function(event)&#123; setMessageInnerHTML(&quot;open&quot;);&#125;;//接收到消息的回调方法websocket.onmessage = function(event)&#123; setMessageInnerHTML(event.data);&#125;;//连接关闭的回调方法websocket.onclose = function()&#123; setMessageInnerHTML(&quot;close&quot;);&#125;;//监听窗口关闭事件，当窗口关闭时，主动去关闭websocket连接，防止连接还没断开就关闭窗口，server端会抛异常。window.onbeforeunload = function()&#123; websocket.close();&#125;;//将消息显示在网页上function setMessageInnerHTML(innerHTML)&#123; document.getElementById(&#x27;message&#x27;).innerHTML += innerHTML + &#x27;&lt;br/&gt;&#x27;;&#125;//关闭连接function closeWebSocket()&#123; websocket.close();&#125;//发送消息function send()&#123; var text = document.getElementById(&#x27;text&#x27;).value; var message = &#123; content:text &#125; websocket.send(JSON.stringify(message));&#125; 自定义实现服务端下面是对WebSocket的简单实现，主要实现了对掩码、压缩、解压等的处理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195public class WebSocket &#123; private final ServerSocket serverSocket = new ServerSocket(8081); @PreDestroy public void destroy() throws IOException &#123; serverSocket.close(); &#125; public static void main(String[] args) throws IOException &#123; WebSocket webSocket = new WebSocket(); &#125; public WebSocket() throws IOException &#123; while (true) &#123; Socket socket = serverSocket.accept(); OutputStream outputStream = socket.getOutputStream(); InputStream inputStream = socket.getInputStream(); Inflater inflater = new Inflater(true); Deflater deflater = new Deflater(Deflater.DEFAULT_COMPRESSION, true); new Thread(() -&gt; &#123; ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); new Thread(() -&gt; &#123; try &#123; byte[] bytes = new byte[1024]; int read; while (-1 != (read = inputStream.read(bytes))) &#123; byteArrayOutputStream.write(bytes, 0, read); &#125; &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; &#125;).start(); try &#123; boolean first = true; while (true) &#123; ThreadUtil.sleep(10); if (byteArrayOutputStream.size() &lt; 1) &#123; continue; &#125; byte[] bytes = byteArrayOutputStream.toByteArray(); byteArrayOutputStream.reset(); if (first) &#123; String request = new String(bytes); System.out.println(request); Map&lt;String, String&gt; headers = getHeaders(request); String secWebsocketKey = headers.get(&quot;Sec-WebSocket-Key&quot;); String secWebsocketAccept = calculateWebSocketAccept(secWebsocketKey); String response = &quot;HTTP/1.1 101 \\r &quot; + &quot;Connection: upgrade\\r &quot; + &quot;Upgrade: websocket\\r &quot; + &quot;Sec-WebSocket-Accept: &quot; + secWebsocketAccept + &quot;\\r &quot; + &quot;Sec-WebSocket-Extensions: permessage-deflate;client_max_window_bits=15\\r &quot; + &quot;\\r &quot;; IoUtil.write(outputStream, CharsetUtil.UTF_8, false, response); first = false; &#125; else &#123; if (isMask(bytes)) &#123; int payloadLength = getPayloadLength(bytes); byte[] unMaskPayload = getUnMaskPayload(bytes, payloadLength); System.out.println(new String(decompressData(inflater, unMaskPayload, 0, payloadLength))); &#125; String message = &quot;hello&quot;; byte[] compressData = compressData(deflater, message.getBytes()); byte[] data = createData(compressData.length, compressData); IoUtil.write(outputStream, false, data); &#125; &#125; &#125; catch (NoSuchAlgorithmException e) &#123; throw new RuntimeException(e); &#125; &#125;).start(); &#125; &#125; public static String calculateWebSocketAccept(String webSocketKey) throws NoSuchAlgorithmException &#123; String magicString = &quot;258EAFA5-E914-47DA-95CA-C5AB0DC85B11&quot;; String concatenated = webSocketKey + magicString; MessageDigest digest = MessageDigest.getInstance(&quot;SHA-1&quot;); byte[] hashedBytes = digest.digest(concatenated.getBytes(StandardCharsets.UTF_8)); return Base64.getEncoder().encodeToString(hashedBytes); &#125; public static Map&lt;String, String&gt; getHeaders(String request) &#123; Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); String[] lines = request.split(&quot;\\r &quot;); for (int i = 1; i &lt; lines.length; i++) &#123; String line = lines[i]; if (StringUtils.isBlank(line)) &#123; break; &#125; String[] split = line.split(&quot;: &quot;); map.put(split[0], split[1]); &#125; return map; &#125; public static byte[] decompressData(Inflater inflater, byte[] input, int offset, int position) &#123; inflater.setInput(input, offset, position); ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; try &#123; while (!inflater.needsInput())&#123;//java.util.zip.Inflater.needsInput方法可以理解为当前input的内容是否已解压完，如果返回true，代表已解压完，需要新的input int count = inflater.inflate(buffer); outputStream.write(buffer, 0, count); &#125; inflater.setInput(new byte[]&#123;0, 0, -1, -1&#125;);//这是因为WebSocket协议在压缩完后会将代表压缩结束的后四位给去掉，所以在解压时，要额外解压这四位才能执行后续解压 inflater.inflate(buffer); &#125; catch (DataFormatException e) &#123; e.printStackTrace(); &#125; return outputStream.toByteArray(); &#125; public boolean isMask(byte[] bytes) &#123; return (bytes[1] &amp; 128) == 128; &#125; public int getPayloadLength(byte[] bytes) &#123; int b = bytes[1] &amp; 127; if (b == 126) &#123; int result = 0; for (int i = 2; i &lt; 4; i++) &#123; //这里的bytes[i] &amp; 255是因为，Java的byte的表示范围是-128~127，byte最高位为1时，将取反变成负数，但是WebSocket的字节表示范围是0~255 //而byte[i]&amp;255可以将负数取反转为大于127的正数，而正数不变，这么做的原理是Java在进行运算时，byte、short都会转为int后再进行运算，并且结果也是int类型 //当byte负数与上255时，byte先变成32位int类型，最高24位全为1，而255最高24位全为0，可以抵消byte负数转为int后带来的影响，而最低8位不变，所以实际值不变 //举个例子，(byte)-2二进制表示为11111110，转为int后变成11111111111111111111111111111110，255默认为int类型，转为而二进制为00000000000000000000000011111111 //两者进行与运算后，结果为00000000000000000000000011111110，十进制值为254 result += (bytes[i] &amp; 255) &lt;&lt; (8 * (3 - i)); &#125; return result; &#125; else if (b == 127) &#123; int result = 0; for (int i = 2; i &lt; 10; i++) &#123; result += (bytes[i] &amp; 255) &lt;&lt; (8 * (9 - i)); &#125; return result; &#125; else &#123; return b; &#125; &#125; public byte[] getUnMaskPayload(byte[] bytes, int payloadLength) &#123; int position = payloadLength &gt; 65535 ? 10 : payloadLength &gt; 125 ? 4 : 2; byte[] maskingKeyBytes = ArrayUtil.sub(bytes, position, position + 4); //获取masking-key byte[] maskPayloadBytes = ArrayUtil.sub(bytes, position + 4, position + 4 + payloadLength); //获取masked-payload byte[] payload = new byte[payloadLength]; // 对每个字节进行异或运算 for (int i = 0; i &lt; payloadLength; i++) &#123; payload[i] = (byte) (maskPayloadBytes[i] ^ maskingKeyBytes[i % 4]); &#125; return payload; &#125; public static byte[] compressData(Deflater deflater, byte[] input) &#123; byte[] bytes = new byte[1024]; deflater.setInput(input); int deflate = deflater.deflate(bytes, 0, bytes.length, Deflater.SYNC_FLUSH); ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); byteArrayOutputStream.write(bytes, 0, deflate - 4);//去掉代表解压结尾的后四位 return byteArrayOutputStream.toByteArray(); &#125; public static byte[] createData(int payloadLength, byte[] maskData) &#123; byte[] one = new byte[]&#123;(byte) 193&#125;; byte[] two; if (payloadLength &gt; 65535) &#123; two = new byte[8]; two[0] = 127;//不使用mask for (int i = 1; i &lt; 9; i++) &#123; two[i] = (byte) (payloadLength &amp; (8 * (9 - i)) &gt;&gt; (8 * (8 - i))); &#125; &#125; else if (payloadLength &gt; 125) &#123; two = new byte[3]; two[0] = 126;//不使用mask two[1] = (byte) (payloadLength &gt;&gt; 8); two[2] = (byte) (payloadLength &amp; 255); &#125; else &#123; two = new byte[]&#123;(byte) payloadLength&#125;;//不使用mask &#125; return ArrayUtil.addAll(one, two, maskData); &#125;&#125;","categories":["计算机网络"]},{"title":"关于公网ip","path":"/2025/01/07/关于公网ip/","content":"前言首先明确一点，所有在互联网进行的网络通信双方都必须是公网ip，而且ipv4请求ipv4，ipv6请求ipv6，但是现在因为ipv4数量已经远远不够了，所以手机卡一般都没有公网ipv4地址了，都是通过公网映射实现的网络通信，但是ipv6的数量非常大，所以手机卡一般都有公网ipv6地址，缺点是并不是所有网络都支持ipv6（这里的不支持不是说没有ipv6地址，而是没有公网的ipv6地址，既无法通过ipv6进行互联网通信），具体可以搜索ipv6的普及性 这篇文章并不介绍任何网络知识，本人对于网络也不是很专业，只是简单介绍下公网ip 公网ipv6参考地址：https://blog.csdn.net/Luo_Xz&#x2F;article&#x2F;details&#x2F;135155449 如果我们想通过手机热点或者路由器对外公开自己的服务，就可以通过ipv6，当我们电脑连上热点或者wifi后，可以通过ipconfig查看自己的ipv6地址，并检查自己的网络是否支持ipv6，只要支持ipv6，就会有一个公网的ipv6地址，获取自己的ipv6地址后，然后设置防火墙把服务端口放开，别人就可以通过这个ipv6地址访问你的服务了，如果是http服务的话，在浏览器输入http:&#x2F;&#x2F;&lt;[ipv6公网地址]&gt;:&#x2F;&lt;具体的服务路径&gt;，就可以访问服务了，不过现在的ip基本都不是固定的，如果需要长期对外公开服务的话，可以采用DDNS（动态域名系统），简单来说就是先将自己的ip绑定到一个域名上，然后通过程序监测自己的ip是否变了，如果变了就更新域名绑定的ip，这样即使ip变了，而对于访问者来说是无感的 公网ipv4NAT参考地址：https://www.zhihu.com/question/31332694 因为ipv4地址数量不足，所以现在不会给每个网络用户分配要给公网ip地址，所以我们打开ifconfig查看自己的ip，基本都是192.168、10、172.16这些开头的内网地址，那么我们是如何访问互联网的呢，依赖于NAT（网络地址转换）技术，简单来讲就是用户访问互联网会先将信息发送到NAT设备，然后NAT设备将信息中的内网ip改为自己的公网ip，并且做好记录，然后再发送到要访问的地址，然后被访问的目标接收到信息后，再发送信息给NAT设备，NAT设备根据本地的记录将信息传回给用户，NAT技术有很多中做记录的方式，比如只记录ip对应的关系，或者连同端口一起记录上，分为很多种方式 我们可以直接在浏览器搜索自己的公网ip，很多网站提供了这种功能，原理就是那些网站接收到的我们的信息的时候，源ip地址其实就是我们的公网ip（NAT设备提供的地址），而不是我们本地的ip，所以通过浏览器查询出来的ip和我们本地的不一样 下面是本机请求云服务器，通过tcpdump命令在云服务器上看到的，113.84.136.48就是本机通过NAT技术转换的后的公网ipv4的地址，和浏览器查出来的一致","categories":["计算机网络"]},{"title":"Java对象内存相关","path":"/2025/01/07/Java对象内存相关/","content":"前言突然想到学习一下Java内存相关知识是因为关于String实例化的问题，网上说String str &#x3D; new String(“hello”)和String str &#x3D; “hello”，这两个主要区别在于，前者会先生成一个String对象，在指向常量池中的”hello”，而后者会直接指向常量池中的”hello”，所以想研究一下是不是这样，记得以前学c语言的时候，查看指针是非常简单的，而Java进行了深度的封装，所以比较麻烦 数组在讲内存之前，得先介绍一下数组，原因是因为我们没办法直接拿到对象本身的指针（具体原因还不清楚，也许对象对外只是提供了一个访问地址而已，并没有指针，而访问地址对于开发者又不可见），比如上面的str，我们是无法拿到它的指针的，也就无法拿到它的内存地址，但是数组比较特殊，因为在Java中，对于非基本数据类型（基本数据类型元素存的是元素本身），数组存的是元素的指针，即内存地址，所以可以通过数组获取对象的内存地址，比如上面的str，我们可以构建一个空String数组，然后把str放进去，这样数组第一个元素存储的就是str的内存地址 其实通过对象的变量也可以做到，比如有一个对象student，它有一个name字段，strudent实例存的也是name的内存地址，这种方式也可以获取到数据的内存地址，只是没有数组方便 Unsafe上面介绍了可以通过数组获取数据的内存地址，但是我们在访问数组的时候，返回的也只是实例对象，而不是数组实际存储的值，这是因为Java做了处理，访问涉及到内存地址的数据的时候，都会直接返回该地址的实例对象。那么这个时候就可以通过Unsafe获取数组具体存储的值，而不是直接返回实例对象 12345678910111213141516171819public void test()&#123; Unsafe unsafe = getUnsafe(); String str = &quot;one&quot;; String[] strs = new String[]&#123;str&#125;; int offset = unsafe.arrayBaseOffset(String[].class); //获取数组类基础偏移量，一般就是object header，这里的偏移量跟对象实例没关系，只和类有关 int address = unsafe.getInt(strs, (long) offset); //以strs对象为基础，获取指定偏移量的数据，这里只填了offset，是因为object header后面就是实例数据 System.out.println(address);&#125;//获取Unsafe，因为Unsafe是单例模式，并且只支持启动类加载加载的类访问，所以我们只能通过反射获取private static Unsafe getUnsafe() &#123; try &#123; Field field = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); field.setAccessible(true); return (Unsafe) field.get(null); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125;&#125; 上面的代码虽然能获取到数组存储的真实的值，但是这不一定就是对象真实的内存地址，这是因为Java会做一些处理，这个下一章节再讲 Unsafe的几个方法介绍 allocateMemory(long)，申请指定字节的堆外内存，返回的申请到的内存开始字节的地址 getInt(long)：获取指定内存地址的int值，会自动读取当前位置开始四个字节的值（因为int是四字节），但是这种方式只支持访问堆外内存，除了getInt(long)，还有getByte(读取一字节)，getChar(读取两字节)，getLong(读取8字节)，除了get，还有put，具体参考Unsafe类 getInt(Object, long)：获取指定对象指定偏移量的int值，会自动读取当前位置开始四个字节的值，如果想过指定内存地址获取int值，可通过getInt(null, address)，除了getInt(Object，long)，还有getByte(读取一字节)，getChar(读取两字节)，getLong(读取8字节)，除了get，还有put，具体参考Unsafe类 getObject(Object, long)，它和上面的getInt不一样，它分为两步，它先是获取到指定对象指定偏移量的int(对象引用大小为四字节)或者long(对象引用大小为八字节)，这一步实际上就是获取对象引用，然后第二步就是通过引用访问具体的对象，哪一步出现问题都会导致JVM报错 arrayBaseOffset(Class)和arrayIndexScale(Class)：这两个方法分别可以获取数组头部偏移量以及数组单元素字节大小，对于Field也有类似的方法，具体参考Unsafe类 jol-corejol-core是一个用于分析和展示 Java 对象内存布局的强大工具，可以很清晰查看具体对象的内存布局，获取具体对象内存地址以及获取指定内存地址的值，使用jol-core需要先引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.10&lt;/version&gt;&lt;/dependency&gt; jol-core有一个org.openjdk.jol.vm.VirtualMachine类，可以通过**VM.current()**获取该类的实例对象，它的方法大部分和Unsafe一致，底层也是调用的Unsafe，只是在Unsafe的基础上加了做了一些处理，使得对于开发者而言，更加方便，比如addressOf方法，它获取指定对象的内存地址，底层就是通过构建数组获取的，前面提到过通过Unsafe获取数组具体位置的int值，并不能代表元素的引用地址，VirtualMachine就做了专门的处理，可以将数组中的值转换为真实的内存地址，具体可以看一下源代码 jol-core还有一个强大的功能，查看对象内存布局，通过以下代码实现 1System.out.println(ClassLayout.parseInstance(object).toPrintable()); 这是一个查看String对象内存布局的例子，可以看到，可以很清晰的看到对象内存的结构 结尾回到最开始说到的String实例化的问题，我们使用jol-core测试一下 测试1234567891011121314public static void test()&#123; String a = &quot;hello&quot;; String b = &quot;hello&quot;; String c = new String(&quot;hello&quot;); VirtualMachine virtualMachine = VM.current(); long addressA = virtualMachine.addressOf(a); long addressB = virtualMachine.addressOf(b); long addressC = virtualMachine.addressOf(c); System.out.println(addressA); System.out.println(addressB); System.out.println(addressC);&#125; 可以看到，a和b是同一个对象，而c是另外一个，接下来测试一下addressC存储的是什么 这里先讲一下自己的思路，本来以为c的地址存储的应该是一个int值，这个值经过转换后应该是和addressA还有addressB一样的值，但是测试结果addressC存储的就是一个String实例，而后我又测试了一下String的char[] 1234567891011121314151617181920212223public static void test()&#123; String a = &quot;hello&quot;; String b = &quot;hello&quot;; String c = new String(&quot;hello&quot;); VirtualMachine vm = VM.current(); long addressA = vm.addressOf(a); long addressB = vm.addressOf(b); long addressC = vm.addressOf(c); // addressA+12是因为在String实例对象的12个字节开始是char[]引用 // 所以vm.getInt(null, addressA + 12)获取的就是String实例对象char数组的引用地址转换前的值 // getRealAddress是将获取到的int值转换为真实的内存地址，但是并不通用，具体参考VirtualMachine System.out.println(getRealAddress(vm.getInt(null, addressA + 12))); System.out.println(getRealAddress(vm.getInt(null, addressB + 12))); System.out.println(getRealAddress(vm.getInt(null, addressC + 12))); System.out.print(vm.getChar(null, getRealAddress(vm.getInt(null, addressA + 12)) + vm.arrayBaseOffset(&quot;char&quot;))); System.out.print(vm.getChar(null, getRealAddress(vm.getInt(null, addressA + 12)) + 2 + vm.arrayBaseOffset(&quot;char&quot;))); System.out.print(vm.getChar(null, getRealAddress(vm.getInt(null, addressA + 12)) + 4 + vm.arrayBaseOffset(&quot;char&quot;))); System.out.print(vm.getChar(null, getRealAddress(vm.getInt(null, addressA + 12)) + 6 + vm.arrayBaseOffset(&quot;char&quot;))); System.out.print(vm.getChar(null, getRealAddress(vm.getInt(null, addressA + 12)) + 8 + vm.arrayBaseOffset(&quot;char&quot;)));&#125; 可以看到，三个地址的char数组的引用地址是一致的，并且引用地址的内容没有问题 总结经过以上测试，我的观点是：String和char[]在常量池中是分开存储的，而常量池中的String对象的char[]则指向常量池中的char[] 如果是String str &#x3D; “hello”，则直接返回常量池中的String对象（没有则在常量池中创建） 如果是String str &#x3D; new String(“hello”)，那么则会创建一个String对象，然后这个String对象中的char[]指向常量池中的char[]，而不是创建一个指向常量池中String对象的指针 如果使用intern，会返回常量池中的String对象（没有则在常量池中创建） 这一篇介绍的String对象都是明确字符串内容的，没明确字符串内容的String对象和本篇的情况又不一样（比如String str &#x3D; FileUtil.readStr(File)这种），这些在另一篇文章里再提（现在还没写）","categories":["Java基础"]},{"title":"Java Reentrantlock","path":"/2025/01/07/Java Reentrantlock/","content":"ReentrantlockReentrantlock实现了Lock接口，Lock接口时Java定义的锁的规范，Reentrantlock基于AbstractQueuedSynchronizer（简称aqs）实现的，拥有Synchronized关键字的所有功能，同时还拥有锁中断，公平锁与非公平锁（synchronized只能是非公平锁） STATEstate是AQS的一个属性，初始值为0，线程在尝试获取锁是，通过cas将state的值从0改为1，若修改成功，则获取锁，否则添加到clh队列中，同时state还记录了重入的状态，每重入一次，state则加1 CLH什么是CLHCLH全称是Craig、Landin and Hagersten 队列，是单向链表实现的队列，**申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱节点释放了锁就结束自旋。**AQS实现的是一个双向链表实现的队列，属于CLH的变体，后面还是简称clh，结构如下图 AQS为什么要采用双向链表 因为原本的CLH只需要通过自旋获取上一个节点的状态，而上一个节点无需获取下一个节点的状态，所以单向即可实现，而AQS的实现是涉及到挂起的，挂起的线程必须通过上一个节点的线程唤醒，所以上一个线程需要获取到下一个节点的线程，故AQS实现的是双向链表 因为Reentrantlock中，线程获取锁的过程中可以中断，中断后的线程需要从列表中溢出，使用双向列表，可以直接将上一个节点指向下一个节点，以及将下一个节点指向上一个节点，避免了遍历列表带来的开销 Reentrantlock，线程加入队列中时，需要判断前置节点，如果前置节点是head，则直接竞争锁，如果前置节点不是head，则判断前置节点线程状态，确保前置节点线程状态正常，避免异常线程影响整体执行 公平锁与非公平锁ReentranLock的公平锁与非公平锁通过FairSync与NonfairSync实现，两者都继承Sync 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; /** * Performs &#123;@link Lock#lock&#125;. The main reason for subclassing * is to allow fast path for nonfair version. */ abstract void lock(); /** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123;//非公平锁在这里是直接竞争 setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; protected final boolean isHeldExclusively() &#123; // While we must in general read state before owner, // we don&#x27;t need to do so to check if current thread is owner return getExclusiveOwnerThread() == Thread.currentThread(); &#125; final ConditionObject newCondition() &#123; return new ConditionObject(); &#125; // Methods relayed from outer class final Thread getOwner() &#123; return getState() == 0 ? null : getExclusiveOwnerThread(); &#125; final int getHoldCount() &#123; return isHeldExclusively() ? getState() : 0; &#125; final boolean isLocked() &#123; return getState() != 0; &#125; /** * Reconstitutes the instance from a stream (that is, deserializes it). */ private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); setState(0); // reset to unlocked state &#125; &#125; 123456789101112131415161718static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; /** * Performs lock. Try immediate barge, backing up to normal * acquire on failure. */ final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125; 12345678910111213141516171819202122232425262728293031static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); &#125; /** * Fair version of tryAcquire. Don&#x27;t grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123;//公平锁在这里要先通过hasQueuedPredecessors方法判断该节点前置节点是否是head setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; &#125; 12345678910public final boolean hasQueuedPredecessors() &#123; // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());&#125; 公平锁和非公平锁的区别就在上述代码，非公平锁在获取锁之前，会先尝试将state设为0以获取锁。公平锁在尝试获取锁的时候是先判断队列中没有节点，没有节点则尝试获取锁，否则加入队列，而非公平锁在尝试获取锁时，不需要管队列有没有节点，直接尝试获取锁，获取失败再加入队列，所以非公平锁在调用lock方法时，在真正加入队列之前，会比公平锁多两次竞争的机会 非公平锁因为有多个线程同时竞争，效率比公平锁高，而公平锁可以避免线程因为长期竞争不到锁，而发生线程饥饿，ReentrantLock的非公平锁不是绝对的非公平，首次竞争失败后的线程还是要加入到队列中，按照公平锁的逻辑获取锁 读锁和写锁读写锁由java.util.concurrent.locks.ReentrantReadWriteLock实现的，读写锁的意义并不是字面上的控制某个属性的读写，而是指锁本身的权限 123ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock();ReentrantReadWriteLock.ReadLock readLock = reentrantReadWriteLock.readLock();ReentrantReadWriteLock.WriteLock writeLock = reentrantReadWriteLock.writeLock(); 读锁和写锁有以下特点 读锁可以多个线程进入，但是如果有线程进入读锁代码，其他线程就无法进入写锁的代码 如果写锁被线程持有，那读锁就无法被线程持有 总结起来就是，读锁和写锁互斥，写锁与写锁互斥，读锁与读锁不互斥（前提读锁和写锁属于同一个ReentrantReadWriteLock） 可中断锁 可中断的锁原理就是在进入方法的方法以及排队过程中判断线程的状态，如果已中断则退出排队并抛出中断错误，退出锁竞争，并且用户可自己通过检测异常实现线程中断 超时获取 超时获取在排队过程通过时间判断是否已经超出预期，如果超出预期，退出排队并抛出中断异常，实现退出锁竞争 等待与唤醒ReentrantLock的等待与唤醒是通过实现Condition完成的，主要逻辑是内部维护了一个链表，每次有线程使用await方法，就加入队列（加入队列实际逻辑比较复杂），调用signal的时候换默认唤醒链表头部的节点 主要是通过一下两个方法 123456789101112131415161718public final void await() throws InterruptedException &#123;if (Thread.interrupted()) throw new InterruptedException();Node node = addConditionWaiter();int savedState = fullyRelease(node);int interruptMode = 0;while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break;&#125;if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT;if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters();if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125; await对标于Object.wait，等待的作用 1234567public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first);&#125; signal对标于Object.notify，唤醒的作用，signalAll对标Object.notifyAll ReentrantLock lock方法这里以非公平锁为例介绍lock方法完整流程 123456final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; 非公平锁先通过compareAndSetState尝试获取锁，这是一个cas方法，获取失败后再调用acquire方法 12345public final void acquire(int arg) &#123;if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; acquire方法中，先通过tryAcquire方法尝试获取一次锁，获取失败后，加入队列排队，如果获取成功，则跳出判断（如果成功，!tryAcquire(arg)为false，那么会直接跳出判断） 12345678910111213141516171819202122protected final boolean tryAcquire(int acquires) &#123;return nonfairTryAcquire(acquires);&#125;final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false;&#125; 这两个方法就是尝试获取锁的主要代码了，基本逻辑就是先判断state的值，如果等于0就尝试竞争，否则判断是否是重入锁 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 这个方法是再队列中排队的逻辑，主要是判断上一个节点是不是head，然后判断是否进行park（阻塞）操作，和Synchronized的阻塞是一样的，都是调用操作系统的方法 123456789101112131415161718192021222324252627private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don&#x27;t park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 这个方法主要是判断是否进行park操作，如果当前节点之前的节点存在waitStatus大于0（即waitStatus为CANCELLED），就得先将之前的节点剔除掉，然后返回false，在acquireQueued方法中循环到下一次再进行判断 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 这个方法就是调用park方法阻塞线程（最终调用的是sun.misc.Unsafe#park（本地方法）），并且在被唤醒后返回线程中断状态 1234567891011121314151617181920212223242526272829303132private void cancelAcquire(Node node) &#123;if (node == null) return;node.thread = null;Node pred = node.prev;while (pred.waitStatus &gt; 0)node.prev = pred = pred.prev;Node predNext = pred.next;node.waitStatus = Node.CANCELLED;if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null);&#125; else &#123; int ws; if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; unparkSuccessor(node); &#125; node.next = node; // help GC&#125;&#125; 这个方法就是取消获取，基本逻辑就是将当前节点的上一个节点向下的指针指向当前节点的下一个节点，但是向上的指针不变，并将当前节点置为CANCELLED，这样下一个节点在获取锁时会将当前节点剔除掉 ReentrantLock unLock方法123public void unlock() &#123; sync.release(1);&#125; 123456789public final boolean release(int arg) &#123;if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true;&#125;return false;&#125; realease方法中主要就是判断是否释放锁成功，成功就唤醒head的下一个节点，让下一个节点重新竞争 123456789101112protected final boolean tryRelease(int releases) &#123;int c = getState() - releases;if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException();boolean free = false;if (c == 0) &#123; free = true; setExclusiveOwnerThread(null);&#125;setState(c);return free;&#125; tryRelease主要是判断是否是重入锁退出，如果是则state减一，返回false，如果不是，则返回true 12345678910111213141516private void unparkSuccessor(Node node) &#123;int ws = node.waitStatus;if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0);Node s = node.next;if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t;&#125;if (s != null) LockSupport.unpark(s.thread);&#125; unparkSuccessor主要是唤醒下一个线程，如果下一个线程已经取消掉了，则从tail一直往前推，直到不满足循环要求，退出循环（这个地方不是找到正常的节点就退出循环，而是要到不满足（t !&#x3D; null &amp;&amp; t !&#x3D; node）的时候（即找到当前节点下一个正常的节点）才退出循环），如果这个时候找到正常的节点了就唤醒，没有就直接返回","categories":["Java基础"]},{"title":"Arthas","path":"/2025/01/07/Arthas/","content":"Arthas 前言这里大部分介绍一下watch、tt这些实时观察方法执行的命令，这些命令的原理都通过字节码增强技术来实现的（动态插入字节码），会在指定类的方法中插入一些切面来实现数据统计和观测，可以通过jad命令查看增强后的字节码，如果观察的对象是接口，那么会把接口所有子类的字节码都增强，去哪儿网的开源项目Bistoury有个在线debug的功能，也是用到了字节码增强技术 另外，下面的命令都涉及到表达式，而且表达式的作用相当重要，表达式具体查看官方参考文档 ognlognl (Object-Graph Navigation Language) 是一种强大的表达式语言，用于获取和设置 Java 对象的属性，允许开发者通过简洁的语法访问复杂的对象图结构，从而简化了数据绑定、类型转换等任务，包括mybatis在内的很多框架都用到了ognl表达式 arthas的所有表达式就采用ognl，包括对象访问表达式、方法调用表达式、条件判断表达式等，所以了解ognl是很有必要的，arthas ognl表达式的特殊用法 arthas的ognl表达式的root是一个Advice类的实例，所以表达式中可以直接访问params、target、returnObj等变量，获取非静态变量的表达式都必须基于Advice实例，表达式核心变量 实际用的时候发现了一个问题，4.0.3版本不支持将returnObj这些对象作为ognl调用静态方法的参数，而4.0.4没有这个问题，经过测试，4.0.3版本的Ognl有问题，可以分别引入两个版本的arthas-core.jar包测试以下代码 12345678910111213141516171819202122232425262728293031323334import cn.hutool.core.map.MapUtil;import com.taobao.arthas.core.command.express.DefaultMemberAccess;import ognl.Ognl;import ognl.OgnlContext;import ognl.OgnlException;import java.util.Map;public class Person &#123; private String name; private String code; public Person(String name, String code) &#123; this.name = name; this.code = code; &#125; public static void main(String[] args) throws OgnlException &#123; OgnlContext ognlContext = new OgnlContext(new DefaultMemberAccess(true), null, null, null); Map&lt;Object, Object&gt; map = MapUtil.builder().put(&quot;person&quot;, new Person(&quot;张三&quot;, &quot;zs0001&quot;)).build(); Object value = Ognl.getValue(&quot;@cn.hutool.json.JSONUtil@toJsonStr(person)&quot;, ognlContext, map); System.out.println(value); &#125; public String getName() &#123; return name; &#125; public String getCode() &#123; return code; &#125;&#125; watchwatch命令主要的作用就是查看方法执行过程中的数据，个人认为相当于低配版的debug，可以查看入参、执行类实例、返参，并且可以通过ognl语句查看更详细的数据 这里使用Web UI举个例子，下面是测试的方法，我们通过watch命令调用fastjson的toJSONString方法，获取返回参数的json字符串 12@Select(&quot;select $&#123;selectFields&#125; from $&#123;tbne&#125; t $&#123;ew.customSqlSegment&#125;&quot;)Page&lt;Map&gt; page(IPage&lt;Map&gt; page, @Param(&quot;tbne&quot;) String tbne, @Param(&quot;selectFields&quot;) String selectFields, @Param(Constants.WRAPPER) Wrapper wrapper); 可以看到成功返回了经过toJSONString转换的page方法返回参数的json字符串，这里实际执行的命令是 1watch -f com.example.AssetOneMapMapper page -x 1 &#x27;@com.alibaba.fastjson.JSON@toJSONString(returnObj)&#x27; -f：代表在函数结束之后(正常返回和异常返回)观察，watch支持在执行前、异常返回时、正常返回时观察，具体参考文档 com.example.Mapper page：要观察的类以及方法，arthas支持通过表达式匹配，即可以匹配多个类或者方法 -x：表示遍历深度，比如入参有一个List，为1的时候只会展示List本身（即List的toString），那么为2的时候将会展示每个元素的内容，依次类推，默认值是 1，最大为4 ‘@com.alibaba.fastjson.JSON@toJSONString(returnObj)’：ognl表达式，表示使用JSON类的静态方法toJSONString转换returnObj，returnObj为观察方法的返回参数 tttt(TimeTunnel )命令的主要就是记录下指定方法每次调用的入参和返回信息，并能对这些不同的时间下调用进行观测，可以立即为方法执行数据的时空隧道，是watch命令的高配版，主要缺点是内存问题，需要手动释放，不然可能导致OOM，有两个比较重要的功能 查看数据：tt命令会记录每次执行涉及到的数据，然后我们可以通过命令查看记录的数据（对象的内部变量也可以查看），这一点比watch更强大，如果需要通过watch查看某个对象数据的内部变量，需要提交watch命令，然后再触发方法，每次更改需要重复这些操作，比较麻烦，而tt命令在这方面更简单 重新调用：tt命令可以通过id重新调用记录的具体某一次方法的执行 这里使用Web UI举个例子，测试的方法仍然使用上面watch测试的方法，我们调用tt命令记录方法执行 12@Select(&quot;select $&#123;selectFields&#125; from $&#123;tbne&#125; t $&#123;ew.customSqlSegment&#125;&quot;)Page&lt;Map&gt; page(IPage&lt;Map&gt; page, @Param(&quot;tbne&quot;) String tbne, @Param(&quot;selectFields&quot;) String selectFields, @Param(Constants.WRAPPER) Wrapper wrapper); 这里可以看到记录下了两次调用，这里参数没展示全，实际上还有returnObj以及throwExp，可以自行测试，这里实际执行的命令是 1tt -t com.example.Mapper page -t：表示希望记录下方法的每次执行情况，在记录时使用该参数，和-p、-w都属于主参数 com.example.Mapper page：表示要观察的类以及方法，arthas支持通过表达式匹配，即可以匹配多个类或者方法 查看数据 上面已经记录下了方法的执行情况，我们可以通过tt -w命令查看某一次记录的数据，需要使用ognl表达式，比如我现在想要查看page方法第四个入参wrapper的customSqlSegment的值，使用以下命令 1tt -w &#x27;params[3].customSqlSegment&#x27; -x 1 -i 1005 -w ‘params[3].customSqlSegment’：-w表示希望查看某一次记录的数据，后面是ognl表达式，即要查看的具体值（在上面的watch命令中有介绍），这里不仅可以查看数据，还可以调用方法，和-t、-p都属于主参数 -x 1：表示便利深度为1，既不展示数据内部的值 -i 1005：表示要查看的记录编号 可以看到返回了customSqlSegment具体的值 重新调用 想要使用重新调用的功能，直接点击Web UI上的invoke按钮即会重新调用，具体命令为 1tt -i 1005 -p -i 1005：代表要重新调用的记录 -p：表示希望重新调用某一次记录，和-t、-w都属于主参数 tracetrace命令的主要作用就是查看方法内部调用路径以及路径上的每个节点上耗时，不过trace只支持跟踪一级方法的调用链路，下个要继续查看下一级方法，可以使用动态trace，另外trace默认不会返回jdk方法的耗时，需要显式设置--skipJDKMethod false 这里使用Web UI举个例子，下面是测试的方法，我们通过trace命令查看这个方法的耗时 1234567891011private void response(ChannelHandlerContext ctx, Http2FrameStream requestStream, String responseBody) &#123; DefaultHttp2HeadersFrame headersFrame = new DefaultHttp2HeadersFrame( new DefaultHttp2Headers().status(&quot;200&quot;) .set(HttpHeaderNames.DATE, DateTime.now().toString()) .set(HttpHeaderNames.CONTENT_TYPE, &quot;text/plain;charset=UTF-8&quot;) .set(HttpHeaderNames.CONTENT_LENGTH, String.valueOf(responseBody.length())) ).stream(requestStream); DefaultHttp2DataFrame dataFrame = new DefaultHttp2DataFrame(Unpooled.wrappedBuffer(responseBody.getBytes()), true).stream(requestStream); ctx.writeAndFlush(headersFrame); ctx.writeAndFlush(dataFrame);&#125; 可以看到返回response方法下各个方法的耗时，这里实际执行的命令是 1trace com.example.netty.server.Https2Server$Http2ServerHandler response 这里仅涉及到需要观察的类以及方法，arthas支持通过表达式匹配，即可以匹配多个类或者方法，其他命令参考官网 stackstack命令的主要作用就是观察方法被调用的调用路径，在实际中可以用来确定当前方法是怎么被调用的，个人认为也可以理解为低配版的debug 这里使用Web UI举个例子，下面是测试的方法，我们通过stack命令查看这个方法的被调用路径 1234567891011private void response(ChannelHandlerContext ctx, Http2FrameStream requestStream, String responseBody) &#123; DefaultHttp2HeadersFrame headersFrame = new DefaultHttp2HeadersFrame( new DefaultHttp2Headers().status(&quot;200&quot;) .set(HttpHeaderNames.DATE, DateTime.now().toString()) .set(HttpHeaderNames.CONTENT_TYPE, &quot;text/plain;charset=UTF-8&quot;) .set(HttpHeaderNames.CONTENT_LENGTH, String.valueOf(responseBody.length())) ).stream(requestStream); DefaultHttp2DataFrame dataFrame = new DefaultHttp2DataFrame(Unpooled.wrappedBuffer(responseBody.getBytes()), true).stream(requestStream); ctx.writeAndFlush(headersFrame); ctx.writeAndFlush(dataFrame);&#125; 可以看到，返回了调用链路、classloader、线程id以及线程名，这里实际的命令是 1stack com.example.netty.server.Https2Server$Http2ServerHandler response 这里只涉及到了观察的类以及方法，arthas支持通过表达式匹配，即可以匹配多个类或者方法，其他参数参考官网 monitormonitor命令的主要作用就是对观察方法的调用进行监控（对一定时间内方法执行情况进行统计），这里不详细介绍了 retransform这个命令是单独的，和上面的命令不是一个原理，动态插入字节码可以理解为修改class的字节码，而retransform是替换class的字节码 retransform的作用是重新加载class文件，可以用来实现热部署，一般可以配合jad（反编译）、mc（编译）两个命令来使用 在这里介绍是因为平时用的可能也比较多，而且有个小问题记录一下，通过retransform替换class字节码后，通过stop关闭arhtas，重新打开arthas后，使用jad命令，会发现被替换过的类还原成替换之前的了，在实际使用时需要注意，参考：https://github.com/alibaba/arthas/issues/1891#issuecomment-900784364","categories":["部署运维"]},{"title":"使用Kubeadm部署kubernetes","path":"/2025/01/07/使用Kubeadm部署kubernetes/","content":"前言使用minikube部署kubernetes，实际上就是在主机上运行一个container，在容器中部署kubernetes，容器可以是docker，这种方式可以提前做好准备（包括环境、需要的镜像等），只需要用户下载好，运行即可，在本机部署测试比较方便，但是实际上的kubernetes是要直接部署在主机上的，这样才能构建多个主机组成的kubernetes集群 另外部署kubernetes需要一定的硬件条件，可以网上搜索，一般就是至少两核cpu、2G内存、20G硬盘 本次安装的是1.23版本，对于最新的1.32来说，算比较老的版本了，所以在有些地方会有一点区别 部署参考文档：安装Kubernetes(k8s) 阿里云kubernetes参考文档：什么是Kubernetes（K8s） 环境准备关闭防火墙123systemctl stop firewalld #关闭firewalldsystemctl disable firewalld #禁止开启自启firewalldiptables -F #清除iptables规则 关闭防火墙的原因（nftables后端兼容性问题，产生重复的防火墙规则） Theiptablestooling can act as a compatibility layer, behaving like iptables but actually configuring nftables. This nftables backend is not compatible with the current kubeadm packages: it causes duplicated firewall rules and breakskube-proxy 上面是老版本官方文档的说法，但是新版本文档中没有这段内容了，但是没有具体测试是否还有此问题 关闭selinux12setenforce 0 //临时关闭编辑/etc/selinux/config，修改&#x27;SELINUX=enforcing&#x27;为&#x27;SELINUX=disabled&#x27; //永久关闭，需要重启系统 关闭selinux的原因（关闭selinux以允许容器访问宿主机的文件系统） Setting SELinux in permissive mode by runningsetenforce 0andsed ...effectively disables it. This is required to allow containers to access the host filesystem, which is needed by pod networks for example. You have to do this until SELinux support is improved in the kubelet 上面是老版本官方文档的说法，但是新版本文档中没有这段内容了，但是没有具体测试是否还有此问题 关闭swap分区12swapoff -a //临时关闭编辑/etc/fstab，找到任何以&#x27;swap&#x27;结尾的行，并在其前面加上&#x27;#&#x27; //永久关闭，需要重启系统 关闭swap的原因，主要是因为内存管理导致的一些问题，在老版本上是必须关闭的，不关闭swap的话，kubelet会直接启动失败，但是新版本做出了一些调整，也可以打开swap分区，但是默认还是必须关闭，需要通过配置开启kubelet支持swap分区，具体参考官方文档：交换分区的配置 知乎参考：为什么要关闭swap、selinux、firewalld 修改内核参数1234567cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOFnet.bridge.bridge-nf-call-ip6tables = 1 //控制着 Linux 系统中桥接流量是否被传递给 ip6tables 防火墙规则处理net.bridge.bridge-nf-call-iptables = 1 //决定了桥接的 IPv4 流量是否会被传递给 iptables 防火墙规则进行处理net.ipv4.ip_forward = 1 //控制着系统是否可以转发 IPv4 数据包EOFsysctl --system //使配置生效 关于设置net.ipv4.ip_forward &#x3D; 1，官方有说明需要配置：启用 IPv4 数据包转发；而其他两个是网上参考文档中说明需要配置的，暂时未在官方文档中找到有说明，可以参考：K8s为啥要启用bridge-nf-call-iptables内核参数 加载ip_vs内核模块kube-proxy组件支持不同的代理模式，网上的说法是ip_vs性能比iptables更好，所以尽可能使用ip_vs，默认使用的是iptables，可以参考kube-proxy 切换 proxy mode 如果kube-proxy 模式为ip_vs则必须加载 12345modprobe ip_vsmodprobe ip_vs_rrmodprobe ip_vs_wrrmodprobe ip_vs_shmodprobe nf_conntrack_ipv4 设置下次开机自动加载 1234567cat &gt; /etc/modules-load.d/ip_vs.conf &lt;&lt; EOF ip_vsip_vs_rrip_vs_wrrip_vs_shnf_conntrack_ipv4EOF 修改本地hosts文件这一步是为集群做准备，编辑&#x2F;etc&#x2F;hosts，每台服务器都需要配置上集群中所有节点的主机名和ip（必要时修改可以通过hostnamectl set-hostname命令修改服务器的主机名），类似以下这种 123192.168.68.106 master.local192.168.68.107 node01.local192.168.68.108 node02.local 容器运行时本次安装测试使用的容器运行时是docker，安装参考：阿里云docker-ce镜像 需要注意k8s后面的版本不再支持docker作为容器运行时（需要额外安装cri-docker），推荐containerd 安装kubeadm、kubectl、kubelet介绍 kubeadm：是一个用于快速部署 Kubernetes 集群的命令行工具。它简化了集群初始化过程，并提供了建立安全最佳实践配置的途径，包括kubeadm init（创建集群）、kubeadm join（加入集群）等功能 kubectl：与 Kubernetes API 交互的命令行工具，用于管理和控制 Kubernetes 集群中的资源，包括deployment、pod等资源，是我们实际应用过程中使用最多的命令 kubelet：与上面两个不同，kubelet不是命令行工具，而是一个服务，它需要在正常启动的状态下才会进行工作，它的主要职责是确保容器都按照预期运行，并且负责与主节点通信以报告节点的状态，它的主要功能就是管理pod，在通过kubeadm命令建立或者加入集群后，下面的工作基本就是靠kubelet了，它会负责启动所有pod，包括服务器重启后，也是kubelet启动所有的pod，使整个k8s恢复工作 配置yum源123456789cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF 以上命令就是设置阿里的镜像源，目的是为了加快kubeadm这些工具的下载速度，这里有个地方需要注意，在v1.24.0开始仓库发生了变化，在配置时需要注意当前版本，具体参考：阿里云Kubernetes镜像 安装安装指定版本的kubeadm,kubelet,kubectl，这里安装v1.23.0，网上说好像通过阿里云拉取最新版本的镜像时会有问题，需要注意 :::tipsyum install -y kubelet-1.23.0 kubeadm-1.23.0 kubectl-1.23.0 &#x2F;&#x2F;-y代表安装过程中所有选项都选yes ::: 之前也有说到kubelet是一个服务，所以设置开机自启 :::tipssystemctl enable kubelet ::: 安装完成后遇到一个问题，就是kubelet启动不起来，看日志说是少了什么配置文件，后来网上搜了一下，在执行kubeadm init或者kubeadm join后，会自动生成这个配置文件，kubelet也会自动启动好（没有其他问题的情况下） 另外kubelet启动还需要和容器运行时使用一样的cgroup驱动，这部分内容可以参考官方：cgroup 驱动 可以通过以下命令查看kubelet当前使用的驱动 :::tipscat &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;config.yaml | grep cgroupDriver ::: 然后就是配置容器运行时的驱动了，这里以docker举例，在&#x2F;etc&#x2F;docker&#x2F;daemon.json中设置以下内容，如果文件中已经有内容了，则将下面大括号里的配置加入到原先内容的大括号当中，配置完重启docker即可 :::tips{“exec-opts”: [“native.cgroupdriver&#x3D;systemd”]} ::: 部署Kubernetes Master节点通过kubeadm构建kubernetes集群可参考官方文档：使用kubeadm创建集群 在主节点服务器上执行以下命令 123456kubeadm init \\ --kubernetes-version 1.23.0 \\ --apiserver-advertise-address=0.0.0.0 \\ --service-cidr=10.96.0.0/16 \\ --pod-network-cidr=10.245.0.0/16 \\ --image-repository registry.aliyuncs.com/google_containers –kubernetes-version：指定版本，需要和上边安装的kubelet,kubead,kubectl保持一致 –apiserver-advertise-address：为通告给其它组件的IP，一般应为master节点的IP地址 –service-cidr：指定service网络，不能和node网络冲突 –pod-network-cidr：指定pod网络，不能和node网络、service网络冲突 –image-repository：定镜像源，由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址，如果k8s版本比较新，可能阿里云没有对应的镜像，就需要自己从其它地方获取镜像了。 下面正常启动下的日志，包括拉取镜像（也可以提前拉取，比如通过kubeadm –kubernetes-version 1.23.0 config images pull）、创建配置文件等 下面是启动成功后的日志 第一个红框是本机配置kubectl需要执行的命令，分别执行完这几条命令之后，就可以使用kubectl操作kubernetes集群资源了 第二个红框是启动服务器再加入kubernetes集群时，需要执行的命令，所以这条命令需要记录下来 部署Kubernetes Worker节点这里需要注意，在worker节点的服务器上也需要做好环境准备和kubeadm等工具安装的工作，然后在worker节点运行上面记录的命令即可，比如这里是 12kubeadm join 192.168.255.101:6443 --token jq3eqc.9y1y3h89kljjipjm \\\t--discovery-token-ca-cert-hash sha256:275b115804658388bba00267d5cfd85f04c31d6ab45c141093e890b4d72f5e91 下面是运行成功的日志 运行完之后，回到主节点执行kubectl get node查看节点状态 发现两个节点都是NotReady，因为缺失网络插件导致的 安装网络插件具体可以参考官方文档：安装 Pod 网络附加组件 这里安装flannel 从官网下载yml文件 :::tipswget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml ::: 修改文件 修改文件中的Network，使其与kubeadm init中的pod-network-cidr参数一致 修改前 修改后 然后执行yml文件 :::tipskubectl apply -f kube-flannel.yml ::: 执行后查看flannel :::tipskubectl get pod -n kube-flannel -o wide ::: 发现启动正常，但是继续查看node，发现仍然是NotReady 查看kube-system命名空间的pod","categories":["部署运维"]},{"title":"使用Minikube部署kubernetes","path":"/2025/01/07/使用Minikube部署kubernetes/","content":"准备需要的三个东西：minikube，docker，kubectl minikube：minikube支持一键部署kubernetes集群，用于单机测试和日常开发，minikube安装可参考官网：https://minikube.sigs.k8s.io/docs/start/，参照官网根据不同的系统到不同的地址下载对应的安装包即可，这个网站还有minikube相关知识关于使用minikube部署kubernetes的使用可以参考kubernetes官网：https://kubernetes.io/zh-cn/docs/tutorials/hello-minikube/ docker：docker是Kubernetes支持的一种容器运行时（container runtime），用于创建和管理容器，需要手动下载，具体可以参考：阿里云docker-ce镜像 kubectl：kubectl是kubenetes命令行工具，通过kubectl可以部署和管理应用，查看各种资源，创建，删除和更新组件，安装参考 启动docker启动首先，启动docker，这里启动时遇到一个问题：Error creating default “bridge” network: Failed to program NAT chain: INVALID_ZONE: docker，原因是因为版本大于等于 20.10.0的docker会自动创建了一个名为docker的 firewalld zone，需要将docker0虚拟网卡加入到这个zone才能正常启动，一般情况下docker0网卡应该默认就在docker zone下面 创建用户minikube不能直接在root用户下启动，所以启动minikube的用户需要加入到docker用户组才能启动、操作docker 123456#创建docker用户组，一般情况下，安装docker时，会自动创建docker用户组sudo groupadd docker#普通用户加入docker用户组sudo usermod -aG docker $&#123;用户名&#125;#重启dockersudo systemctl restart docker minikube启动minikube启动命令，这里启动时遇到一个问题，minikube内部所需的镜像等无法正常下载，本地环境是虚拟机，为虚拟机的ens33网卡配置dns后，下载正常 1minikube start --driver=&quot;docker&quot; --registry-mirror=&quot;https://kn0t2bca.mirror.aliyuncs.com&quot; –driver：指定容器运行时 –registry-mirror：镜像地址，minikube拉取镜像时的地址，也就是minikube内部docker的镜像地址，可以进入minikube后执行docrer info确认如果需要更换的话，必须先执行minikube delete删除当前minikube环境（所有deployment、pod等都没了），在执行start命令，还没有找到其他办法 进入minikubeminikube的启动实际上是创建了一个docker容器，使用docker容器作为运行kubernetes的主机 进入方法包括两种，一种是通过docker exec（进入后是root用户），一种是通过minikube ssh命令（进入后是docker用户） 可以到容器内部，检查相关内容，例如网络，在外网环境下，minikube必须要能够访问外网才能在首次启动时正常下载需要的镜像并且在之后的使用中正常拉取镜像。后面所有pod管理的容器实际上也是minikube容器下创建的 仪表板minikube启动后可以通过一个命令打开一个浏览器或输出一个url，可以访问kubernetes集群控制台 1minikube dashboard --url//加上--url会输出一个url，不加的话，系统会尝试打开一个浏览器自动访问 这个命令的作用是展示kubernetes的dashboard组件提供的地址，但是minikube默认只代理127.0.0.1的流量，这时候可以使用kubectl proxy命令，kubectl proxy将本地流量代理到Kubernetes集群的API Server，我们如果需要代理其他网卡的流量，可以单独执行kubectl proxy命令，具体路径参考minikube dashboard –url输出的路径，只是需要注意ip和端口的变化 1kubectl proxy --port=8080 --address=&#x27;192.168.255.100&#x27; --accept-hosts=&#x27;^.*&#x27; &amp; –port&#x3D;8080：代理端口为8080 –address&#x3D;’192.168.255.100’：代理的ip，配合–port参数，可以理解为将访问192.168.255.100:8080的请求转发到Kubernetes集群 –accept-hosts&#x3D;’^.*’ &amp;：接受哪些主机的访问请求，这里的值代表全部 相关内容这里了解Deployment、Endpoint、Pod、Service等知识 DeploymentKubernetes Deployment 是一种用于管理容器化应用实例的控制器，它确保在集群中按照用户定义的规格（如副本数量、镜像版本等）持续运行并能自动进行滚动更新与恢复。一般情况下，在命令当中，deployment可以被简写为deploy 相关命令创建deployment命令，除了create通过命令创建，还可以通过apply使用yaml文件创建deployment，这里使用create命令示例 1kubectl create deploy hello-node --image=nginx --replicas=3 hello-node：deployment的名称 –image&#x3D;nginx：使用nginx的镜像 –replicas&#x3D;3：启动三个副本（Pod），并且确保Deployment应该始终保持 3 个副本（Pod）的数量在线，当有 Pod 故障时，Kubernetes 会自动创建新的 Pod 来替换故障的 Pod，以保持副本数目的稳定 deployment创建完后也可以通过scale修改副本数 1kubectl scale deploy hello-node --replicas=2 hello-node：deployment的名称 –replicas&#x3D;2：修改副本数 deployment创建后可通过get deployment查看所有deployment 1kubectl get deploy 滚动更新滚动更新是deployment的功能之一，在使用kubectl apply -f命令时，如果deployment已存在并且内容发生了变化，则会重新创建一个ReplicaSet并滚动创建新的pod（即等新的pod启动后才会关闭旧的pod，保证任何时候都能正常访问），需要注意通过create命令，无法实现滚动更新 滚动恢复在进行上面的滚动更新操作后，旧的ReplicaSet并不会再使用，它所管理的pod也会被陆续删除，但是旧的ReplicaSet本身会被保留，一个ReplicaSet可以代表一个版本，可以通过kubectl rollout history查看版本列表 1kubectl rollout history deployment &lt;deployment-name&gt; --revision=3 #--revision：可选，代表查看具体的版本 可通过kubectl rollout undo命令滚动回退版本（保证任意时刻都有pod在运行） 1kubectl rollout undo deployment &lt;deployment-name&gt; --to-revision=3 #--to-revision：可选，代表回退到指定版本 Replica SetReplica Sets是Kubernetes中用于确保指定数量的Pod副本按照同一模板运行并保持一致性的控制器，它具备自动扩缩容和自我修复能力，确保Pod服务的高可用性和稳定性。它的名称通常就是deployment+随机字符串。在创建deployment时，Replica Sets会被自动创建。一般情况下，命令中的replicaset可以被简写为rs 相关命令可通过get replicaset获取所有replicaset 1kubectl get rs PodPod是Kubernetes中部署和管理容器化应用的基本单位，它封装了一个或多个紧密相关的容器，这些容器共享存储卷、网络命名空间和IPC（进程间通信），共同组成一个运行环境。Pod强调了容器间的协同工作，确保这些容器一起调度、一起运行，并且具有唯一的IP地址和网络标识，以实现高效的微服务架构部署与管理。 相关命令可通过get pods获取所有pod 1kubectl get pods 可通过describe 查看pod日志 1kubectl describe pod &lt;pod-name&gt; 可通过exec命令进入pod创建的容器 12kubectl exec -it &lt;pod-name&gt; -- bash//pod只有一个容器的情况下kubectl exec -it &lt;pod-name&gt; [-c &lt;container-name&gt;] -- bash//pod多个容器的情况下 访问podPod可以通过集群api访问，举个例子 http://192.168.255.100:8080/api/v1/namespaces/default/pods/hello-node-86c8975888-rqqms:80/proxy/ 例子中的hello-node-86c8975888-rqqms代表容器，80代表访问容器的端口，后面的&#x2F;proxy&#x2F;是必须的，综合起来hello-node-86c8975888-rqqms:80&#x2F;proxy&#x2F;相当于访问容器的80端口，如果需要访问具体资源，则为hello-node-86c8975888-rqqms:80&#x2F;proxy&#x2F;+资源路径 ServiceKubernetes Service是一个抽象层，它定义了一个稳定的网络入口点，通过标签选择器将流量路由到后端的一组Pod实例上，并提供负载均衡和服务发现机制。简单来说，Service是连接和管理Pod间通信以及对外暴露服务的核心组件。service拥有很多功能，例如：服务发现、负载均衡。一般命令中的service可以被简写为svc 相关命令可通过kubectl expose deployment发布service 1kubectl expose deployment hello-node --type=LoadBalancer --port=80 --target-port=8080 deployment：这里指为指定的deployment创建service，但是不但可以为deployment创建service，还可以为replicaset、pod等创建service hello-node：deployment的名字，如果是为replicaset、pod创建service，那么就是replicaset、pod的名称 –type&#x3D;LoadBalancer：type决定了服务如何路由流量到后端Pod，包括 ClusterIP (默认类型)： 创建一个仅在集群内部可以访问的服务，由集群内其他服务或Pod通过内部IP地址进行访问。 NodePort：在ClusterIP的基础上，还会在每个Node上开放一个特定端口（30000-32767范围内的随机端口或者指定端口），允许外部客户端通过这个端口直接访问到服务。这意味着集群外部可以通过任何节点的该端口访问服务。这里的Node在minikube环境下可以理解为minikube容器，普通情况下就是运行kubernetes的节点 LoadBalancer： 适用于云环境，在NodePort的基础上，会在云提供商层面创建一个负载均衡器，将外部流量转发到Service。负载均衡器会分配一个公网IP地址，使得外部网络可以直接访问到服务。如果条件允许，可通过外网ip访问 ExternalName： 将Service映射到DNS名称，不创建集群内部的Endpoints。当集群需要引用集群外的服务时，这种类型非常有用 Headless Service（无头服务）： 不为Service分配Cluster IP，而是创建没有代理的Endpoints资源对象，通常与StatefulSet配合使用，直接通过Pod的DNS名称进行通信 –port：service监听端口 –target-port&#x3D;8080：目标端口，结合配置–port可以理解为发起到service的80端口的请求会被转发到pod内部的8080端口 通过kubectl get services命令查看service 1kubectl get services 访问service 在上图的hello-node服务中，type&#x3D;LoadBalancer代表使用LoadBalancer模式路由，cluster-ip&#x3D;10.100.105.87是为Service创建的集群IP 通过集群api访问service和pod一样，也可以通过集群api访问，举个例子 http://192.168.255.100:8080/api/v1/namespaces/default/services/hello-node:80/proxy/ 格式和pod类似，其中services对应上面例子的pods，代表类型，hello-node是service的名字，80是访问service的端口，即创建service是配置的–port 通过service生成的集群ip访问上面的提到ClusterIP、NodePort、LoadBalancer模式下，都会为Service生成一个集群ip，这个ip只能在pod内部访问，并且在pod内部还可以通过Service的名称访问，名称对应的ip地址就是Servicd的集群ip地址 通过静态端口访问上面提到的NodePort、LoadBalancer模式下，会为Node创建一个静态端口，可以在集群外通过这个静态端口访问Service，在minikube环境下，minikube容器就是一个Node，所以可以通过minikube的ip加上静态端口访问Service，下图的是minikube容器的ip，即kubernetes Node的ip 服务发现kubernetes的服务发现功能就是通过service实现的，kubernetes会根据servcie的名称建立一个DNS记录，而kubelet 在启动 Pod 时也会配置 Pod 中的 resolv.conf 文件，指向集群中的 DNS 服务器，所以在pod内部可以通过http:&#x2F;&#x2F;&lt;service的名称&gt;:的方式访问service 负载均衡service默认提供了基本的四层（TCP&#x2F;UDP）负载均衡能力，该能力主要通过 kube-proxy 组件实现，并且基于 IP 地址和端口进行分发流量，使用一定的策略将请求分发到后端 Pod。这里提到的四层（TCP&#x2F;UDP）负载均衡能力，可以理解为nginx的stream模块，而nginx的http模块，可以对具体http路径进行代理负载，实现七层(HTTP&#x2F;HTTPS)负载均衡，service在不借助其他工具的情况下无法实现类似nginx的http模块的功能 EndpointEndpoint（端点）是 Service 与 Pod 实例之间的逻辑连接。一个 Endpoint 对象代表了 Pod 的 IP 地址和端口号的集合，这些 Pod 为同一个 Service 提供服务，Service 通过 Cluster IP 和端口提供统一的服务入口，而实际的请求会被路由到这些已经记录在 Endpoints 中的 Pod 实例上。这样就实现了对后端应用实例的负载均衡和服务发现。Endpoint会根据pod的状态自动更新，确保Service始终指向可用的pod实例。在Kubernetes v1.17及之后的版本，引入了EndpointSlices用于代替Endpoint。一般命令中的endpoints可以被简写为ep 相关命令可通过get endpoints获取端点 1kubectl get endpoints 探针探针在Kubernetes中的作用是对Pod进行健康检查，一个额外的知识，容器在创建时镜像执行的第一个命令或者应用程序会作为容器内的主进程（也称为PID 1）。这个主进程的生命周期直接决定了容器的生命周期，也就是说如果一个运行nginx的docker，当nginx的进程死掉之后，docker容器也就停止了，这时候pod会直接重启，即pod会删除原容器并通过镜像重新运行一个容器 Kubernetes包含三种探针，三种探针检查时机以及检测失败后的动作有所不同 存活探针（Liveness Probe）： 目的是确定容器内的主应用程序是否还在正常运行。如果存活探针检测失败，Kubernetes会认为容器内的主进程已死锁或不可用，进而根据Pod的重启策略重启容器。 就绪探针（Readiness Probe）： 用于决定容器是否准备好开始接收请求。如果就绪探针检测失败，Kubernetes会从服务负载均衡列表中移除该容器，直到就绪探针再次成功，这意味着容器所在Pod在此期间不会接受新的流量。这里并不会重启pod。 启动探针（Startup Probe）： 判断容器内的应用是否已经正确启动。如果提供了启动探针，Kubernetes会在应用完全启动之前忽略其他的存活探针和就绪探针。只有当启动探针成功后，才会开始执行其他探针。如果启动探针失败，Kubernetes会杀死容器并依据重启策略进行重启。 这三种探针都可以通过以下方式执行检测： exec: 执行容器内部的特定命令，根据命令的退出状态码判断探针的成功与否。 tcpSocket: 尝试通过TCP连接到容器的指定端口，如果连接成功则认为探针成功。 httpGet: 发起HTTP GET请求到容器的服务端点，根据响应的状态码判断探针的成功与否。 下面是Liveness Probe的TcpSocket检测方式的示例，其余两个探针只需要示例中的改livenessProbe成readinessProbe或者startupProbe即可，如需更改检测方式，只需将配置中tcpSocket改为exec或者httpGet即可 1234567891011121314151617181920212223242526apiVersion: apps/v1 #用来指定资源对象使用的API版本kind: Deployment #指定资源对象metadata: #创建的资源对象属性 name: demo #创建的资源对象名称spec: #定义Deployment对象的具体配置和期望状态 replicas: 1 #pod（副本）数量 selector: #选择器配置，这里选择器的作用是匹配到的pod归于这个deployment管理 matchLabels: #通过labels选择匹配 app: demo #匹配labels属性包含app: demo的pod template: #模板，即pod相关配置 metadata: #定义pod属性 labels: #定义pod的lables属性 app: demo #定义pod的labels属性为app: demo，这里配置需与上面的一样，这样才能将创建的pod归于deployment管理 spec: #定义pod对象的具体配置和期望状态 containers: #pod下容器相关配置 - name: my-container #容器名称 image: demo #容器使用的镜像 imagePullPolicy: IfNotPresent #镜像拉取策略，IfNotPresent指只要本地有这个镜像，则不拉取，不考虑版本，而Always配置会考虑版本，如果本地镜像的版本是latest，则会拉取，Never配置只从本地获取，不会拉取，如果本地没有，则报错 livenessProbe: #livenessProbe探针相干配置 tcpSocket: #livenessProbe配置通过tcpSocket对容器进行检测 port: 8081 #配置tcpSocket检测的端口 initialDelaySeconds: 1 #容器启动后多久开始进行检测 periodSeconds: 5 #检测频率，隔多久检测一次 timeoutSeconds: 1 #探针执行检测请求后，等待响应的超时时间 successThreshold: 1 #探针检测失败后认为成功的最小连接成功次数，默认为1s，在liveness探针中必须为1s，最小为1s failureThreshold: 1 #探测失败的重试次数，重试一定次数后将认为失败 关于具体的容器，我们使用Java编写一个程序用于检测是否有进行tcp检测 1234567891011121314151617181920212223242526272829303132333435@RestControllerpublic class TestController implements InitializingBean &#123; private ServerSocket serverSocket; @GetMapping(&quot;/closeSocket&quot;) public String closeSocket()&#123; try &#123; serverSocket.close(); &#125; catch (IOException e) &#123; return &quot;false&quot;; &#125; return &quot;true&quot;; &#125; @Override public void afterPropertiesSet() throws Exception &#123; try &#123; serverSocket = new ServerSocket(8081); new Thread(() -&gt; &#123; while(true)&#123; Socket accept; try &#123; accept = serverSocket.accept(); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; System.out.println(DateTime.now() + &quot;:&quot; + accept.getRemoteSocketAddress()); &#125; &#125;).start(); &#125; catch (IOException e) &#123; throw new RuntimeException(); &#125; &#125;&#125; 这段代码打开一个端口为8081的ServerSocket，用于kubernetes做检测，并且提供一个方法用于关闭此ServerSocket，用于测试kubernetes是否会重启pod 可以看到每隔5秒，程序就会建立一个tcp连接，证明kubernetes探针已经生效了 我们调用closeSocket接口关闭serverSocket，看一下是否会pod是否会重启 查看pod的事件，发现探针检测到了端口关闭，并且pod进行了重启 查看容器日志，发现重新运行了","categories":["部署运维"]},{"title":"Nacos服务注册流程","path":"/2025/01/07/Nacos服务注册流程/","content":"临时节点注册过程开始测试源码时，发现注册接口的断点无论如何都不会执行，打印语句也不会执行，最后发现nacos设置了一个过滤器，会根据注册服务的ip端口经过hash后的值进行负载均衡，选择一个节点处理请求，所以并不一定会在请求的节点进入服务注册接口，下面就是过滤器doFilter代码，这个过滤器只会对&#x2F;v1&#x2F;ns&#x2F;相关接口生效 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain)throws IOException, ServletException &#123; ReuseHttpServletRequest req = new ReuseHttpServletRequest((HttpServletRequest) servletRequest); HttpServletResponse resp = (HttpServletResponse) servletResponse; String urlString = req.getRequestURI(); if (StringUtils.isNotBlank(req.getQueryString())) &#123; urlString += &quot;?&quot; + req.getQueryString(); &#125; try &#123; Method method = controllerMethodsCache.getMethod(req); String path = new URI(req.getRequestURI()).getPath(); if (method == null) &#123; throw new NoSuchMethodException(req.getMethod() + &quot; &quot; + path); &#125; if (!method.isAnnotationPresent(CanDistro.class)) &#123; filterChain.doFilter(req, resp); return; &#125; String distroTag = distroTagGenerator.getResponsibleTag(req); if (distroMapper.responsible(distroTag)) &#123; filterChain.doFilter(req, resp); return; &#125; // proxy request to other server if necessary: String userAgent = req.getHeader(HttpHeaderConsts.USER_AGENT_HEADER); if (StringUtils.isNotBlank(userAgent) &amp;&amp; userAgent.contains(UtilsAndCommons.NACOS_SERVER_HEADER)) &#123; // This request is sent from peer server, should not be redirected again: Loggers.SRV_LOG.error(&quot;receive invalid redirect request from peer &#123;&#125;&quot;, req.getRemoteAddr()); resp.sendError(HttpServletResponse.SC_BAD_REQUEST, &quot;receive invalid redirect request from peer &quot; + req.getRemoteAddr()); return; &#125; final String targetServer = distroMapper.mapSrv(distroTag); List&lt;String&gt; headerList = new ArrayList&lt;&gt;(16); Enumeration&lt;String&gt; headers = req.getHeaderNames(); while (headers.hasMoreElements()) &#123; String headerName = headers.nextElement(); headerList.add(headerName); headerList.add(req.getHeader(headerName)); &#125; final String body = IoUtils.toString(req.getInputStream(), StandardCharsets.UTF_8.name()); final Map&lt;String, String&gt; paramsValue = HttpClient.translateParameterMap(req.getParameterMap()); RestResult&lt;String&gt; result = HttpClient .request(HTTP_PREFIX + targetServer + req.getRequestURI(), headerList, paramsValue, body, PROXY_CONNECT_TIMEOUT, PROXY_READ_TIMEOUT, StandardCharsets.UTF_8.name(), req.getMethod()); String data = result.ok() ? result.getData() : result.getMessage(); try &#123; WebUtils.response(resp, data, result.getCode()); &#125; catch (Exception ignore) &#123; Loggers.SRV_LOG.warn(&quot;[DISTRO-FILTER] request failed: &quot; + distroMapper.mapSrv(distroTag) + urlString); &#125; &#125; catch (AccessControlException e) &#123; resp.sendError(HttpServletResponse.SC_FORBIDDEN, &quot;access denied: &quot; + ExceptionUtil.getAllExceptionMsg(e)); &#125; catch (NoSuchMethodException e) &#123; resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, &quot;no such api:&quot; + req.getMethod() + &quot;:&quot; + req.getRequestURI()); &#125; catch (Exception e) &#123; Loggers.SRV_LOG.warn(&quot;[DISTRO-FILTER] Server failed: &quot;, e); resp.sendError(HttpServletResponse.SC_INTERNAL_SERVER_ERROR, &quot;Server failed, &quot; + ExceptionUtil.getAllExceptionMsg(e)); &#125; &#125; 经过过滤器后，会在对应的节点进入服务注册的接口 123456789101112131415161718@CanDistro@PostMapping@Secured(action = ActionTypes.WRITE)public String register(HttpServletRequest request) throws Exception &#123; final String namespaceId = WebUtils .optional(request, CommonParams.NAMESPACE_ID, Constants.DEFAULT_NAMESPACE_ID); final String serviceName = WebUtils.required(request, CommonParams.SERVICE_NAME); NamingUtils.checkServiceNameFormat(serviceName); final Instance instance = HttpRequestInstanceBuilder.newBuilder() .setDefaultInstanceEphemeral(switchDomain.isDefaultInstanceEphemeral()).setRequest(request).build(); getInstanceOperator().registerInstance(namespaceId, serviceName, instance); NotifyCenter.publishEvent(new RegisterInstanceTraceEvent(System.currentTimeMillis(), &quot;&quot;, false, namespaceId, NamingUtils.getGroupName(serviceName), NamingUtils.getServiceName(serviceName), instance.getIp(), instance.getPort())); return &quot;ok&quot;;&#125; 经过不断调用，会进入到ClientOperationServiceProxy类 12345@Overridepublic void registerInstance(Service service, Instance instance, String clientId) throws NacosException &#123; final ClientOperationService operationService = chooseClientOperationService(instance); operationService.registerInstance(service, instance, clientId);&#125; 这里使用了策略模式，根据服务是否是临时节点，选择响应的处理方法，这里我们先讲临时节点注册过程 12345678910111213141516171819202122@Overridepublic void registerInstance(Service service, Instance instance, String clientId) throws NacosException &#123; NamingUtils.checkInstanceIsLegal(instance); Service singleton = ServiceManager.getInstance().getSingleton(service); if (!singleton.isEphemeral()) &#123; throw new NacosRuntimeException(NacosException.INVALID_PARAM, String.format(&quot;Current service %s is persistent service, can&#x27;t register ephemeral instance.&quot;, singleton.getGroupedServiceName())); &#125; Client client = clientManager.getClient(clientId); if (!clientIsLegal(client, clientId)) &#123; return; &#125; InstancePublishInfo instanceInfo = getPublishInfo(instance); client.addServiceInstance(singleton, instanceInfo); client.setLastUpdatedTime(); client.recalculateRevision(); NotifyCenter.publishEvent(new ClientOperationEvent.ClientRegisterServiceEvent(singleton, clientId)); NotifyCenter .publishEvent(new MetadataEvent.InstanceMetadataEvent(singleton, instanceInfo.getMetadataId(), false));&#125; 这里会判断一下要注册的服务所在的服务组是否也是临时的，不是就会报错，这个方法中比较重要的是client.addServiceInstance(singleton, instanceInfo)，负责添加服务实例，并且推送给其他节点 123456789101112public boolean addServiceInstance(Service service, InstancePublishInfo instancePublishInfo) &#123; if (null == publishers.put(service, instancePublishInfo)) &#123; if (instancePublishInfo instanceof BatchInstancePublishInfo) &#123; MetricsMonitor.incrementIpCountWithBatchRegister(instancePublishInfo); &#125; else &#123; MetricsMonitor.incrementInstanceCount(); &#125; &#125; NotifyCenter.publishEvent(new ClientEvent.ClientChangedEvent(this)); Loggers.SRV_LOG.info(&quot;Client change for service &#123;&#125;, &#123;&#125;&quot;, service, getClientId()); return true;&#125; NotifyCenter.publishEvent(new ClientEvent.ClientChangedEvent(this))将服务节点改变推送给其他nacos节点，每个事件都会有对应的发布者 1234567891011121314151617private static boolean publishEvent(final Class&lt;? extends Event&gt; eventType, final Event event) &#123; if (ClassUtils.isAssignableFrom(SlowEvent.class, eventType)) &#123; return INSTANCE.sharePublisher.publish(event); &#125; final String topic = ClassUtils.getCanonicalName(eventType); EventPublisher publisher = INSTANCE.publisherMap.get(topic); if (publisher != null) &#123; return publisher.publish(event); &#125; if (event.isPluginEvent()) &#123; return true; &#125; LOGGER.warn(&quot;There are no [&#123;&#125;] publishers for this event, please register&quot;, topic); return false;&#125; 这里会根据事件类型获取对应的发布者，发布者会有响应的订阅者（subscribers），像服务节点改变事件的订阅者就是所有其他nacos节点，这里用到了设计模式中的观察者模式，订阅者就是观察者，发布者具体发布的代码可参考com.alibaba.nacos.naming.core.v2.event.publisher.NamingEventPublisherr类 123456789public boolean publish(Event event) &#123; checkIsStart(); boolean success = this.queue.offer(event); if (!success) &#123; Loggers.EVT_LOG.warn(&quot;Unable to plug in due to interruption, synchronize sending time, event : &#123;&#125;&quot;, event); handleEvent(event); &#125; return true; &#125; 原理就是发布者会将事件存放到BlockingQueue中，另外一个方法不断的从BlockingQueue中获取并执行事件，通知订阅者 123456789101112private void handleEvents() &#123; while (!shutdown) &#123; try &#123; final Event event = queue.take(); handleEvent(event); &#125; catch (InterruptedException e) &#123; Loggers.EVT_LOG.warn(&quot;Naming Event Publisher &#123;&#125; take event from queue failed:&quot;, this.publisherName, e); // set the interrupted flag Thread.currentThread().interrupt(); &#125; &#125;&#125; 12345678910111213private void handleEvent(Event event) &#123; Class&lt;? extends Event&gt; eventType = event.getClass(); Set&lt;Subscriber&lt;? extends Event&gt;&gt; subscribers = subscribes.get(eventType); if (null == subscribers) &#123; if (Loggers.EVT_LOG.isDebugEnabled()) &#123; Loggers.EVT_LOG.debug(&quot;[NotifyCenter] No subscribers for slow event &#123;&#125;&quot;, eventType.getName()); &#125; return; &#125; for (Subscriber subscriber : subscribers) &#123; notifySubscriber(subscriber, event); &#125;&#125; 12345678910111213141516public void notifySubscriber(Subscriber subscriber, Event event) &#123; if (Loggers.EVT_LOG.isDebugEnabled()) &#123; Loggers.EVT_LOG.debug(&quot;[NotifyCenter] the &#123;&#125; will received by &#123;&#125;&quot;, event, subscriber); &#125; final Runnable job = () -&gt; subscriber.onEvent(event); final Executor executor = subscriber.executor(); if (executor != null) &#123; executor.execute(job); &#125; else &#123; try &#123; job.run(); &#125; catch (Throwable e) &#123; Loggers.EVT_LOG.error(&quot;Event callback exception: &quot;, e); &#125; &#125;&#125; 这几个方法就是将事件推送给所有订阅者，subscriber.onEvent(event)就是将事件提交给订阅者，后面可能还会涉及到很多阻塞队列的使用，阻塞队列可以很好的应对并发问题，具体可以参考源码，推送代码最后面会会构造一个_type属性为DistroDataRequest的com.alibaba.nacos.api.grpc.auto.Payload，并调用io.grpc.ClientCall#sendMessage方法，提交给其他nacos节点，这是grpc客户端的接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344public abstract class ClientCall&lt;ReqT, RespT&gt; &#123; public ClientCall() &#123; &#125; public abstract void start(Listener&lt;RespT&gt; var1, Metadata var2); public abstract void request(int var1); public abstract void cancel(@Nullable String var1, @Nullable Throwable var2); public abstract void halfClose(); public abstract void sendMessage(ReqT var1); public boolean isReady() &#123; return true; &#125; @ExperimentalApi(&quot;https://github.com/grpc/grpc-java/issues/1703&quot;) public void setMessageCompression(boolean enabled) &#123; &#125; @ExperimentalApi(&quot;https://github.com/grpc/grpc-java/issues/2607&quot;) public Attributes getAttributes() &#123; return Attributes.EMPTY; &#125; public abstract static class Listener&lt;T&gt; &#123; public Listener() &#123; &#125; public void onHeaders(Metadata headers) &#123; &#125; public void onMessage(T message) &#123; &#125; public void onClose(Status status, Metadata trailers) &#123; &#125; public void onReady() &#123; &#125; &#125;&#125; 这个接口中通过sendMessage推送消息，以及通过onMessage异步接收响应，主要作用就是发起gRpc请求以及异步接收服务端响应 临时节点nacos响应过程上面提到非临时节点注册过程中会通过ClientCall接口将注册事件提交给其他nacos节点，其他nacos节点则通过ServerCall接收来自ClientCall的消息，ServerCall是服务端的接口 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public abstract class ServerCall&lt;ReqT, RespT&gt; &#123; public ServerCall() &#123; &#125; public abstract void request(int var1); public abstract void sendHeaders(Metadata var1); public abstract void sendMessage(RespT var1); public boolean isReady() &#123; return true; &#125; public abstract void close(Status var1, Metadata var2); public abstract boolean isCancelled(); @ExperimentalApi(&quot;https://github.com/grpc/grpc-java/issues/1704&quot;) public void setMessageCompression(boolean enabled) &#123; &#125; @ExperimentalApi(&quot;https://github.com/grpc/grpc-java/issues/1704&quot;) public void setCompression(String compressor) &#123; &#125; @ExperimentalApi(&quot;https://github.com/grpc/grpc-java/issues/4692&quot;) public SecurityLevel getSecurityLevel() &#123; return SecurityLevel.NONE; &#125; @ExperimentalApi(&quot;https://github.com/grpc/grpc-java/issues/1779&quot;) public Attributes getAttributes() &#123; return Attributes.EMPTY; &#125; @Nullable @ExperimentalApi(&quot;https://github.com/grpc/grpc-java/issues/2924&quot;) public String getAuthority() &#123; return null; &#125; public abstract MethodDescriptor&lt;ReqT, RespT&gt; getMethodDescriptor(); public abstract static class Listener&lt;ReqT&gt; &#123; public Listener() &#123; &#125; public void onMessage(ReqT message) &#123; &#125; public void onHalfClose() &#123; &#125; public void onCancel() &#123; &#125; public void onComplete() &#123; &#125; public void onReady() &#123; &#125; &#125;&#125; ServerCall与ClientCall相反，通过onMessage接收来自ClientCall的消息，并且用sendMessage对ClientCall异步提交响应，具体处理入口是onHalfClose方法 123456789101112131415public void onHalfClose() &#123; if (this.canInvoke) &#123; if (this.request == null) &#123; this.call.close(Status.INTERNAL.withDescription(&quot;Half-closed without a request&quot;), new Metadata()); &#125; else &#123; UnaryServerCallHandler.this.method.invoke(this.request, this.responseObserver); this.request = null; this.responseObserver.freeze(); if (this.wasReady) &#123; this.onReady(); &#125; &#125; &#125;&#125; 其中UnaryServerCallHandler.this.method.invoke(this.request, this.responseObserver);就是具体处理方法的入口，这是因为注册了相关Payload消息的事件 12345678910111213141516171819202122232425262728293031323334private void addServices(MutableHandlerRegistry handlerRegistry, ServerInterceptor... serverInterceptor) &#123; // unary common call register. final MethodDescriptor&lt;Payload, Payload&gt; unaryPayloadMethod = MethodDescriptor.&lt;Payload, Payload&gt;newBuilder() .setType(MethodDescriptor.MethodType.UNARY) .setFullMethodName(MethodDescriptor.generateFullMethodName(GrpcServerConstants.REQUEST_SERVICE_NAME, GrpcServerConstants.REQUEST_METHOD_NAME)) .setRequestMarshaller(ProtoUtils.marshaller(Payload.getDefaultInstance())) .setResponseMarshaller(ProtoUtils.marshaller(Payload.getDefaultInstance())).build(); final ServerCallHandler&lt;Payload, Payload&gt; payloadHandler = ServerCalls .asyncUnaryCall((request, responseObserver) -&gt; grpcCommonRequestAcceptor.request(request, responseObserver)); final ServerServiceDefinition serviceDefOfUnaryPayload = ServerServiceDefinition.builder( GrpcServerConstants.REQUEST_SERVICE_NAME) .addMethod(unaryPayloadMethod, payloadHandler).build(); handlerRegistry.addService(ServerInterceptors.intercept(serviceDefOfUnaryPayload, serverInterceptor)); // bi stream register. final ServerCallHandler&lt;Payload, Payload&gt; biStreamHandler = ServerCalls.asyncBidiStreamingCall( (responseObserver) -&gt; grpcBiStreamRequestAcceptor.requestBiStream(responseObserver)); final MethodDescriptor&lt;Payload, Payload&gt; biStreamMethod = MethodDescriptor.&lt;Payload, Payload&gt;newBuilder() .setType(MethodDescriptor.MethodType.BIDI_STREAMING).setFullMethodName(MethodDescriptor .generateFullMethodName(GrpcServerConstants.REQUEST_BI_STREAM_SERVICE_NAME, GrpcServerConstants.REQUEST_BI_STREAM_METHOD_NAME)) .setRequestMarshaller(ProtoUtils.marshaller(Payload.newBuilder().build())) .setResponseMarshaller(ProtoUtils.marshaller(Payload.getDefaultInstance())).build(); final ServerServiceDefinition serviceDefOfBiStream = ServerServiceDefinition .builder(GrpcServerConstants.REQUEST_BI_STREAM_SERVICE_NAME).addMethod(biStreamMethod, biStreamHandler).build(); handlerRegistry.addService(ServerInterceptors.intercept(serviceDefOfBiStream, serverInterceptor));&#125; 该方法中注册了相关事件，其中11到17行就是注册相关Payload消息的事件，也就是我们要说的事件，我们可以看到注册过程中，用到了grpcCommonRequestAcceptor.request方法，即com.alibaba.nacos.core.remote.grpc.GrpcRequestAcceptor#request方法，这个方法会根据Payload的类型（即PayLoad的_type属性）调用响应的处理方法，我们这里说的临时节点通知消息就是DistroDataRequestHandler类的handle方法 123456789101112131415161718192021222324public DistroDataResponse handle(DistroDataRequest request, RequestMeta meta) throws NacosException &#123; try &#123; switch (request.getDataOperation()) &#123; case VERIFY: return handleVerify(request.getDistroData(), meta); case SNAPSHOT: return handleSnapshot(); case ADD: case CHANGE: case DELETE: return handleSyncData(request.getDistroData()); case QUERY: return handleQueryData(request.getDistroData()); default: return new DistroDataResponse(); &#125; &#125; catch (Exception e) &#123; Loggers.DISTRO.error(&quot;[DISTRO-FAILED] distro handle with exception&quot;, e); DistroDataResponse result = new DistroDataResponse(); result.setErrorCode(ResponseCode.FAIL.getCode()); result.setMessage(&quot;handle distro request with exception&quot;); return result; &#125;&#125; 该方法会将其他nacos节点推送过来的消息应用到本节点 非临时节点注册过程在上面ClientOperationServiceProxy中提到使用了策略模式，下面是非临时节点处理方法 1234567891011121314151617181920212223@Overridepublic void registerInstance(Service service, Instance instance, String clientId) &#123; Service singleton = ServiceManager.getInstance().getSingleton(service); if (singleton.isEphemeral()) &#123; throw new NacosRuntimeException(NacosException.INVALID_PARAM, String.format(&quot;Current service %s is ephemeral service, can&#x27;t register persistent instance.&quot;, singleton.getGroupedServiceName())); &#125; final InstanceStoreRequest request = new InstanceStoreRequest(); request.setService(service); request.setInstance(instance); request.setClientId(clientId); final WriteRequest writeRequest = WriteRequest.newBuilder().setGroup(group()) .setData(ByteString.copyFrom(serializer.serialize(request))).setOperation(DataOperation.ADD.name()) .build(); try &#123; protocol.write(writeRequest); Loggers.RAFT.info(&quot;Client registered. service=&#123;&#125;, clientId=&#123;&#125;, instance=&#123;&#125;&quot;, service, instance, clientId); &#125; catch (Exception e) &#123; throw new NacosRuntimeException(NacosException.SERVER_ERROR, e); &#125;&#125; 该方法中需要注意的就是protocol.write(writeRequest)，从这里可以看出来，非临时节点和临时的节点的区别之一就是非临时节点会用到jraft算法，而临时节点会直接存储然后广播 123456@Overridepublic Response write(WriteRequest request) throws Exception &#123; CompletableFuture&lt;Response&gt; future = writeAsync(request); // Here you wait for 10 seconds, as long as possible, for the request to complete return future.get(10_000L, TimeUnit.MILLISECONDS);&#125; 这里异步调用异步请求方法，nacos源码中涉及到很多的异步方法以及异步请求，所以源码观看起来可能有点麻烦，writeAsync(request)调用的是JRaftServer的commit方法 123456789101112131415161718192021public CompletableFuture&lt;Response&gt; commit(final String group, final Message data, final CompletableFuture&lt;Response&gt; future) &#123; LoggerUtils.printIfDebugEnabled(Loggers.RAFT, &quot;data requested this time : &#123;&#125;&quot;, data); final RaftGroupTuple tuple = findTupleByGroup(group); if (tuple == null) &#123; future.completeExceptionally(new IllegalArgumentException(&quot;No corresponding Raft Group found : &quot; + group)); return future; &#125; FailoverClosureImpl closure = new FailoverClosureImpl(future); final Node node = tuple.node; if (node.isLeader()) &#123; // The leader node directly applies this request applyOperation(node, data, closure); &#125; else &#123; // Forward to Leader for request processing invokeToLeader(group, data, 10000, closure); &#125; return future;&#125; 这里可以看出来jraft算法的特点，请求需要交给leader及主节点处理，如果是主节点就直接调用applyOperation(node, data, closure)处理，如果不是主节点，就会调用invokeToLeader将请求打包成WriteRequest并请求主节点，主节点的响应方法是 12345678910111213141516171819protected void handleRequest(final JRaftServer server, final String group, final RpcContext rpcCtx, Message message) &#123; try &#123; final JRaftServer.RaftGroupTuple tuple = server.findTupleByGroup(group); if (Objects.isNull(tuple)) &#123; rpcCtx.sendResponse(Response.newBuilder().setSuccess(false) .setErrMsg(&quot;Could not find the corresponding Raft Group : &quot; + group).build()); return; &#125; if (tuple.getNode().isLeader()) &#123; execute(server, rpcCtx, message, tuple); &#125; else &#123; rpcCtx.sendResponse( Response.newBuilder().setSuccess(false).setErrMsg(&quot;Could not find leader : &quot; + group).build()); &#125; &#125; catch (Throwable e) &#123; Loggers.RAFT.error(&quot;handleRequest has error : &quot;, e); rpcCtx.sendResponse(Response.newBuilder().setSuccess(false).setErrMsg(e.toString()).build()); &#125;&#125; 其中execute(server, rpcCtx, message, tuple)会调用上述commit中也提到过的applyOperation(node, data, closure)方法，applyOperation方法后续过程用到了LMAX Disruptor框架，观看源码时需要注意，applyOperation会调用到com.alipay.sofa.jraft.storage.impl.LogManagerImpl#appendEntries，后面将非临时节点存储到本地日志，并通过io.grpc.ClientCall将事件和日志打包成com.alipay.sofa.jraft.rpc.RpcRequests.AppendEntriesRequest并通知到其他节点，通知其他节点时，会继续异步调用，后续过程中会调用到以下方法 12345678910111213141516171819202122232425262728293031323334@Overridepublic Response onApply(WriteRequest request) &#123;final Lock lock = readLock;lock.lock();try &#123; final InstanceStoreRequest instanceRequest = serializer.deserialize(request.getData().toByteArray()); final DataOperation operation = DataOperation.valueOf(request.getOperation()); switch (operation) &#123; case ADD: onInstanceRegister(instanceRequest.service, instanceRequest.instance, instanceRequest.getClientId()); break; case DELETE: onInstanceDeregister(instanceRequest.service, instanceRequest.getClientId()); break; case CHANGE: if (instanceAndServiceExist(instanceRequest)) &#123; onInstanceRegister(instanceRequest.service, instanceRequest.instance, instanceRequest.getClientId()); &#125; break; default: return Response.newBuilder().setSuccess(false).setErrMsg(&quot;unsupport operation : &quot; + operation) .build(); &#125; return Response.newBuilder().setSuccess(true).build();&#125; catch (Exception e) &#123; Loggers.RAFT.warn(&quot;Persistent client operation failed. &quot;, e); return Response.newBuilder().setSuccess(false) .setErrMsg(&quot;Persistent client operation failed. &quot; + e.getMessage()).build();&#125; finally &#123; lock.unlock();&#125;&#125; 这个方法主要就是注册或者删除非临时节点的后续处理 非临时节点nacos响应过程上面提到，applyOperation方法会将事件打包后通过ClientCall发送给其他节点，参考上面临时节点nacos响应过程，可知，我们只需要找到ServerCall的onHalfClose方法中，AppendEntriesRequest请求对应的处理类即可 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public void registerProcessor(RpcProcessor processor) &#123;String interest = processor.interest();Message reqIns = (Message)Requires.requireNonNull(this.parserClasses.get(interest), &quot;null default instance: &quot; + interest);MethodDescriptor&lt;Message, Message&gt; method = MethodDescriptor.newBuilder().setType(MethodType.UNARY).setFullMethodName(MethodDescriptor.generateFullMethodName(processor.interest(), &quot;_call&quot;)).setRequestMarshaller(ProtoUtils.marshaller(reqIns)).setResponseMarshaller(ProtoUtils.marshaller(this.marshallerRegistry.findResponseInstanceByRequest(interest))).build();ServerCallHandler&lt;Message, Message&gt; handler = ServerCalls.asyncUnaryCall((request, responseObserver) -&gt; &#123; final SocketAddress remoteAddress = RemoteAddressInterceptor.getRemoteAddress(); final Connection conn = ConnectionInterceptor.getCurrentConnection(this.closedEventListeners); RpcContext rpcCtx = new RpcContext() &#123; public void sendResponse(Object responseObj) &#123; try &#123; responseObserver.onNext((Message)responseObj); responseObserver.onCompleted(); &#125; catch (Throwable var3) &#123; GrpcServer.LOG.warn(&quot;[GRPC] failed to send response.&quot;, var3); &#125; &#125; public Connection getConnection() &#123; if (conn == null) &#123; throw new IllegalStateException(&quot;fail to get connection&quot;); &#125; else &#123; return conn; &#125; &#125; public String getRemoteAddress() &#123; return remoteAddress != null ? remoteAddress.toString() : null; &#125; &#125;; RpcProcessor.ExecutorSelector selector = processor.executorSelector(); Object executor; if (selector != null &amp;&amp; request instanceof RpcRequests.AppendEntriesRequest) &#123; RpcRequests.AppendEntriesRequest req = (RpcRequests.AppendEntriesRequest)request; RpcRequests.AppendEntriesRequestHeader.Builder header = AppendEntriesRequestHeader.newBuilder().setGroupId(req.getGroupId()).setPeerId(req.getPeerId()).setServerId(req.getServerId()); executor = selector.select(interest, header.build()); &#125; else &#123; executor = processor.executor(); &#125; if (executor == null) &#123; executor = this.defaultExecutor; &#125; if (executor != null) &#123; ((Executor)executor).execute(() -&gt; &#123; processor.handleRequest(rpcCtx, request); &#125;); &#125; else &#123; processor.handleRequest(rpcCtx, request); &#125;&#125;);ServerServiceDefinition serviceDef = ServerServiceDefinition.builder(interest).addMethod(method, handler).build();this.handlerRegistry.addService(ServerInterceptors.intercept(serviceDef, (ServerInterceptor[])this.serverInterceptors.toArray(new ServerInterceptor[0])));&#125; 第一行的String interest &#x3D; processor.interest();就是获取处理器对应的请求类型，后续进行注册，nacos中大部分请求都需要通过实现RpcProcessor处理，而registerProcessor方法就是注册每个请求对应的处理类，比如AppendEntriesRequest请求注册的就是AppendEntriesRequestProcessor，上面提到过的WriteRequest对应的就是NacosWriteRequestProcessor以及NacosReadRequestProcessor，这两个类都是AbstractProcessor的子类，所以实际上是在AbstractProcessor中处理的，AppendEntriesRequestProcessor实际调用的方法是processRequest0 12345678910111213141516171819202122232425public Message processRequest0(RaftServerService service, RpcRequests.AppendEntriesRequest request, RpcRequestClosure done) &#123; Node node = (Node)service; if (node.getRaftOptions().isReplicatorPipeline()) &#123; String groupId = request.getGroupId(); PeerPair pair = this.pairOf(request.getPeerId(), request.getServerId()); boolean isHeartbeat = this.isHeartbeatRequest(request); int reqSequence = -1; if (!isHeartbeat) &#123; reqSequence = this.getAndIncrementSequence(groupId, pair, done.getRpcCtx().getConnection()); &#125; Message response = service.handleAppendEntriesRequest(request, new SequenceRpcRequestClosure(done, this.defaultResp(), groupId, pair, reqSequence, isHeartbeat)); if (response != null) &#123; if (isHeartbeat) &#123; done.getRpcCtx().sendResponse(response); &#125; else &#123; this.sendSequenceResponse(groupId, pair, reqSequence, done.getRpcCtx(), response); &#125; &#125; return null; &#125; else &#123; return service.handleAppendEntriesRequest(request, done); &#125;&#125; service.handleAppendEntriesRequest(request, done)就是将主节点推送过来的日志应用到本地，也会和主节点一样调用到com.alipay.sofa.jraft.storage.impl.LogManagerImpl#appendEntries applyOperation具体调用过程参考文章：蚂蚁金服生产级 Raft 算法库 SOFAJRaft 存储模块剖析 | SOFAJRaft 实现原理 这里就是讲一下，applyOperation具体调用过程，也就是nacos的jraft算法过程中，主节点处理消息的过程 1234567891011121314151617181920212223public void applyOperation(Node node, Message data, FailoverClosure closure) &#123; final Task task = new Task(); task.setDone(new NacosClosure(data, status -&gt; &#123; NacosClosure.NacosStatus nacosStatus = (NacosClosure.NacosStatus) status; closure.setThrowable(nacosStatus.getThrowable()); closure.setResponse(nacosStatus.getResponse()); closure.run(nacosStatus); &#125;)); // add request type field at the head of task data. byte[] requestTypeFieldBytes = new byte[2]; requestTypeFieldBytes[0] = ProtoMessageUtil.REQUEST_TYPE_FIELD_TAG; if (data instanceof ReadRequest) &#123; requestTypeFieldBytes[1] = ProtoMessageUtil.REQUEST_TYPE_READ; &#125; else &#123; requestTypeFieldBytes[1] = ProtoMessageUtil.REQUEST_TYPE_WRITE; &#125; byte[] dataBytes = data.toByteArray(); task.setData((ByteBuffer) ByteBuffer.allocate(requestTypeFieldBytes.length + dataBytes.length) .put(requestTypeFieldBytes).put(dataBytes).position(0)); node.apply(task);&#125; 可以看到applyOperation方法本身就是生成一个task，然后调用node.apply(task)，这里node是Node的实现类 ：NodeImpl 123456789101112131415161718192021222324252627282930313233public void apply(Task task) &#123;if (this.shutdownLatch != null) &#123; ThreadPoolsFactory.runClosureInThread(this.groupId, task.getDone(), new Status(RaftError.ENODESHUTDOWN, &quot;Node is shutting down.&quot;, new Object[0])); throw new IllegalStateException(&quot;Node is shutting down&quot;);&#125; else &#123; Requires.requireNonNull(task, &quot;Null task&quot;); LogEntry entry = new LogEntry(); entry.setData(task.getData()); EventTranslator&lt;LogEntryAndClosure&gt; translator = (event, sequence) -&gt; &#123; event.reset(); event.done = task.getDone(); event.entry = entry; event.expectedTerm = task.getExpectedTerm(); &#125;; switch (this.options.getApplyTaskMode()) &#123; case Blocking: this.applyQueue.publishEvent(translator); break; case NonBlocking: default: if (!this.applyQueue.tryPublishEvent(translator)) &#123; String errorMsg = &quot;Node is busy, has too many tasks, queue is full and bufferSize=&quot; + this.applyQueue.getBufferSize(); ThreadPoolsFactory.runClosureInThread(this.groupId, task.getDone(), new Status(RaftError.EBUSY, errorMsg, new Object[0])); LOG.warn(&quot;Node &#123;&#125; applyQueue is overload.&quot;, this.getNodeId()); this.metrics.recordTimes(&quot;apply-task-overload-times&quot;, 1L); if (task.getDone() == null) &#123; throw new OverloadException(errorMsg); &#125; &#125; &#125;&#125;&#125; 可以看到，apply方法就是生成一个translator，然后通过applyQueue发布，这里的applyQueue是RingBuffer的对象，RingBuffer就是上面提到的LMAX Disruptor框架的内容，而且这个类使用了装饰器模式，既然使用到了LMAX Disruptor框架，那么实现肯定有一个实现EventHandler的事件处理类 1234567891011121314151617181920212223242526272829303132333435363738private class LogEntryAndClosureHandler implements EventHandler&lt;LogEntryAndClosure&gt; &#123; private final List&lt;LogEntryAndClosure&gt; tasks; private LogEntryAndClosureHandler() &#123; this.tasks = new ArrayList(NodeImpl.this.raftOptions.getApplyBatch()); &#125; public void onEvent(LogEntryAndClosure event, long sequence, boolean endOfBatch) throws Exception &#123; if (event.shutdownLatch != null) &#123; if (!this.tasks.isEmpty()) &#123; NodeImpl.this.executeApplyingTasks(this.tasks); this.reset(); &#125; int num = NodeImpl.GLOBAL_NUM_NODES.decrementAndGet(); NodeImpl.LOG.info(&quot;The number of active nodes decrement to &#123;&#125;.&quot;, num); event.shutdownLatch.countDown(); &#125; else &#123; this.tasks.add(event); if (this.tasks.size() &gt;= NodeImpl.this.raftOptions.getApplyBatch() || endOfBatch) &#123; NodeImpl.this.executeApplyingTasks(this.tasks); this.reset(); &#125; &#125; &#125; private void reset() &#123; Iterator var1 = this.tasks.iterator(); while(var1.hasNext()) &#123; LogEntryAndClosure task = (LogEntryAndClosure)var1.next(); task.reset(); &#125; this.tasks.clear(); &#125;&#125; 这里需要注意的是executeApplyingTasks方法，它会调用上面提到过的com.alipay.sofa.jraft.storage.impl.LogManagerImpl#appendEntries方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public void appendEntries(List&lt;LogEntry&gt; entries, LogManager.StableClosure done) &#123; assert done != null; Requires.requireNonNull(done, &quot;done&quot;); if (this.hasError) &#123; entries.clear(); ThreadPoolsFactory.runClosureInThread(this.groupId, done, new Status(RaftError.EIO, &quot;Corrupted LogStorage&quot;, new Object[0])); &#125; else &#123; boolean doUnlock = true; this.writeLock.lock(); try &#123; if (!entries.isEmpty() &amp;&amp; !this.checkAndResolveConflict(entries, done, this.writeLock)) &#123; entries.clear(); return; &#125; for(int i = 0; i &lt; entries.size(); ++i) &#123; LogEntry entry = (LogEntry)entries.get(i); if (this.raftOptions.isEnableLogEntryChecksum()) &#123; entry.setChecksum(entry.checksum()); &#125; if (entry.getType() == EntryType.ENTRY_TYPE_CONFIGURATION) &#123; Configuration oldConf = new Configuration(); if (entry.getOldPeers() != null) &#123; oldConf = new Configuration(entry.getOldPeers(), entry.getOldLearners()); &#125; ConfigurationEntry conf = new ConfigurationEntry(entry.getId(), new Configuration(entry.getPeers(), entry.getLearners()), oldConf); this.configManager.add(conf); &#125; &#125; if (!entries.isEmpty()) &#123; done.setFirstLogIndex(((LogEntry)entries.get(0)).getId().getIndex()); this.logsInMemory.addAll(entries); &#125; done.setEntries(entries); doUnlock = false; if (!this.wakeupAllWaiter(this.writeLock)) &#123; this.notifyLastLogIndexListeners(); &#125; this.diskQueue.publishEvent((event, sequence) -&gt; &#123; event.reset(); event.type = LogManagerImpl.EventType.OTHER; event.done = done; &#125;); &#125; finally &#123; if (doUnlock) &#123; this.writeLock.unlock(); &#125; &#125; &#125;&#125; 这里需要注意的是this.wakeupAllWaiter(this.writeLock)，这个方法就是nacos主节点唤醒并通知其他nacos节点，它后面会调用到sendEntries方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687private boolean sendEntries(long nextSendingIndex) &#123; RpcRequests.AppendEntriesRequest.Builder rb = AppendEntriesRequest.newBuilder(); if (!this.fillCommonFields(rb, nextSendingIndex - 1L, false)) &#123; this.installSnapshot(); return false; &#125; else &#123; ByteBufferCollector dataBuf = null; int maxEntriesSize = this.raftOptions.getMaxEntriesSize(); RecyclableByteBufferList byteBufList = RecyclableByteBufferList.newInstance(); label152: &#123; boolean var19; try &#123; for(int i = 0; i &lt; maxEntriesSize; ++i) &#123; RaftOutter.EntryMeta.Builder emb = EntryMeta.newBuilder(); if (!this.prepareEntry(nextSendingIndex, i, emb, byteBufList)) &#123; break; &#125; rb.addEntries(emb.build()); &#125; if (rb.getEntriesCount() != 0) &#123; if (byteBufList.getCapacity() &lt;= 0) &#123; break label152; &#125; dataBuf = ByteBufferCollector.allocateByRecyclers(byteBufList.getCapacity()); Iterator var20 = byteBufList.iterator(); while(var20.hasNext()) &#123; ByteBuffer b = (ByteBuffer)var20.next(); dataBuf.put(b); &#125; ByteBuffer buf = dataBuf.getBuffer(); BufferUtils.flip(buf); rb.setData(ZeroByteStringHelper.wrap(buf)); break label152; &#125; if (nextSendingIndex &lt; this.options.getLogManager().getFirstLogIndex()) &#123; this.installSnapshot(); var19 = false; return var19; &#125; this.waitMoreEntries(nextSendingIndex); var19 = false; &#125; finally &#123; RecycleUtil.recycle(byteBufList); &#125; return var19; &#125; final RpcRequests.AppendEntriesRequest request = rb.build(); if (LOG.isDebugEnabled()) &#123; LOG.debug(&quot;Node &#123;&#125; send AppendEntriesRequest to &#123;&#125; term &#123;&#125; lastCommittedIndex &#123;&#125; prevLogIndex &#123;&#125; prevLogTerm &#123;&#125; logIndex &#123;&#125; count &#123;&#125;&quot;, new Object[]&#123;this.options.getNode().getNodeId(), this.options.getPeerId(), this.options.getTerm(), request.getCommittedIndex(), request.getPrevLogIndex(), request.getPrevLogTerm(), nextSendingIndex, request.getEntriesCount()&#125;); &#125; this.statInfo.runningState = Replicator.RunningState.APPENDING_ENTRIES; this.statInfo.firstLogIndex = rb.getPrevLogIndex() + 1L; this.statInfo.lastLogIndex = rb.getPrevLogIndex() + (long)rb.getEntriesCount(); final Recyclable recyclable = dataBuf; final int v = this.version; final long monotonicSendTimeMs = Utils.monotonicMs(); final int seq = this.getAndIncrementReqSeq(); ++this.appendEntriesCounter; Future&lt;Message&gt; rpcFuture = null; try &#123; rpcFuture = this.rpcService.appendEntries(this.options.getPeerId().getEndpoint(), request, -1, new RpcResponseClosureAdapter&lt;RpcRequests.AppendEntriesResponse&gt;() &#123; public void run(Status status) &#123; RecycleUtil.recycle(recyclable); Replicator.onRpcReturned(Replicator.this.id, Replicator.RequestType.AppendEntries, status, request, this.getResponse(), seq, v, monotonicSendTimeMs); &#125; &#125;); &#125; catch (Throwable var17) &#123; RecycleUtil.recycle(dataBuf); ThrowUtil.throwException(var17); &#125; this.addInflight(Replicator.RequestType.AppendEntries, nextSendingIndex, request.getEntriesCount(), request.getData().size(), seq, rpcFuture); return true; &#125;&#125; 这个方法会构造一个RpcRequests.AppendEntriesRequest请求，并通过rpcService.appendEntries方法发送出去，并实现了异步回调，用于了解其他nacos节点接收日志的情况，同时后面还会调用上面提到的com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl#onApply","categories":["Spring Cloud相关中间件"]},{"title":"Netty实现Https!Http2(ssl!tls)服务端","path":"/2025/01/07/Netty实现Https!Http2(ssl!tls)服务端/","content":"依赖在netty中，如果想使用ssl的功能，除了netty默认需要的依赖以外，还需要一些其他的依赖以支持ssl 12345678910111213&lt;!--netty对SSL/TLS的支持，可以在 Netty 中使用 BoringSSL 提供的 SSL/TLS 功能，而无需依赖于系统中已安装的 OpenSSL 库--&gt;&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-tcnative-boringssl-static&lt;/artifactId&gt; &lt;version&gt;2.0.51.Final&lt;/version&gt;&lt;/dependency&gt;&lt;!--这是jdk提供的加密套件，Bouncy Castle 是一个流行的开源加密库，提供了丰富的加密算法和安全功能--&gt;&lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcpkix-jdk15on&lt;/artifactId&gt; &lt;version&gt;1.70&lt;/version&gt;&lt;/dependency&gt; 代码服务端的代码与客户端的代码基本类似，也是通过userEventTriggered获取ALPN协商的协议后，决定代码所使用的协议 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191package com.example.netty.server;import cn.hutool.core.date.DateTime;import cn.hutool.core.util.StrUtil;import io.netty.bootstrap.ServerBootstrap;import io.netty.buffer.ByteBuf;import io.netty.buffer.ByteBufUtil;import io.netty.buffer.Unpooled;import io.netty.channel.*;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.handler.codec.ByteToMessageDecoder;import io.netty.handler.codec.http.*;import io.netty.handler.codec.http2.*;import io.netty.handler.ssl.*;import io.netty.handler.ssl.util.InsecureTrustManagerFactory;import io.netty.handler.ssl.util.SelfSignedCertificate;import io.netty.util.CharsetUtil;import io.netty.util.internal.StringUtil;import javax.net.ssl.SSLException;import java.security.cert.CertificateException;import java.util.List;public class Https2Server &#123; public static void main(String[] args) throws CertificateException, InterruptedException, SSLException &#123; // Generate a self-signed SSL certificate SelfSignedCertificate cert = new SelfSignedCertificate(); SslContext sslContext = SslContextBuilder .forServer(cert.certificate(), cert.privateKey()) .sslProvider(SslProvider.OPENSSL) .ciphers(Http2SecurityUtil.CIPHERS, SupportedCipherSuiteFilter.INSTANCE)//配置 HTTP/2 协议中支持的密码套件列表，并使用 SupportedCipherSuiteFilter 进行过滤。 .trustManager(InsecureTrustManagerFactory.INSTANCE)//在服务端使用非认证的证书时，必须使用该代码 .applicationProtocolConfig(new ApplicationProtocolConfig( ApplicationProtocolConfig.Protocol.ALPN, ApplicationProtocolConfig.SelectorFailureBehavior.NO_ADVERTISE, ApplicationProtocolConfig.SelectedListenerFailureBehavior.ACCEPT, ApplicationProtocolNames.HTTP_2, ApplicationProtocolNames.HTTP_1_1)) .build(); // Create event loop groups EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; // Create and configure the server bootstrap ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 128) .localAddress(8080) .childOption(ChannelOption.SO_KEEPALIVE, true) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) &#123; ch.pipeline() .addLast(sslContext.newHandler(ch.alloc())) .addLast(new FrontHandler()); &#125; &#125;); // Bind and start the server ChannelFuture future = bootstrap.bind().sync(); System.out.println(&quot;Server started and listening on port 8080&quot;); // Wait until the server socket is closed future.channel().closeFuture().sync(); &#125; finally &#123; // Shut down the event loop groups bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; static class FrontHandler extends ChannelInboundHandlerAdapter &#123; private final HttpServerCodec httpServerCodec; private final HttpObjectAggregator httpObjectAggregator; private final HttpServerHandler httpServerHandler; private final Http2FrameCodec http2FrameCodec; private final Http2ServerHandler http2ServerHandler; public FrontHandler() &#123; httpServerCodec = new HttpServerCodec(); httpObjectAggregator = new HttpObjectAggregator(10240); httpServerHandler = new HttpServerHandler(); http2FrameCodec = Http2FrameCodecBuilder.forServer().build(); http2ServerHandler = new Http2ServerHandler(); &#125; @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123; ctx.pipeline().addLast(httpServerCodec).addLast(httpObjectAggregator).addLast(httpServerHandler); &#125; //sslHandler处理完协议协商后，会触发SslHandshakeCompletionEvent，可以通过SslHandshakeCompletionEvent修改客户端使用协议 @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (evt instanceof SslHandshakeCompletionEvent)&#123; SslHandler sslHandler = ctx.pipeline().get(SslHandler.class); String protocol = sslHandler.applicationProtocol(); if (StrUtil.isBlank(protocol))&#123; return; &#125; if (protocol.equals(ApplicationProtocolNames.HTTP_2))&#123; ctx.pipeline().remove(httpServerCodec).remove(httpObjectAggregator).remove(httpServerHandler).addLast(http2FrameCodec).addLast(http2ServerHandler); ctx.pipeline().remove(this); &#125;else if (protocol.equals(ApplicationProtocolNames.HTTP_1_1))&#123; ctx.pipeline().remove(this); &#125; &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); &#125; &#125; @ChannelHandler.Sharable static class Http2ServerHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; if (msg instanceof DefaultHttp2HeadersFrame) &#123; DefaultHttp2HeadersFrame http2HeadersFrame = (DefaultHttp2HeadersFrame) msg; if (http2HeadersFrame.isEndStream())&#123; String responseBody = &quot;http/2&quot;; Http2FrameStream requestStream = http2HeadersFrame.stream(); response(ctx, requestStream, responseBody); &#125; &#125; else if (msg instanceof DefaultHttp2DataFrame) &#123; DefaultHttp2DataFrame http2RequestDataFrame = (DefaultHttp2DataFrame) msg; String requestBody = http2RequestDataFrame.content().toString(CharsetUtil.UTF_8); System.out.println(http2RequestDataFrame.stream().id() + &quot;:&quot; + requestBody); String responseBody = &quot;http/2:&quot; + requestBody; Http2FrameStream requestStream = http2RequestDataFrame.stream(); response(ctx, requestStream, responseBody); &#125; else if (msg instanceof DefaultHttp2PingFrame) &#123; if (((DefaultHttp2PingFrame) msg).ack()) &#123; DefaultHttp2PingFrame pingFrame = new DefaultHttp2PingFrame(1); ctx.writeAndFlush(pingFrame); &#125; &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; cause.printStackTrace(); ctx.close(); &#125; private void response(ChannelHandlerContext ctx, Http2FrameStream requestStream, String responseBody)&#123; DefaultHttp2HeadersFrame headersFrame = new DefaultHttp2HeadersFrame( new DefaultHttp2Headers().status(&quot;200&quot;) .set(HttpHeaderNames.DATE, DateTime.now().toString()) .set(HttpHeaderNames.CONTENT_TYPE, &quot;text/plain;charset=UTF-8&quot;) .set(HttpHeaderNames.CONTENT_LENGTH, String.valueOf(responseBody.length())) ).stream(requestStream); DefaultHttp2DataFrame dataFrame = new DefaultHttp2DataFrame(Unpooled.wrappedBuffer(responseBody.getBytes()), true).stream(requestStream); ctx.writeAndFlush(headersFrame); ctx.writeAndFlush(dataFrame); &#125; &#125; @ChannelHandler.Sharable static class HttpServerHandler extends ChannelInboundHandlerAdapter&#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof FullHttpMessage)&#123; DefaultFullHttpResponse httpResponse = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK, Unpooled.wrappedBuffer(&quot;http/1.1&quot;.getBytes())); httpResponse.headers().set(HttpHeaderNames.CONTENT_LENGTH, &quot;http/1.1&quot;.length()); httpResponse.headers().set(HttpHeaderNames.CONNECTION, &quot;keep-alive&quot;); ctx.writeAndFlush(httpResponse); &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); &#125; &#125;&#125;","categories":["Netty"]},{"title":"Spring Boot整合LMAX Disruptor","path":"/2025/01/07/Spring Boot整合LMAX Disruptor/","content":"参考文章：https://www.yuque.com/simonalong/jishu/qhdcb2 依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.lmax&lt;/groupId&gt; &lt;artifactId&gt;disruptor&lt;/artifactId&gt; &lt;version&gt;3.4.2&lt;/version&gt;&lt;/dependency&gt; 实例代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public class EventInfoServiceImpl &#123; private Disruptor&lt;EventInfoAndBack&gt; applyDisruptor; private RingBuffer&lt;EventInfoAndBack&gt; applyQueue; @GrpcClient(&quot;grpc-server&quot;) private EventInfoServiceGrpc.EventInfoServiceFutureStub eventInfoServiceFutureStub; public EventInfoServiceImpl() &#123; ThreadPoolExecutor executor = new ThreadPoolExecutor(7, 7, 1, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1)); this.applyDisruptor = DisruptorBuilder.newInstance(EventInfoAndBack.class).setRingBufferSize(1024).setEventFactory(new EventInfoFactory()).setExecutor(executor).setProducerType(ProducerType.MULTI).setWaitStrategy(new BlockingWaitStrategy()).build(); this.applyDisruptor.handleEventsWithWorkerPool(new EventInfoWorkHandler(&quot;1&quot;),new EventInfoWorkHandler(&quot;2&quot;),new EventInfoWorkHandler(&quot;3&quot;)); this.applyDisruptor.handleEventsWith(new EventInfoHandler(&quot;1&quot;), new EventInfoHandler(&quot;2&quot;)); this.applyDisruptor.handleEventsWithWorkerPool(new EventInfoWorkHandler(&quot;4&quot;),new EventInfoWorkHandler(&quot;5&quot;)); this.applyDisruptor.setDefaultExceptionHandler(new FatalExceptionHandler()); applyQueue = applyDisruptor.start(); &#125; public EventInfoResponse sendEventInfoMessage(String data) &#123; EventInfoMessage eventInfoMessage = EventInfoMessage.newBuilder().setMsg(data).build(); AtomicReference&lt;EventInfoResponse&gt; eventInfoResponse = new AtomicReference&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; applyQueue.publishEvent((event, sequence) -&gt; &#123; event.eventInfoMessage = eventInfoMessage; event.back = eventInfoResponse::set; &#125;); &#125; while (eventInfoResponse.get() == null)&#123; &#125; return eventInfoResponse.get(); &#125; private class EventInfoAndBack &#123; EventInfoMessage eventInfoMessage; Back&lt;EventInfoResponse&gt; back; public EventInfoMessage getEventInfoMessage() &#123; return eventInfoMessage; &#125; public void setEventInfoMessage(EventInfoMessage eventInfoMessage) &#123; this.eventInfoMessage = eventInfoMessage; &#125; public Back&lt;EventInfoResponse&gt; getBack() &#123; return back; &#125; public void setBack(Back&lt;EventInfoResponse&gt; back) &#123; this.back = back; &#125; &#125; private class EventInfoFactory implements EventFactory&lt;EventInfoAndBack&gt; &#123; @Override public EventInfoAndBack newInstance() &#123; return new EventInfoAndBack(); &#125; &#125; private class EventInfoHandler implements EventHandler&lt;EventInfoAndBack&gt; &#123; private String str; public EventInfoHandler(String str) &#123; this.str = str; &#125; @Override public void onEvent(EventInfoAndBack eventInfo, long l, boolean b) throws Exception &#123; System.out.println(&quot;event-&quot;+str+&quot;:&quot;+Thread.currentThread().getName()); ListenableFuture&lt;EventInfoResponse&gt; response = eventInfoServiceFutureStub.sendMessageEvent(eventInfo.getEventInfoMessage()); eventInfo.back.run(response.get()); &#125; &#125; private class EventInfoWorkHandler implements WorkHandler&lt;EventInfoAndBack&gt; &#123; private String str; public EventInfoWorkHandler(String str) &#123; this.str = str; &#125; @Override public void onEvent(EventInfoAndBack eventInfo) throws Exception &#123; System.out.println(&quot;work-&quot;+str+&quot;:&quot;+Thread.currentThread().getName()); ListenableFuture&lt;EventInfoResponse&gt; response = eventInfoServiceFutureStub.sendMessageEvent(eventInfo.getEventInfoMessage()); eventInfo.back.run(response.get()); &#125; &#125; private interface Back&lt;T&gt; &#123; void run(T t); &#125;&#125; Disruptor的几个重要的参数： ringBufferSize：可以理解为环的大小，也就是队列最大容量 eventFactory：参数工厂，需要实现com.lmax.disruptor.EventFactory接口，Disruptor维护对象的生产工厂，队列中的对象通过这个工厂获取 executor：java.util.concurrent.Executor执行器，具体消费者的执行器，Disruptor默认实现了com.lmax.disruptor.dsl.BasicExecutor类，如果只传入线程工厂，就会使用此类，也可以使用其他的执行器，比如代码中使用的就是线程池 producerType：生产模式，由com.lmax.disruptor.dsl.ProducerType枚举控制 SINGLE：单生产者模式，com.lmax.disruptor.SingleProducerSequencer，适用于单线程 MULTI：多生产者模式，对应com.lmax.disruptor.MultiProducerSequencer，适用于多线程，主要区别在于，多生产者模式会使用到cas获取下一个序列，可以无锁解决并发问题，单生产者模式在多线程下可能会出现序列冲突问题 waitStrategy：等待策略，com.lmax.disruptor.WaitStrategy接口控制，即消费者在没有事件需要处理时，如和等待新事件，下面是几个实现类，从上到下，更加轻量 BlockingWaitStrategy：阻塞等待，有新的事件，会被唤醒，调用java.util.concurrent.locks.Condition#await()方法 SleepingWaitStrategy：自旋让渡加休眠等待，每自旋一段时间，就会尝试调用Thread.yield方法让渡cpu资源，再休眠一段时间再自旋等待 YieldingWaitStrategy：自旋让渡，每自旋一段时间，就会尝试调用Thread.yield方法让渡cpu资源，但不会像上者一样休眠等待 BusySpinWaitStrategy：自旋等待，只会不断自旋，不会让渡cpu资源，更不会等待 上面几个参数，大部分其实是RingBuffer类的参数，具体可参考是Disruptor类的构造方法 Disruptor几个重要的方法 handleEventsWith(EventHandler&lt;? super T&gt;… handlers)：配置Disruptor的事件处理类，我们编写的事件处理类需要实现EventHandler接口，可以通过此方法一次配置多个事件处理者，也可以多次调用这个方法配置，无论如何配置的，当生产者推送一个事件，所有事件处理者都会收到并处理 handleEventsWithWorkerPool(WorkHandler… workHandlers)：配置Disruptor工作处理类，工作处理类与事件处理类的区别在于，通过调用一次handleEventsWithWorkerPool方法配置的多个WorkHandler，而已理解为一个工作组，当有事件推送时，一个工作组中只有一个工作处理者能接收到事件 setDefaultExceptionHandler(ExceptionHandler&lt;? super T&gt; exceptionHandler)：配置异常处理类，Disruptor提供了几个默认的实现类，也可以自己实现","categories":["Spring Boot"]},{"title":"Apache HttpClient以及OkHttp","path":"/2025/01/07/Apache HttpClient以及OkHttp/","content":"依赖 OkHttp 12345&lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp3&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt; &lt;version&gt;4.9.3&lt;/version&gt;&lt;/dependency&gt; apache httpclient 123456789101112&lt;!--同步请求模块--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.14&lt;/version&gt;&lt;/dependency&gt;&lt;!--异步请求模块--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpasyncclient&lt;/artifactId&gt; &lt;version&gt;4.1.5&lt;/version&gt;&lt;/dependency&gt; 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163public class HttpClient &#123; static List&lt;String&gt; urlList = new ArrayList&lt;&gt;(); static &#123; Logger logger = (Logger) LoggerFactory.getLogger(&quot;org.apache.http&quot;); // 设置日志级别为OFF logger.setLevel(Level.OFF); for (int i = 0; i &lt; 100; i++) &#123; urlList.add(&quot;http://127.0.0.1:8080/query&quot;); &#125; &#125; public static void main(String[] args) throws IOException, InterruptedException &#123;// okHttpSync();// okHttpAsync();// apacheHttpSync();// apacheHttpAsync(); &#125; public static OkHttpClient okHttpClient() &#123; Dispatcher dispatcher = new Dispatcher(); //maxRequests和maxRequestsPerHost是同时能够请求的数量，底层通过两个队列存储，但是只会计算异步请求的数量，不过异步请求占满了之后同步请求也会被拒绝 dispatcher.setMaxRequests(20); dispatcher.setMaxRequestsPerHost(10);//maxRequestsPerHost记录同ip的请求 //okhttp连接池底层是链表，所以大小没有限制，底层也没有提供最大连接数，只提供了，最大空闲连接以及最大空闲时间 ConnectionPool connectionPool = new ConnectionPool(10, 10, TimeUnit.SECONDS); return new OkHttpClient().newBuilder().connectionPool(connectionPool).dispatcher(dispatcher).build(); &#125; public static void okHttpSync() &#123; OkHttpClient client = okHttpClient(); /** * 同步请求 底层使用Socket */ AtomicInteger i = new AtomicInteger(); ExecutorService executorService = Executors.newCachedThreadPool(); CountDownLatch countDownLatch = new CountDownLatch(100); for (String url : urlList) &#123; executorService.execute(() -&gt; &#123; Request request = new Request.Builder() .url(url) .build(); try &#123; Response response = client.newCall(request).execute(); System.out.println(response.body().string() + &quot;----&quot; + i.getAndIncrement()); countDownLatch.countDown(); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125;); &#125; executorService.shutdown(); try &#123; countDownLatch.await(); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; &#125; public static void okHttpAsync() &#123; OkHttpClient client = okHttpClient(); /** * 异步请求 底层使用Socket，原理是将请求作为任务保存到队列，交给专门处理异步请求的线程处理请求，请求完成后调用回调函数， * 异步请求底层使用的是缓存线程池，即同时有多少异步请求，就同时创建多少线程 */ urlList.forEach(url -&gt; &#123; Request request = new Request.Builder() .url(url) .build(); client.newCall(request).enqueue(new Callback() &#123; @Override public void onFailure(@NotNull Call call, @NotNull IOException e) &#123; System.out.println(&quot;请求失败&quot;); &#125; @Override public void onResponse(@NotNull Call call, @NotNull Response response) throws IOException &#123; System.out.println(response.body().string()); &#125; &#125;); &#125;); &#125; public static void apacheHttpSync() &#123; /** * maxConnTotal是最大连接数，和okhttp不同，apache httpclient连接数是可以设置的，底层使用的也是链表，defaultSocketConfig是路由最大连接数， * 这里的路由是具体到端口的，而okhttp只会到ip */ CloseableHttpClient httpclient = HttpClients.custom().setMaxConnTotal(20).setMaxConnPerRoute(20).build(); AtomicInteger i = new AtomicInteger(); ExecutorService executorService = Executors.newCachedThreadPool(); CountDownLatch countDownLatch = new CountDownLatch(urlList.size()); urlList.forEach(url -&gt; &#123; executorService.execute(() -&gt; &#123; try &#123; CloseableHttpResponse response = httpclient.execute(new HttpGet(url)); System.out.println(IoUtil.readUtf8(response.getEntity().getContent()) + &quot;----&quot; + i.getAndIncrement()); response.close(); countDownLatch.countDown(); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; &#125;); &#125;); executorService.shutdown(); try &#123; countDownLatch.await(); httpclient.close(); &#125; catch (InterruptedException | IOException e) &#123; throw new RuntimeException(e); &#125; &#125; public static void apacheHttpAsync() &#123; /** * 底层使用NIO，所以不受线程的限制，数据会先写入到conn.getContext().getAttribute(HTTP_HANDLER)中(org.apache.http.impl.nio.client.AbstractClientExchangeHandler)，conn为httpclient异步请求自定义的连接，底层有一个IOReactor的类， * 会调用系统方法获取那些channel是可以写入的，然后访问连接的SessionOutputBufferImpl，如果有数据，则直接写入channel，发送给服务端，如果没有数据，则将conn.getContext().getAttribute(HTTP_HANDLER) * 中的数据写入然后访问SessionOutputBufferImpl中，然后进行发送，虽然异步请求不受线程多少影响，但是这里用到了多线程，IOReactor有一个AbstractMultiworkerIOReactor实现类， * 它会创建多个（电脑cpu核数）线程，每个线程都有一个独立的IOReactor并行处理数据 */ CloseableHttpAsyncClient asyncClient = HttpAsyncClients.custom().setMaxConnTotal(20).setMaxConnPerRoute(20).build(); asyncClient.start(); AtomicInteger i = new AtomicInteger(); for (String url : urlList) &#123; asyncClient.execute(new HttpGet(url), new FutureCallback&lt;HttpResponse&gt;() &#123; @Override public void completed(HttpResponse httpResponse) &#123; try &#123; System.out.println(IoUtil.readUtf8(httpResponse.getEntity().getContent()) + &quot;----&quot; + i.getAndIncrement()); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; &#125; @Override public void failed(Exception e) &#123; &#125; @Override public void cancelled() &#123; &#125; &#125;); &#125; &#125;&#125;","categories":["服务通信"]},{"title":"GRPC消息发送流程","path":"/2025/01/07/GRPC消息发送流程/","content":"前言grpc发送过程总结起来可以分为两步，一步是写入内存，也就是写入ByteBuf，写入ByteBuf的目的是因为Java NIO对于数据有要求，第二步就是通过netty发送数据 1234567891011121314private static &lt;ReqT, RespT&gt; void asyncUnaryRequestCall( ClientCall&lt;ReqT, RespT&gt; call, ReqT req, StartableListener&lt;RespT&gt; responseListener) &#123; startCall(call, responseListener); try &#123; call.sendMessage(req); call.halfClose(); &#125; catch (RuntimeException e) &#123; throw cancelThrow(call, e); &#125; catch (Error e) &#123; throw cancelThrow(call, e); &#125;&#125; call.sendMessage(req);这句命令就是处理我们的数据，而在正式处理我们发送的数据之前，会调用startCall(call, responseListener);这个命令，这个命令其中一个功能就是写入http2头部，写入头部的逻辑最后会调用下面的方法 123456789101112131415161718192021222324252627282930313233343536private void writeHeadersInternal(Metadata headers, byte[] requestPayload) &#123; AsciiString defaultPath = (AsciiString)NettyClientStream.methodDescriptorAccessor.geRawMethodName(NettyClientStream.this.method); if (defaultPath == null) &#123; defaultPath = new AsciiString(&quot;/&quot; + NettyClientStream.this.method.getFullMethodName()); NettyClientStream.methodDescriptorAccessor.setRawMethodName(NettyClientStream.this.method, defaultPath); &#125; boolean get = requestPayload != null; AsciiString httpMethod; if (get) &#123; defaultPath = new AsciiString(defaultPath + &quot;?&quot; + BaseEncoding.base64().encode(requestPayload)); httpMethod = Utils.HTTP_GET_METHOD; &#125; else &#123; httpMethod = Utils.HTTP_METHOD; &#125; Http2Headers http2Headers = Utils.convertClientHeaders(headers, NettyClientStream.this.scheme, defaultPath, NettyClientStream.this.authority, httpMethod, NettyClientStream.this.userAgent); ChannelFutureListener failureListener = new ChannelFutureListener() &#123; public void operationComplete(ChannelFuture future) throws Exception &#123; if (!future.isSuccess()) &#123; Status s = NettyClientStream.this.transportState().handler.getLifecycleManager().getShutdownStatus(); if (s == null) &#123; s = NettyClientStream.this.transportState().statusFromFailedFuture(future); &#125; if (NettyClientStream.this.transportState().isNonExistent()) &#123; NettyClientStream.this.transportState().transportReportStatus(s, RpcProgress.MISCARRIED, true, new Metadata()); &#125; else &#123; NettyClientStream.this.transportState().transportReportStatus(s, RpcProgress.PROCESSED, true, new Metadata()); &#125; &#125; &#125; &#125;; NettyClientStream.this.writeQueue.enqueue(new CreateStreamCommand(http2Headers, NettyClientStream.this.transportState(), NettyClientStream.this.shouldBeCountedForInUse(), get), !NettyClientStream.this.method.getType().clientSendsOneMessage() || get).addListener(failureListener);&#125; 该方法就是创建一个CreateStreamCommand，并放入队列中，消息体后续也会加入这个队列，需要注意，如果这里是多元流或者没有消息体，那么将会直接flsuh，即会直接发送，否则会等到消息体加入队列之后，或者主动调用flush方法。 写入内存这一步总结一下就是数据写入ByteBuf的过程 1234567891011121314151617181920final void sendMessage(final ReqT message) &#123; State savedState = state; if (savedState.passThrough) &#123; savedState.winningSubstream.stream.writeMessage(method.streamRequest(message)); return; &#125; class SendMessageEntry implements BufferEntry &#123; @Override public void runWith(Substream substream) &#123; substream.stream.writeMessage(method.streamRequest(message)); // TODO(ejona): Workaround Netty memory leak. Message writes always need to be followed by // flushes (or half close), but retry appears to have a code path that the flushes may // not happen. The code needs to be fixed and this removed. See #9340. substream.stream.flush(); &#125; &#125; delayOrExecute(new SendMessageEntry());&#125; 这里面的runwith方法，其中substream.stream.writeMessage(method.streamRequest(message));就是将数据写入内存，而substream.stream.flush();就可以理解为发送数据 123456public void writeTo(OutputStream output) throws IOException &#123; int bufferSize = CodedOutputStream.computePreferredBufferSize(this.getSerializedSize()); CodedOutputStream codedOutput = CodedOutputStream.newInstance(output, bufferSize); this.writeTo(codedOutput); codedOutput.flush();&#125; 这个方法是将消息转为protobuf，使用protobuf也是grpc效率高的一个原因，AbstractMessageLite也就是grpc生成的消息类的父类，所以在这里调用writeTo方法的其实就是grpc根据我们定义数据生成的类 123456789101112131415private void writeRaw(byte[] b, int off, int len) &#123; while (len &gt; 0) &#123; if (buffer != null &amp;&amp; buffer.writableBytes() == 0) &#123; commitToSink(false, false); &#125; if (buffer == null) &#123; // Request a buffer allocation using the message length as a hint. buffer = bufferAllocator.allocate(len); &#125; int toWrite = min(len, buffer.writableBytes()); buffer.write(b, off, toWrite); off += toWrite; len -= toWrite; &#125;&#125; 可以看到写入内存实际上就是写入MessageFramer类的buffer变量中，后续发送时，就是发送buffer变量 123456public ByteBuf writeBytes(byte[] src, int srcIndex, int length) &#123; this.ensureWritable(length); this.setBytes(this.writerIndex, src, srcIndex, length); this.writerIndex += length; return this;&#125; 后面是调用了netty ByteBuf的writeBytes方法，就是将数据写入到ByteBuf 1public native void copyMemory(Object var1, long var2, Object var4, long var5, long var7); 调用到这里其实已经是netty的范围了，ByteBuf最后会调用到一个本地方法，copyMemory的五个参数分别是 srcBase：源对象的基地址，即要复制数据的起始位置。 srcOffset：源对象的偏移量，即要复制数据的起始偏移量。 destBase：目标对象的基地址，即要复制数据的目标位置。 destOffset：目标对象的偏移量，即要复制数据的目标偏移量。 length：要复制的数据长度。 发送数据从上面io.grpc.internal.RetriableStream#sendMessage方法的runwith方法中的substream.stream.flush();，就是开启刷新步骤，也就是发送流程 123456private void commitToSink(boolean endOfStream, boolean flush) &#123; WritableBuffer buf = buffer; buffer = null; sink.deliverFrame(buf, endOfStream, flush, messagesBuffered); messagesBuffered = 0;&#125; 这个方法将上面提到的的buffer写入sink，就是正式发送数据 1234567891011121314151617181920private void writeFrameInternal(WritableBuffer frame, boolean endOfStream, boolean flush, final int numMessages) &#123; Preconditions.checkArgument(numMessages &gt;= 0); ByteBuf bytebuf = frame == null ? Unpooled.EMPTY_BUFFER : ((NettyWritableBuffer)frame).bytebuf().touch(); final int numBytes = bytebuf.readableBytes(); if (numBytes &gt; 0) &#123; NettyClientStream.this.onSendingBytes(numBytes); NettyClientStream.this.writeQueue.enqueue(new SendGrpcFrameCommand(NettyClientStream.this.transportState(), bytebuf, endOfStream), flush).addListener(new ChannelFutureListener() &#123; public void operationComplete(ChannelFuture future) throws Exception &#123; if (future.isSuccess() &amp;&amp; NettyClientStream.this.transportState().http2Stream() != null) &#123; NettyClientStream.this.transportState().onSentBytes(numBytes); NettyClientStream.this.getTransportTracer().reportMessageSent(numMessages); &#125; &#125; &#125;); &#125; else &#123; NettyClientStream.this.writeQueue.enqueue(new SendGrpcFrameCommand(NettyClientStream.this.transportState(), bytebuf, endOfStream), flush); &#125;&#125; 这里将消息包装成SendGrpcFrameCommand放入队列中进行处理，这里的队列就是最上面提到过http2header也加入的队列 1234567891011ChannelFuture enqueue(QueuedCommand command, boolean flush) &#123; Preconditions.checkArgument(command.promise() == null, &quot;promise must not be set on command&quot;); ChannelPromise promise = this.channel.newPromise(); command.promise(promise); this.queue.add(command); if (flush) &#123; this.scheduleFlush(); &#125; return promise;&#125; 这个方法就是将消息放入队列并处理的方法，在上面http2header添加的时候，flush要根据条件判断，但是在添加我们的消息的时候，flush就是true，直接调用刷新方法，而this.scheduleFlush();命令会从队列中取出封装好的消息体，并调用他们的run方法 123public final void run(Channel channel) &#123;channel.write(this, this.promise);&#125; 123public final void run(Channel channel) &#123;channel.write(this, this.promise);&#125; 无论是http2header的CreateStreamCommand，还是我们写入消息的SendGrpcFrameCommand，他们的run方法都是一样的，都是调用netty的channel的write方法进行发送，至于channel的flush方法实在前面提到的scheduleFlush方法中执行的。我们知道channel需要添加channelHandler才能处理消息，而grpc实现了一个NettyClientHandler，下面就是NettyClientHandler的写入方法的实现 12345678910111213141516171819202122public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123; if (msg instanceof CreateStreamCommand) &#123; this.createStream((CreateStreamCommand)msg, promise); &#125; else if (msg instanceof SendGrpcFrameCommand) &#123; this.sendGrpcFrame(ctx, (SendGrpcFrameCommand)msg, promise); &#125; else if (msg instanceof CancelClientStreamCommand) &#123; this.cancelStream(ctx, (CancelClientStreamCommand)msg, promise); &#125; else if (msg instanceof SendPingCommand) &#123; this.sendPingFrame(ctx, (SendPingCommand)msg, promise); &#125; else if (msg instanceof GracefulCloseCommand) &#123; this.gracefulClose(ctx, (GracefulCloseCommand)msg, promise); &#125; else if (msg instanceof ForcefulCloseCommand) &#123; this.forcefulClose(ctx, (ForcefulCloseCommand)msg, promise); &#125; else &#123; if (msg != NOOP_MESSAGE) &#123; throw new AssertionError(&quot;Write called for unexpected type: &quot; + msg.getClass().getName()); &#125; ctx.write(Unpooled.EMPTY_BUFFER, promise); &#125;&#125; 总结该篇讲到了我们自己写入的消息是如何发送出去的，但是从写入内存到发送数据的步骤，严格来讲这其实属于netty的范畴，因为netty写入数据也是写入内存到发送数据，只是grpc按照需求实现了一遍，包括http2header，这里对于http2header其实并没有讲到很细，但是其实http2header也经历了写入内存到发送数据的步骤，只是http2header的写入使用的就是netty默认的逻辑，总结起来就是消息体的写入，grpc有自己的实现，而对于http2header的写入，使用的就是netty默认的逻辑","categories":["GRPC"]},{"title":"Spring及Spring Boot知识记录","path":"/2025/01/07/Spring及Spring Boot知识记录/","content":"Spring Boot欢迎页spring boot欢迎页，就是默认访问的页面，默认为Resources类的CLASSPATH_RESOURCE_LOCATIONS属性，spring boot通过EnableWebMvcConfiguration类的getWelcomePage方法获取欢迎页的路径 1private static final String[] CLASSPATH_RESOURCE_LOCATIONS = new String[]&#123;&quot;classpath:/META-INF/resources/&quot;, &quot;classpath:/resources/&quot;, &quot;classpath:/static/&quot;, &quot;classpath:/public/&quot;&#125;; 12345678910111213141516171819private Resource getWelcomePage() &#123; String[] var1 = this.resourceProperties.getStaticLocations(); int var2 = var1.length; for(int var3 = 0; var3 &lt; var2; ++var3) &#123; String location = var1[var3]; Resource indexHtml = this.getIndexHtml(location); if (indexHtml != null) &#123; return indexHtml; &#125; &#125; ServletContext servletContext = this.getServletContext(); if (servletContext != null) &#123; return this.getIndexHtml((Resource)(new ServletContextResource(servletContext, &quot;/&quot;))); &#125; else &#123; return null; &#125;&#125; 方法中的resourceProperties.getStaticLocations()，获取其实就是spring.web.resources.static-locations的值，在没有配置的情况下，spring.web.resources.static-locations为上面CLASSPATH_RESOURCE_LOCATIONS的值，具体可查看resourceProperties类源码。 WebMvcConfigurerorg.springframework.web.servlet.config.annotation.WebMvcConfigurer 是Spring Web MVC框架中的一个接口，用于自定义和扩展Web MVC的配置。开发者可以通过实现这个接口来修改或增强Spring MVC的行为，包括一下功能 addFormatters：添加格式化程序 addResourceHandlers：对特定路径配置静态资源映射的方法，这里只能配置到文件夹 addViewControllers：用于将特定的URL请求映射到特定的视图（需要注意视图和资源的区别），而不需要再创建Controller addInterceptors：对特定路径的URL配置过滤器 1234567891011121314151617181920212223@Componentpublic class WebMvcConfig implements WebMvcConfigurer &#123; @Override public void addFormatters(FormatterRegistry registry) &#123; registry.addFormatter(new DateFormatter(&quot;yyyy-MM-dd&quot;)); &#125; @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler(&quot;/WebContent&quot;).addResourceLocations(&quot;file:D:\\\\Order\\\\WebContent&quot;); &#125; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(&quot;/testh&quot;).setViewName(&quot;testh&quot;); &#125; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new UserRoleAuthorizationInterceptor()).addPathPatterns(&quot;/user&quot;); &#125;&#125;","categories":["知识累积"]},{"title":"Spring Boot整合RabbitMQ事务","path":"/2025/01/07/Spring Boot整合RabbitMQ事务/","content":"开启事务注册Rabbit事务管理器，本质还是实现了Spring的PlatformTransactionManager 123456@Beanpublic RabbitTransactionManager rabbitTransactionManager(CachingConnectionFactory connectionFactory, RabbitTemplate rabbitTemplate) &#123; // channel开启事务支持 rabbitTemplate.setChannelTransacted(true); return new RabbitTransactionManager(connectionFactory);&#125; 发送消息123456789101112//使用spring事务，必须使用该注解@Transactionalpublic void send(String messageStr, String routeKey) &#123; String messageId = String.valueOf(UUID.randomUUID()); Body body = new Body(); body.setCreateTime(DateTime.now()); body.setMessage(messageStr); body.setMessageId(messageId); //将消息携带绑定键值，发送到交换机 rabbitTemplate.convertAndSend(&quot;testTopic&quot;, routeKey, body); System.out.println(rabbitTemplate.isChannelTransacted());&#125; 拦截器我们知道spring声明式事务的核心就是aop拦截器，那么spring是如何拦截rabbit的呢 1234567891011121314151617181920212223242526protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, TransactionAspectSupport.InvocationCallback invocation) throws Throwable &#123; TransactionAttributeSource tas = this.getTransactionAttributeSource(); TransactionAttribute txAttr = tas != null ? tas.getTransactionAttribute(method, targetClass) : null; PlatformTransactionManager tm = this.determineTransactionManager(txAttr); String joinpointIdentification = this.methodIdentification(method, targetClass, txAttr); Object result; if (txAttr != null &amp;&amp; tm instanceof CallbackPreferringPlatformTransactionManager) &#123; //该部分代码比较复杂，没有贴出，可以自行查看，其实就是我没看懂，所以没贴 &#125; else &#123; TransactionAspectSupport.TransactionInfo txInfo = this.createTransactionIfNecessary(tm, txAttr, joinpointIdentification); try &#123; //这里代表我们实际的方法，即加上@Transactional注解的方法，spring在注册bean时，会扫描包含@Transactional注解的方法，然后生成代理方法，即aop拦截 result = invocation.proceedWithInvocation(); &#125; catch (Throwable var17) &#123; //如果发生了报错，则回滚，调用PlatformTransactionManager的rollback()，最终调用channel的txRollback() this.completeTransactionAfterThrowing(txInfo, var17); throw var17; &#125; finally &#123; this.cleanupTransactionInfo(txInfo); &#125; //如果执行成功，则提交，调用PlatformTransactionManager的commit()，最终调用channel的txCommit() this.commitTransactionAfterReturning(txInfo); return result; &#125;&#125; 1234567891011121314151617181920212223242526272829303132protected void completeTransactionAfterThrowing(@Nullable TransactionAspectSupport.TransactionInfo txInfo, Throwable ex) &#123;if (txInfo != null &amp;&amp; txInfo.getTransactionStatus() != null) &#123; if (this.logger.isTraceEnabled()) &#123; this.logger.trace(&quot;Completing transaction for [&quot; + txInfo.getJoinpointIdentification() + &quot;] after exception: &quot; + ex); &#125; //这里主要是判断事务传播机制，以及错误类型是否需要回滚，错误类型由@Transactional注解的rollbackFor属性决定，默认RuntimeException if (txInfo.transactionAttribute != null &amp;&amp; txInfo.transactionAttribute.rollbackOn(ex)) &#123; try &#123; txInfo.getTransactionManager().rollback(txInfo.getTransactionStatus()); &#125; catch (TransactionSystemException var6) &#123; this.logger.error(&quot;Application exception overridden by rollback exception&quot;, ex); var6.initApplicationException(ex); throw var6; &#125; catch (Error | RuntimeException var7) &#123; this.logger.error(&quot;Application exception overridden by rollback exception&quot;, ex); throw var7; &#125; &#125; else &#123; try &#123; txInfo.getTransactionManager().commit(txInfo.getTransactionStatus()); &#125; catch (TransactionSystemException var4) &#123; this.logger.error(&quot;Application exception overridden by commit exception&quot;, ex); var4.initApplicationException(ex); throw var4; &#125; catch (Error | RuntimeException var5) &#123; this.logger.error(&quot;Application exception overridden by commit exception&quot;, ex); throw var5; &#125; &#125;&#125;&#125; 总结rabbitmq本身的事务是通过channel.txSelect、channel.txCommit、channel.txRollback实现的，spring是在rabbitmq本身事务的基础上加了一层事务","categories":["RabbitMQ"]},{"title":"Spring Boot整合Zookeeper","path":"/2025/01/07/Spring Boot整合Zookeeper/","content":"准备依赖使用Curator，是目前使用者最多的zookeeper客户端 12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;5.2.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;5.2.0&lt;/version&gt;&lt;/dependency&gt; 配置类curator需要我们自己配置一个CuratorFramework 12345678910@Configurationpublic class ZookeeperConfig &#123; @Bean(initMethod = &quot;start&quot;)//initMethod表示在Bean创建好后需要执行start的命令 public CuratorFramework curatorFramework()&#123; RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3); return CuratorFrameworkFactory.newClient(&quot;localhost:2181&quot;, retryPolicy); &#125;&#125; 操作代码实现类zookeeper的每条命令curator都有单独的方法对应，需要设置的参数curator也都设置了单独的方法，比如set -v version，curator可以使用setData().setData().withVersion(version) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Servicepublic class ZookeeperService &#123; private Logger logger = LoggerFactory.getLogger(ZookeeperService.class); @Autowired private CuratorFramework client; //create对应zookeeper create命令，withMode对应（-s:-e），代表有序/无序节点；临时/持久节点 public void creatNode(String path, String data) throws Exception &#123; client.create().withMode(CreateMode.PERSISTENT).forPath(path, data.getBytes(StandardCharsets.UTF_8)); &#125; //getData对应zookeeper get命令 public String getNode(String path) throws Exception &#123; byte[] data = client.getData().forPath(path); return new String(data); &#125; //setData对应zookeeper set命令,withVersion()对应-v 设置版本要求 public void setNode(String path, String newData, int version) throws Exception &#123; client.setData().withVersion(version).forPath(path, newData.getBytes(StandardCharsets.UTF_8)); &#125; //delete对应zookeeper delete命令,deletingChildrenIfNeeded()对应deleteall,withVersion()对应-v 设置版本要求 public void deleteNode(String path,int version) throws Exception &#123; client.delete().deletingChildrenIfNeeded().withVersion(version).forPath(path); &#125; //watchers().add() 对应zookeeper addWatch命令，withMode()对应-m 决定采取哪种模式 public void addWatch(String path) throws Exception &#123; client.watchers().add().withMode(AddWatchMode.PERSISTENT).usingWatcher((CuratorWatcher) watchedEvent -&gt; logger.info(&quot;&#123;&#125;&quot;,watchedEvent)).forPath(path); &#125; //curator的缓存机制，利用本地缓存与zookeeper的数据对比实现监听 public void addWatch1(String path)&#123; CuratorCache curatorCache = CuratorCache.build(client, path); curatorCache.listenable().addListener((type, childData, childData1) -&gt; &#123; switch (type)&#123; case NODE_CREATED: logger.info(&quot;创建节点： &#123;&#125;------&#123;&#125;&quot;,childData1.getPath(),new String(childData1.getData())); break; case NODE_CHANGED: logger.info(&quot;节点改变： &#123;&#125;------&#123;&#125; &#123;&#125;------&#123;&#125;&quot;,childData.getPath(),new String(childData.getData()),childData1.getPath(),new String(childData1.getData())); break; case NODE_DELETED: logger.info(&quot;节点删除： &#123;&#125;------&#123;&#125;&quot;,childData.getPath(),new String(childData.getData())); break; &#125; &#125;); //新建完缓存后，一定要启动，否则不会生效 curatorCache.start(); logger.info(&quot;为&#123;&#125;添加watch成功&quot;,path); &#125;&#125; Backgroundable接口 Backgroundable 接口中定义了多个方法，最常用的是 inBackground() 方法，它表示将当前的操作放在后台线程中执行，即异步执行。inBackground() 方法有多个重载形式，其中最简单的形式不需要传入任何参数，表示后台任务执行完成后，不需要回调任何方法。 如果需要在后台任务完成后执行回调方法，可以使用inBackground(org.apache.curator.framework.api.BackgroundCallback callback) 方法。该方法需要传入一个 BackgroundCallback 接口的实现对象，该接口中定义了 processResult() 方法，用于在后台任务执行完成后处理结果。 如果需要在后台任务完成后同时设置回调方法和自定义的 Executor，可以使用 inBackground(BackgroundCallback callback, java.util.concurrent.Executor executor) 方法。其中，Executor 对象表示后台任务执行所使用的线程池，通过它可以控制后台任务的执行。如果不指定 Executor，则会使用默认的线程池。 Curator 框架的许多操作都支持后台异步执行，可以通过 inBackground() 方法指定。在使用 Curator 进行开发时，可以根据实际情况选择同步或异步操作。如果需要执行一些比较耗时的操作，最好采用异步方式，避免阻塞应用程序的主线程。","categories":["Zookeeper"]},{"title":"基于Docker搭建Kafka集群","path":"/2025/01/07/基于Docker搭建Kafka集群/","content":"步骤下载Zookeeper和Kafka镜像通过docker search zookeeper 和 docker search kafka搜索对应的镜像进行下载 执行Zookeeper12docker run -d --name zookeeper -p 2181:2181 zookeeper//注：搭建zookeeper时会有点不同，2888，3888两个端口在这里没有用到，所有没有配置 执行3个Kafka12345678kafka0:docker run -d --user $(id -u) --name kafka0 --privileged=true -p 9090:9090 -v /cluster/kafka/kafka0/data:/bitnami/kafka/data -v /cluster/kafka/kafka0/config/server.properties:/opt/bitnami/kafka/config/server.properties -e KAFKA_BROKER_ID=0 -e KAFKA_ZOOKEEPER_CONNECT=192.168.255.1:2181 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.255.101:9090 -e ALLOW_PLAINTEXT_LISTENER=yes -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9090 kafkakafka1:docker run -d --user $(id -u) --name kafka1 --privileged=true -p 9091:9091 -v /cluster/kafka/kafka1/data:/bitnami/kafka/data -v /cluster/kafka/kafka1/config/server.properties:/opt/bitnami/kafka/config/server.properties -e KAFKA_BROKER_ID=1 -e KAFKA_ZOOKEEPER_CONNECT=192.168.255.1:2181 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.255.101:9091 -e ALLOW_PLAINTEXT_LISTENER=yes -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9091 kafkakafka2:docker run -d --user $(id -u) --name kafka2 --privileged=true -p 9092:9092 -v /cluster/kafka/kafka2/data:/bitnami/kafka/data -v /cluster/kafka/kafka2/config/server.properties:/opt/bitnami/kafka/config/server.properties -e KAFKA_BROKER_ID=2 -e KAFKA_ZOOKEEPER_CONNECT=192.168.255.1:2181 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.255.101:9092 -e ALLOW_PLAINTEXT_LISTENER=yes -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 kafka –user代表以宿主机当前用户作为容器对象，可以不要； –privileged涉及到权限问题，docker在挂载时，可能存在文件无法创建的情况，需要加上这个配置； 挂载data的目的一个是方便查看数据，另一个是方便修改meta.properties(存在和集群相关的信息，比较重要) 挂载server.properties的目的是方便修改配置，虽然可以通过环境变量的方式进行一些配置，但是似乎不是所有配置都可以利用这种方式，例如zookeeper.connection.timeout.ms（kafka连接zookeeper超时时间，有时候连不上zookeeper可以调整这个参数）似乎就不行，可以通过这个方法解决（需要先通过vim创建文件，不然创建的文件是个文件夹，会出现问题，猜测容器在启动的时候才会创建server.properties，所以宿主机的文件会同步写入配置）； 其余配置都是通过环境变量的方式配置Kafka","categories":["kafka"]},{"title":"TransactionTemplate编程式事务","path":"/2025/01/07/TransactionTemplate编程式事务/","content":"TransactionTemplate 编程式事务使用12345678910public void dealUser(Map map2) throws Exception &#123; try &#123; transactionTemplate.execute(transactionStatus -&gt; &#123; //数据库操作 return true； &#125;); &#125; catch (Exception e) &#123; throw new Exception(); &#125;&#125; transactionTemplate.execute源码解析12345678910111213141516171819202122public &lt;T&gt; T execute(TransactionCallback&lt;T&gt; action) throws TransactionException &#123; Assert.state(this.transactionManager != null, &quot;No PlatformTransactionManager set&quot;); if (this.transactionManager instanceof CallbackPreferringPlatformTransactionManager) &#123; return ((CallbackPreferringPlatformTransactionManager)this.transactionManager).execute(this, action); &#125; else &#123; TransactionStatus status = this.transactionManager.getTransaction(this); Object result; try &#123; result = action.doInTransaction(status); &#125; catch (Error | RuntimeException var5) &#123; this.rollbackOnException(status, var5); throw var5; &#125; catch (Throwable var6) &#123; this.rollbackOnException(status, var6); throw new UndeclaredThrowableException(var6, &quot;TransactionCallback threw undeclared checked exception&quot;); &#125; this.transactionManager.commit(status); return result; &#125;&#125; 不难看出execute方法和声明式事务的处理方法也差不多，也是捕获异常的话，就回退并继续抛出异常，否则就尝试提交，这里之所以说尝试提交，就和transactionStatus.setRollbackOnly();有关系 transactionStatus.setRollbackOnly为什么使用transactionStatus.setRollbackOnly();不抛出异常，也可以回退，我们看代码得知，唯一能回退的代码只可能在this.transactionManager.commit(status);里面了，我们看一下代码 1234567891011121314151617181920212223public final void commit(TransactionStatus status) throws TransactionException &#123; if (status.isCompleted()) &#123; throw new IllegalTransactionStateException(&quot;Transaction is already completed - do not call commit or rollback more than once per transaction&quot;); &#125; else &#123; DefaultTransactionStatus defStatus = (DefaultTransactionStatus)status; //就在这里，这里判断一下是否设置了仅回退，如果设置了，直接回退 if (defStatus.isLocalRollbackOnly()) &#123; if (defStatus.isDebug()) &#123; this.logger.debug(&quot;Transactional code has requested rollback&quot;); &#125; this.processRollback(defStatus, false); &#125; else if (!this.shouldCommitOnGlobalRollbackOnly() &amp;&amp; defStatus.isGlobalRollbackOnly()) &#123; if (defStatus.isDebug()) &#123; this.logger.debug(&quot;Global transaction is marked as rollback-only but transactional code requested commit&quot;); &#125; this.processRollback(defStatus, true); &#125; else &#123; this.processCommit(defStatus); &#125; &#125;&#125; 看代码很容易就看出来了，做了判断，判断一下是否设置了仅回退，如果设置了，直接回退","categories":["Spring Boot"]},{"title":"Thread threadLocals属性","path":"/2025/01/07/Thread threadLocals属性/","content":"前言先考虑一个问题，多线程的情况下，如何隔离变量，例如 1234567891011public class Number&#123; private int number; public int getNumber() &#123; return number; &#125; public void setNumber(int number) &#123; this.number = number; &#125;&#125; 在两个线程同时访问同一个Number实例时，从效果来看，通过getNumber获取到的是同一个值，并且可以通过setNunber修改其他线程的值，如何做到number在线程间的隔离呢 Map先看例子 12345678910111213141516171819public class Number&#123; private Map&lt;Thread, Integer&gt; numberMap; public int getNumber() &#123; Thread thread = Thread.currentThread(); return numberMap.get(thread); &#125; public void setNumber(int number) &#123; Thread thread = Thread.currentThread(); numberMap.put(thread, number); &#125; //防止当前线程结束后，内存无法释放 public void remove()&#123; Thread thread = Thread.currentThread(); numberMap.remove(thread); &#125;&#125; 从效果来看，两个线程同时访问同一个Number实例时，通过getNumber获取的值是不一样的，并且无法通过setNunber修改其他线程的值，但是有一个问题，严格来讲，numberMap仍然是线程间持有的，线程仍然可以通过手段访问到其他线程的值甚至线程对象 ThreadLocal先看例子 12345678910111213141516public class Number&#123; private ThreadLocal&lt;Integer&gt; threadLocal; public int getNumber() &#123; return threadLocal.get(); &#125; public void setNumber(int number) &#123; threadLocal.set(number); &#125; //当一个线程不再使用Number时，需要调用此方法，防止内存泄露 public void remove()&#123; threadLocal.remove(); &#125;&#125; ThreadLocal类的get和set方法 123456789101112131415161718192021public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 从ThreadLocal的get和set方法，不难看出，是使用了当前线程的一个ThreadLocalMap，number相当于是存储到了线程内部，所以ThreadLocalMap 可以实现一个隔离的效果","categories":["Java基础"]},{"title":"知识记录","path":"/2025/01/07/知识记录/","content":"Mybatis缓存 一级缓存 (Local Cache) 特点： 默认启用：MyBatis 一级缓存是自动开启的，无需额外配置。 会话级别：一级缓存的作用域局限在同一个 SqlSession 中，即同一个会话内的查询结果会被缓存起来。 线程不安全：每个 SqlSession 对象是线程不安全的，因此一级缓存也是线程私有的，不同线程间的 SqlSession 无法共享一级缓存数据。 简单快速：一级缓存基于 HashMap 实现，数据读取速度快，适用于简单的缓存场景。 生命周期： 一级缓存的生命周期与 SqlSession 绑定，当 SqlSession 关闭、过期或显式清除缓存时，一级缓存随之清空。 缓存策略： 查询时：在同一个 SqlSession 内，当执行相同的查询请求时，MyBatis 会首先在一级缓存中查找结果。如果找到匹配的缓存数据，则直接返回，避免了对数据库的重复查询。 更新时：当在同一个 SqlSession 中执行插入、更新、删除等修改数据库的操作时，MyBatis 会自动清空当前 SqlSession 的一级缓存，以确保缓存数据与数据库状态的一致性。 适用场景： 适用于单个用户或单个操作序列（如一个HTTP请求）内的重复查询，能够有效减少短时间内对同一数据的重复查询。 二级缓存 (Global Cache) 特点： 可配置启用：二级缓存默认关闭，需要在 mybatis-config.xml 文件或 Mapper XML 文件中进行显式配置才能启用。 Mapper（命名空间）级别：二级缓存的作用域扩大到了同一个命名空间（Mapper）的所有 SqlSession，即多个会话间可以共享同一命名空间的缓存数据。 线程安全：二级缓存通常实现为线程安全的数据结构，允许在多线程环境中共享数据。 可扩展：二级缓存支持多种第三方缓存插件，如 Ehcache、Redis、Memcached 等，可以根据需求选择合适的缓存实现。 生命周期： 二级缓存的生命周期与 Mapper 命名空间绑定，当某个命名空间的缓存配置发生变化、或者显式清空缓存时，该命名空间的二级缓存数据才会被清空。 缓存策略： 查询时：在不同 SqlSession 之间，如果执行相同的查询请求且对应 Mapper 已启用二级缓存，MyBatis 会首先在二级缓存中查找结果。如果找到匹配的缓存数据，则直接返回，否则才查询数据库，并将查询结果存入二级缓存供后续查询使用。 更新时：当执行插入、更新、删除等操作时，二级缓存的行为取决于配置。一般情况下，二级缓存会在下一次查询时自动刷新，确保数据新鲜度。但也可以配置为立即刷新或基于某种事件（如JMS消息）触发刷新。 适用场景： 适用于多用户或长时间跨度内的相同查询，尤其适合那些查询数据变化频率较低且被大量用户共享的场景。 总结 一级缓存：轻量级、快速响应，适用于单个会话内减少重复查询，但作用范围有限，且与会话生命周期紧密关联。 二级缓存：更全局、持久的缓存，适用于跨会话共享查询结果，降低了不同用户或服务间对同一数据的重复查询，但配置较为复杂，且需要考虑数据一致性、缓存同步等问题。 在实际使用中，一级缓存和二级缓存可以配合使用，形成多级缓存体系，以更精细的粒度优化查询性能。不过，启用缓存的同时也需要考虑数据一致性、缓存更新策略以及可能引入的并发问题，确保缓存机制在提升性能的同时不会对业务逻辑产生负面影响。","categories":["知识累积"]},{"title":"Java知识","path":"/2025/01/07/Java知识/","content":"Java字符串常量池在jdk1.7之前放在永久代、jdk1.7时放在堆中、jdk1.8及之后放在元空间。Java字符串常量池中的字符串是在编译时确定的，无法在运行时修改或添加新的字符串字面量。如果在运行时需要动态地创建字符串，可以使用new关键字来创建一个新的字符串对象，该对象会被存储在堆内存中。这样的字符串对象不会被添加到字符串常量池中，而是独立于常量池存在，除非显式调用intern方法。 java.util.Collection#parallelStream的最大并发度是由ForkJoinPool决定的，而ForkJoinPool在Java8环境下最大并发度默认是电脑cpu核数，ForkJoinPool最大并发度可以通过一下代码查看： int parallelism= ForkJoinPool.getCommonPoolParallelism(); 可以通过设置系统环境来修改： System.setProperty(&quot;java.util.concurrent.ForkJoinPool.common.parallelism&quot;, &quot;10&quot;) Integer i &#x3D; 100;和Integer i &#x3D; Integer.valueOf(100)都是直接返回java.lang.Integer.IntegerCache#cache数组的元素，仅限-128至127","categories":["知识累积"]},{"title":"Autowired注解源码生效过程","path":"/2025/01/07/Autowired注解源码生效过程/","content":"前言编写代码中遇到一个问题，下面的代码一有时不会生效，必须通过代码二的方式，通过set方法注入DataSource然后再隐式转换赋值，所以稍微研究一下Autowired注解 123456789//代码一@Autowiredprivate DynamicRoutingDataSource dataSource;//代码二@Autowiredpublic void setDataSource(DataSource dataSource) &#123; this.dataSource = (DynamicRoutingDataSource) dataSource;&#125; DynamicRoutingDataSource对象实例化的方法 1234567891011@Bean@ConditionalOnMissingBeanpublic DataSource dataSource(DynamicDataSourceProvider dynamicDataSourceProvider) &#123; DynamicRoutingDataSource dataSource = new DynamicRoutingDataSource(); dataSource.setPrimary(this.properties.getPrimary()); dataSource.setStrategy(this.properties.getStrategy()); dataSource.setProvider(dynamicDataSourceProvider); dataSource.setP6spy(this.properties.getP6spy()); dataSource.setStrict(this.properties.getStrict()); return dataSource;&#125; 涉及相关类InstantiationAwareBeanPostProcessorInstantiationAwareBeanPostProcessor的作用是在属性赋值时，进行一些额外的操作，它是Autowired注解发挥作用最根本的类，Spring创建Bean的过程中，在执行populateBean为对象变量赋值时，大部分地方都在调用InstantiationAwareBeanPostProcessor的方法 12345678910111213141516171819202122public interface InstantiationAwareBeanPostProcessor extends BeanPostProcessor &#123; @Nullable default Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; return null; &#125; default boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException &#123; return true; &#125; @Nullable default PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName) throws BeansException &#123; return null; &#125; /** @deprecated */ @Deprecated @Nullable default PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException &#123; return pvs; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) &#123; if (bw == null) &#123; if (mbd.hasPropertyValues()) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Cannot apply property values to null instance&quot;); &#125; &#125; else &#123; if (!mbd.isSynthetic() &amp;&amp; this.hasInstantiationAwareBeanPostProcessors()) &#123; Iterator var4 = this.getBeanPostProcessorCache().instantiationAware.iterator(); while(var4.hasNext()) &#123; InstantiationAwareBeanPostProcessor bp = (InstantiationAwareBeanPostProcessor)var4.next(); if (!bp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123; return; &#125; &#125; &#125; //pvs是判断是否有是否为当前Bean实例配置了property，xml中可以配置 PropertyValues pvs = mbd.hasPropertyValues() ? mbd.getPropertyValues() : null; int resolvedAutowireMode = mbd.getResolvedAutowireMode(); if (resolvedAutowireMode == 1 || resolvedAutowireMode == 2) &#123; MutablePropertyValues newPvs = new MutablePropertyValues((PropertyValues)pvs); if (resolvedAutowireMode == 1) &#123; this.autowireByName(beanName, mbd, bw, newPvs); &#125; if (resolvedAutowireMode == 2) &#123; this.autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs; &#125; boolean hasInstAwareBpps = this.hasInstantiationAwareBeanPostProcessors(); boolean needsDepCheck = mbd.getDependencyCheck() != 0; PropertyDescriptor[] filteredPds = null; if (hasInstAwareBpps) &#123; if (pvs == null) &#123; pvs = mbd.getPropertyValues(); &#125; PropertyValues pvsToUse; for(Iterator var9 = this.getBeanPostProcessorCache().instantiationAware.iterator(); var9.hasNext(); pvs = pvsToUse) &#123; InstantiationAwareBeanPostProcessor bp = (InstantiationAwareBeanPostProcessor)var9.next(); //Autowired就是通过这里生效的 pvsToUse = bp.postProcessProperties((PropertyValues)pvs, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; if (filteredPds == null) &#123; filteredPds = this.filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); &#125; pvsToUse = bp.postProcessPropertyValues((PropertyValues)pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; return; &#125; &#125; &#125; &#125; if (needsDepCheck) &#123; if (filteredPds == null) &#123; filteredPds = this.filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); &#125; this.checkDependencies(beanName, mbd, filteredPds, (PropertyValues)pvs); &#125; if (pvs != null) &#123; //这里为Xml配置的实例变量或者配置了autowire的实例的变量赋值，需要注意Autowired注解不在这里赋值 this.applyPropertyValues(beanName, mbd, bw, (PropertyValues)pvs); &#125; &#125;&#125; 从populateBean代码可以看出，InstantiationAwareBeanPostProcessor对于populateBean方法相当重要。 关于popluate中调用autowireByName和autowireByType，这两个方法是根据相应的策略，为类中的set方法进行装配，如果是ByName，则根据set方法“set”后面的名称装配，如果是ByType，则根据方法内的参数类型进行装配，在这里还没有为变量赋值，只是先确定赋哪个值，可以通过xml配置或者@Bean注解的方式配置这两者，默认不启用 //以下情况将调用autowireByName装配//&lt;bean&gt;设置autowire属性&lt;bean id=&quot;exampleBean&quot; class=&quot;com.example.ExampleBean&quot; autowire=&quot;byName&quot;&gt;***&lt;/bean&gt;或//@Bean注解使用autowire属性@Bean(name = &quot;exampleBean&quot;, autowire = Autowire.BY_NAME) ## AutowiredAnnotationBeanPostProcessor AutowiredAnnotationBeanPostProcessor实现了InstantiationAwareBeanPostProcessor，是实现Autowired注解逻辑的直接类，它实现的postProcessProperties方法会在类给属性赋值时，检查类对象使用到Autowired注解的变量或者方法，如果有，则尝试为对象变量赋值 1234567891011121314public PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName) &#123; //这一步是检查传入的类使用到Autowired注解的变量或者方法 InjectionMetadata metadata = this.findAutowiringMetadata(beanName, bean.getClass(), pvs); try &#123; //这一步是为那些使用到Autowired注解的变量或者方法变量赋值 metadata.inject(bean, beanName, pvs); return pvs; &#125; catch (BeanCreationException var6) &#123; throw var6; &#125; catch (Throwable var7) &#123; throw new BeanCreationException(beanName, &quot;Injection of autowired dependencies failed&quot;, var7); &#125;&#125; InjectionMetadata这个类主要用于存储和管理与注解相关的元数据，这些元数据描述了如何以及在哪里应用自动注入。上述介绍的postProcessProperties方法中就用到了它。具体来说，InjectionMetadata会收集以下信息： 注解的类型和属性。 需要执行注入的目标成员（如字段或方法）。 任何可能影响注入行为的特定配置（例如，是否需要强制要求依赖存在）。 AutowiredFieldElementAutowiredFieldElement位于InjectionMetadata内部，它代表了注入点的一个基本元素，可以是一个需要进行依赖注入的字段、方法或是构造函数。这个类为处理各种类型的注入点提供了一个统一的基础抽象，封装了执行注入操作所需的基本逻辑和信息。AutowiredFieldElement有一个inject方法，它的子类通过实现这个方法完成不同的注入功能 AutowiredAnnotationBeanPostProcessor实现两个AutowiredFieldElement AutowiredFieldElement：负责处理需要进行依赖注入的字段，例如直接在字段上使用@Autowired注解 AutowiredMethodElement：负责处理负责处理需要进行依赖注入的方法，例如直接在set方法上使用@Autowired注解 DefaultListableBeanFactoryDefaultListableBeanFactory提供了Bean定义的注册、Bean的创建、配置、管理和依赖注入等功能。是Spring框架中一个非常核心的类，它是Spring IoC容器的基础实现之一，负责管理和维护bean的定义（BeanDefinition）以及bean的实例化、配置和组装工作。这个类属于Spring的beans包下，是构建Spring应用上下文（ApplicationContext）的基石 doResolveDependencydoResolveDependency方法，它是Spring框架中bean依赖解析过程的一个核心步骤。这个方法主要用于解决和创建应用程序在运行时需要的bean之间的依赖关系。它是Spring IoC容器如何管理bean间复杂依赖关系背后的关键逻辑实现之一。根据步骤，它会解析依赖描述、查找候选bean、处理泛型依赖、创建或获取bean实例、处理特殊依赖类型、类型转换、处理可选依赖 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100public Object doResolveDependency(DependencyDescriptor descriptor, @Nullable String beanName, @Nullable Set&lt;String&gt; autowiredBeanNames, @Nullable TypeConverter typeConverter) throws BeansException &#123; InjectionPoint previousInjectionPoint = ConstructorResolver.setCurrentInjectionPoint(descriptor); Object var7; try &#123; Object shortcut = descriptor.resolveShortcut(this); if (shortcut == null) &#123; Class&lt;?&gt; type = descriptor.getDependencyType(); Object value = this.getAutowireCandidateResolver().getSuggestedValue(descriptor); Object var23; if (value != null) &#123; if (value instanceof String) &#123; String strVal = this.resolveEmbeddedValue((String)value); BeanDefinition bd = beanName != null &amp;&amp; this.containsBean(beanName) ? this.getMergedBeanDefinition(beanName) : null; value = this.evaluateBeanDefinitionString(strVal, bd); &#125; TypeConverter converter = typeConverter != null ? typeConverter : this.getTypeConverter(); try &#123; var23 = converter.convertIfNecessary(value, type, descriptor.getTypeDescriptor()); return var23; &#125; catch (UnsupportedOperationException var18) &#123; Object var25 = descriptor.getField() != null ? converter.convertIfNecessary(value, type, descriptor.getField()) : converter.convertIfNecessary(value, type, descriptor.getMethodParameter()); return var25; &#125; &#125; Object multipleBeans = this.resolveMultipleBeans(descriptor, beanName, autowiredBeanNames, typeConverter); if (multipleBeans != null) &#123; var23 = multipleBeans; return var23; &#125; //这一步是查找候选者，即符合注入条件的对象，这一步返回的可能是Class对象也有可能是生成好的Bean Map&lt;String, Object&gt; matchingBeans = this.findAutowireCandidates(beanName, type, descriptor); String autowiredBeanName; if (matchingBeans.isEmpty()) &#123; if (this.isRequired(descriptor)) &#123; this.raiseNoMatchingBeanFound(type, descriptor.getResolvableType(), descriptor); &#125; autowiredBeanName = null; return autowiredBeanName; &#125; Object instanceCandidate; Object result; if (matchingBeans.size() &gt; 1) &#123; autowiredBeanName = this.determineAutowireCandidate(matchingBeans, descriptor); if (autowiredBeanName == null) &#123; if (!this.isRequired(descriptor) &amp;&amp; this.indicatesMultipleBeans(type)) &#123; result = null; return result; &#125; result = descriptor.resolveNotUnique(descriptor.getResolvableType(), matchingBeans); return result; &#125; instanceCandidate = matchingBeans.get(autowiredBeanName); &#125; else &#123; Map.Entry&lt;String, Object&gt; entry = (Map.Entry)matchingBeans.entrySet().iterator().next(); autowiredBeanName = (String)entry.getKey(); instanceCandidate = entry.getValue(); &#125; if (autowiredBeanNames != null) &#123; autowiredBeanNames.add(autowiredBeanName); &#125; if (instanceCandidate instanceof Class) &#123; //如果返回的是候选者Class对象，则在这一步尝试解析成候选者Bean，这一步其实就是调用beanFactory.getBean(autowiredBeanName) instanceCandidate = descriptor.resolveCandidate(autowiredBeanName, type, this); &#125; result = instanceCandidate; if (instanceCandidate instanceof NullBean) &#123; if (this.isRequired(descriptor)) &#123; this.raiseNoMatchingBeanFound(type, descriptor.getResolvableType(), descriptor); &#125; result = null; &#125; if (!ClassUtils.isAssignableValue(type, result)) &#123; throw new BeanNotOfRequiredTypeException(autowiredBeanName, type, instanceCandidate.getClass()); &#125; Object var14 = result; return var14; &#125; var7 = shortcut; &#125; finally &#123; ConstructorResolver.setCurrentInjectionPoint(previousInjectionPoint); &#125; return var7;&#125; 这个方法比较重要的一步就是查找候选者，即上述代码中的 Map&lt;String, Object&gt; matchingBeans &#x3D; this.findAutowireCandidates(beanName, type, descriptor); 这一步是查询候选者，返回的可能是生成好的Bean实例，也有可能是Bean的Class对象， findAutowireCandidatesfindAutowireCandidates 方法是Spring框架IoC（控制反转）容器中的一个重要组成部分。该方法负责在容器中寻找可以自动装配的bean候选者，这主要发生在依赖注入的过程中。它不仅会寻找bean候选者，还会尝试获取实例，它会尝试先获取候选者的名称，然后判断是否存在候选者的实例，如果存在，则返回候选者实例，如果不存在，则返回候选者的类型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960protected Map&lt;String, Object&gt; findAutowireCandidates(@Nullable String beanName, Class&lt;?&gt; requiredType, DependencyDescriptor descriptor) &#123; //这一步就是获取候选者们 String[] candidateNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(this, requiredType, true, descriptor.isEager()); Map&lt;String, Object&gt; result = CollectionUtils.newLinkedHashMap(candidateNames.length); Iterator var6 = this.resolvableDependencies.entrySet().iterator(); while(var6.hasNext()) &#123; Map.Entry&lt;Class&lt;?&gt;, Object&gt; classObjectEntry = (Map.Entry)var6.next(); Class&lt;?&gt; autowiringType = (Class)classObjectEntry.getKey(); if (autowiringType.isAssignableFrom(requiredType)) &#123; Object autowiringValue = classObjectEntry.getValue(); autowiringValue = AutowireUtils.resolveAutowiringValue(autowiringValue, requiredType); if (requiredType.isInstance(autowiringValue)) &#123; result.put(ObjectUtils.identityToString(autowiringValue), autowiringValue); break; &#125; &#125; &#125; String[] var12 = candidateNames; int var14 = candidateNames.length; for(int var16 = 0; var16 &lt; var14; ++var16) &#123; String candidate = var12[var16]; if (!this.isSelfReference(beanName, candidate) &amp;&amp; this.isAutowireCandidate(candidate, descriptor)) &#123; //addCandidateEntry会尝试获取实例的方法 this.addCandidateEntry(result, candidate, descriptor, requiredType); &#125; &#125; if (result.isEmpty()) &#123; boolean multiple = this.indicatesMultipleBeans(requiredType); DependencyDescriptor fallbackDescriptor = descriptor.forFallbackMatch(); String[] var17 = candidateNames; int var19 = candidateNames.length; int var10; String candidate; for(var10 = 0; var10 &lt; var19; ++var10) &#123; candidate = var17[var10]; if (!this.isSelfReference(beanName, candidate) &amp;&amp; this.isAutowireCandidate(candidate, fallbackDescriptor) &amp;&amp; (!multiple || this.getAutowireCandidateResolver().hasQualifier(descriptor))) &#123; this.addCandidateEntry(result, candidate, descriptor, requiredType); &#125; &#125; if (result.isEmpty() &amp;&amp; !multiple) &#123; var17 = candidateNames; var19 = candidateNames.length; for(var10 = 0; var10 &lt; var19; ++var10) &#123; candidate = var17[var10]; if (this.isSelfReference(beanName, candidate) &amp;&amp; (!(descriptor instanceof MultiElementDescriptor) || !beanName.equals(candidate)) &amp;&amp; this.isAutowireCandidate(candidate, fallbackDescriptor)) &#123; this.addCandidateEntry(result, candidate, descriptor, requiredType); &#125; &#125; &#125; &#125; return result;&#125; 这个方法当中 BeanFactoryUtils.beanNamesForTypeIncludingAncestors获取候选者名称 addCandidateEntry会尝试获取候选者实例或者类型 findAutowireCandidates方法后面涉及到一个比较重要的方法就是doGetBeanNamesForType，是实现获取候选者名称的关键之一 doGetBeanNamesForTypedoGetBeanNamesForType是Spring IoC容器核心功能的一部分。这个方法主要用于根据给定的类型查找并返回所有匹配的bean名称列表。它是Spring在内部用于处理按类型查找Bean的请求的关键方法。它主要是通过遍历beanDefinitionNames（Spring Boot中所有Bean定义名称的集合，一般为类名或者类全限定名），然后判断是否和需要解析的Bean匹配，然后返回所有匹配的Bean名称 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980private String[] doGetBeanNamesForType(ResolvableType type, boolean includeNonSingletons, boolean allowEagerInit) &#123; List&lt;String&gt; result = new ArrayList(); //获取所有Bean定义名称的集合的迭代器，用于遍历 Iterator var5 = this.beanDefinitionNames.iterator(); while(true) &#123; String beanName; do &#123; if (!var5.hasNext()) &#123; var5 = this.manualSingletonNames.iterator(); while(var5.hasNext()) &#123; beanName = (String)var5.next(); try &#123; if (this.isFactoryBean(beanName)) &#123; if ((includeNonSingletons || this.isSingleton(beanName)) &amp;&amp; this.isTypeMatch(beanName, type)) &#123; result.add(beanName); continue; &#125; beanName = &quot;&amp;&quot; + beanName; &#125; if (this.isTypeMatch(beanName, type)) &#123; result.add(beanName); &#125; &#125; catch (NoSuchBeanDefinitionException var13) &#123; this.logger.trace(LogMessage.format(&quot;Failed to check manually registered singleton with name &#x27;%s&#x27;&quot;, beanName), var13); &#125; &#125; return StringUtils.toStringArray(result); &#125; beanName = (String)var5.next(); &#125; while(this.isAlias(beanName)); try &#123; RootBeanDefinition mbd = this.getMergedLocalBeanDefinition(beanName); if (!mbd.isAbstract() &amp;&amp; (allowEagerInit || (mbd.hasBeanClass() || !mbd.isLazyInit() || this.isAllowEagerClassLoading()) &amp;&amp; !this.requiresEagerInitForType(mbd.getFactoryBeanName()))) &#123; boolean isFactoryBean = this.isFactoryBean(beanName, mbd); BeanDefinitionHolder dbd = mbd.getDecoratedDefinition(); boolean matchFound = false; boolean allowFactoryBeanInit = allowEagerInit || this.containsSingleton(beanName); boolean isNonLazyDecorated = dbd != null &amp;&amp; !mbd.isLazyInit(); if (!isFactoryBean) &#123; if (includeNonSingletons || this.isSingleton(beanName, mbd, dbd)) &#123; //判断当前Bean与目标Bean是否匹配 matchFound = this.isTypeMatch(beanName, type, allowFactoryBeanInit); &#125; &#125; else &#123; if (includeNonSingletons || isNonLazyDecorated || allowFactoryBeanInit &amp;&amp; this.isSingleton(beanName, mbd, dbd)) &#123; matchFound = this.isTypeMatch(beanName, type, allowFactoryBeanInit); &#125; if (!matchFound) &#123; beanName = &quot;&amp;&quot; + beanName; if (includeNonSingletons || this.isSingleton(beanName, mbd, dbd)) &#123; matchFound = this.isTypeMatch(beanName, type, allowFactoryBeanInit); &#125; &#125; &#125; if (matchFound) &#123; result.add(beanName); &#125; &#125; &#125; catch (BeanDefinitionStoreException | CannotLoadBeanClassException var14) &#123; if (allowEagerInit) &#123; throw var14; &#125; LogMessage message = var14 instanceof CannotLoadBeanClassException ? LogMessage.format(&quot;Ignoring bean class loading failure for bean &#x27;%s&#x27;&quot;, beanName) : LogMessage.format(&quot;Ignoring unresolvable metadata in bean definition &#x27;%s&#x27;&quot;, beanName); this.logger.trace(message, var14); this.onSuppressedException(var14); &#125; catch (NoSuchBeanDefinitionException var15) &#123; &#125; &#125;&#125; 这个方法当中比较关键的就是通过isTypeMatch筛选符合条件的Bean的名称 isTypeMatchisTypeMatch是Spring IoC容器内部用于检查和验证Bean类型是否匹配的核心方法之一。这个方法主要用于在实例化或注入Bean之前，确定一个已经注册的Bean（通过名字指定）是否与期望的类型相匹配。开头讲到通过方式一注入有时候行有时候不行，就是在这里找到了原因 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105protected boolean isTypeMatch(String name, ResolvableType typeToMatch, boolean allowFactoryBeanInit) throws NoSuchBeanDefinitionException &#123; String beanName = this.transformedBeanName(name); boolean isFactoryDereference = BeanFactoryUtils.isFactoryDereference(name); Object beanInstance = this.getSingleton(beanName, false); if (beanInstance != null &amp;&amp; beanInstance.getClass() != NullBean.class) &#123; if (beanInstance instanceof FactoryBean) &#123; if (isFactoryDereference) &#123; return typeToMatch.isInstance(beanInstance); &#125; else &#123; Class&lt;?&gt; type = this.getTypeForFactoryBean((FactoryBean)beanInstance); return type != null &amp;&amp; typeToMatch.isAssignableFrom(type); &#125; &#125; else &#123; if (!isFactoryDereference) &#123; if (typeToMatch.isInstance(beanInstance)) &#123; return true; &#125; if (typeToMatch.hasGenerics() &amp;&amp; this.containsBeanDefinition(beanName)) &#123; RootBeanDefinition mbd = this.getMergedLocalBeanDefinition(beanName); Class&lt;?&gt; targetType = mbd.getTargetType(); if (targetType != null &amp;&amp; targetType != ClassUtils.getUserClass(beanInstance)) &#123; Class&lt;?&gt; classToMatch = typeToMatch.resolve(); if (classToMatch != null &amp;&amp; !classToMatch.isInstance(beanInstance)) &#123; return false; &#125; if (typeToMatch.isAssignableFrom(targetType)) &#123; return true; &#125; &#125; ResolvableType resolvableType = mbd.targetType; if (resolvableType == null) &#123; resolvableType = mbd.factoryMethodReturnType; &#125; return resolvableType != null &amp;&amp; typeToMatch.isAssignableFrom(resolvableType); &#125; &#125; return false; &#125; &#125; else if (this.containsSingleton(beanName) &amp;&amp; !this.containsBeanDefinition(beanName)) &#123; return false; &#125; else &#123; BeanFactory parentBeanFactory = this.getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !this.containsBeanDefinition(beanName)) &#123; return parentBeanFactory.isTypeMatch(this.originalBeanName(name), typeToMatch); &#125; else &#123; RootBeanDefinition mbd = this.getMergedLocalBeanDefinition(beanName); BeanDefinitionHolder dbd = mbd.getDecoratedDefinition(); Class&lt;?&gt; classToMatch = typeToMatch.resolve(); if (classToMatch == null) &#123; classToMatch = FactoryBean.class; &#125; Class&lt;?&gt;[] typesToMatch = FactoryBean.class == classToMatch ? new Class[]&#123;classToMatch&#125; : new Class[]&#123;FactoryBean.class, classToMatch&#125;; Class&lt;?&gt; predictedType = null; if (!isFactoryDereference &amp;&amp; dbd != null &amp;&amp; this.isFactoryBean(beanName, mbd) &amp;&amp; (!mbd.isLazyInit() || allowFactoryBeanInit)) &#123; RootBeanDefinition tbd = this.getMergedBeanDefinition(dbd.getBeanName(), dbd.getBeanDefinition(), mbd); Class&lt;?&gt; targetType = this.predictBeanType(dbd.getBeanName(), tbd, typesToMatch); if (targetType != null &amp;&amp; !FactoryBean.class.isAssignableFrom(targetType)) &#123; predictedType = targetType; &#125; &#125; if (predictedType == null) &#123; predictedType = this.predictBeanType(beanName, mbd, typesToMatch); if (predictedType == null) &#123; return false; &#125; &#125; ResolvableType beanType = null; if (FactoryBean.class.isAssignableFrom(predictedType)) &#123; if (beanInstance == null &amp;&amp; !isFactoryDereference) &#123; beanType = this.getTypeForFactoryBean(beanName, mbd, allowFactoryBeanInit); predictedType = beanType.resolve(); if (predictedType == null) &#123; return false; &#125; &#125; &#125; else if (isFactoryDereference) &#123; predictedType = this.predictBeanType(beanName, mbd, FactoryBean.class); if (predictedType == null || !FactoryBean.class.isAssignableFrom(predictedType)) &#123; return false; &#125; &#125; if (beanType == null) &#123; ResolvableType definedType = mbd.targetType; if (definedType == null) &#123; definedType = mbd.factoryMethodReturnType; &#125; if (definedType != null &amp;&amp; definedType.resolve() == predictedType) &#123; beanType = definedType; &#125; &#125; return beanType != null ? typeToMatch.isAssignableFrom(beanType) : typeToMatch.isAssignableFrom(predictedType); &#125; &#125;&#125; 直接用前言中的例子放到这个方法里面分析一下，方法开始会尝试根据待匹配的BeanName获取Bean实例，如果获取成功（这里指的获取成功，代表这之前，待匹配的BeanName已经实例化完成了），则判断待匹配的Bean实例是否是需要注入的对象的类或者子类，如果获取待匹配的BeanName的实例失败，则往后执行，普通的Bean最后都会通过判断待匹配的BeanName的Bean定义中的类是否是需要注入的对象的类或者子类。 这里我们假设DynamicRoutingDataSource已经实例化完成了，那么待匹配的Bean实例就是DynamicRoutingDataSource，而我们需要注入的也是DynamicRoutingDataSource类，那么这里就ok。这里的情况是因为引入JdbcTemplate之后，JdbcTemplate会引入DataSource，导致DynamicRoutingDataSource提前实例化了 如果这里DynamicRoutingDataSource还没有实例化完成，通过前言中DynamicRoutingDataSource实例化的方法可知，DynamicRoutingDataSource的Bean定义中的类是DataSource，而DataSource不是DynamicRoutingDataSource，更不是它的子类，很明显就无法匹配，最后也无法注入 而前言中的方式二可以成功是因为，哪怕DynamicRoutingDataSource还没有实例化完成，但是我们需要注入的类是DataSource，和DynamicRoutingDataSource的Bean定义中的DataSource类是一样的，所以可以注入成功 总结出现这种情况，是因为，需要注入的对象和候选者对象比较的时候除了问题，候选者Bean是否已经实例化会影响比较的逻辑，这里又涉及到Bean实例化的时机，像本文中的例子，JdbcTemplate会先加载DataSource。 Spring Boot会先将程序中需要注册的类先放到一个定义集合，然后ApplicationContext就会循环定义集合创建Bean实例，在创建的过程中，遇到需要注入的情况，BeanFactory会直接创建需要注入的实例","categories":["Spring Boot"]},{"title":"Spring多数据源事务","path":"/2025/01/07/Spring多数据源事务/","content":"前言系统中有一些情况需要在一个业务中涉及到多个数据源，在平时遇到这种情况，喜欢将每个数据源的操作分别提取到一个单独的方法，这样可以利用Dynamic多数据源和Spring事务，实现多数据源操作，但是对于这个情况来说，由于同一个数据源有些操作并不是连续的，所以需要构建很多方法，过于复杂。如果放在同一个方法，那么如何切换数据源（本质上应该叫切换数据库连接）就是问题，所以先需要看一下JdbcTemplate和Mybatis在事务和非事务环境下，分别是如何获取数据库连接的，这样才可以确定，如何切换数据源以及数据库连接 对于Spring事务和数据源的关系，Spring事务本质上还是使用到Connection的commit、rollback等方法，也就是数据库本身的事务能力，所以同一个事务必须使用同一个数据库连接，所以同一个事务在代码中使用同一个数据源不够，得确定是同一个数据库连接 DataSourceTransactionManagerDataSourceTransactionManager是Spring用管理数据库默认的事务管理器 它会在开启事务的时候，从自身的数据源中获取一个数据库连接，并将数据源作为key，数据库连接作为value绑定到事务，这样后续有涉及到数据库操作的时候可通过数据源直接从事务中获取已经生成的数据库连接，并通过这个数据库连接进行操作 提交或者事务的时候，它会执行上面的数据库连接的提交或者回滚操作 JdbcTemplate分析12345678910111213141516171819202122232425262728293031323334353637383940414243private &lt;T&gt; T execute(PreparedStatementCreator psc, PreparedStatementCallback&lt;T&gt; action, boolean closeResources)throws DataAccessException &#123; Assert.notNull(psc, &quot;PreparedStatementCreator must not be null&quot;); Assert.notNull(action, &quot;Callback object must not be null&quot;); if (logger.isDebugEnabled()) &#123; String sql = getSql(psc); logger.debug(&quot;Executing prepared SQL statement&quot; + (sql != null ? &quot; [&quot; + sql + &quot;]&quot; : &quot;&quot;)); &#125; Connection con = DataSourceUtils.getConnection(obtainDataSource()); PreparedStatement ps = null; try &#123; ps = psc.createPreparedStatement(con); applyStatementSettings(ps); T result = action.doInPreparedStatement(ps); handleWarnings(ps); return result; &#125; catch (SQLException ex) &#123; // Release Connection early, to avoid potential connection pool deadlock // in the case when the exception translator hasn&#x27;t been initialized yet. if (psc instanceof ParameterDisposer) &#123; ((ParameterDisposer) psc).cleanupParameters(); &#125; String sql = getSql(psc); psc = null; JdbcUtils.closeStatement(ps); ps = null; DataSourceUtils.releaseConnection(con, getDataSource()); con = null; throw translateException(&quot;PreparedStatementCallback&quot;, sql, ex); &#125; finally &#123; if (closeResources) &#123; if (psc instanceof ParameterDisposer) &#123; ((ParameterDisposer) psc).cleanupParameters(); &#125; JdbcUtils.closeStatement(ps); DataSourceUtils.releaseConnection(con, getDataSource()); &#125; &#125;&#125; 该方法是JdbcTemplate执行sql的通用方法，这里通过DataSourceUtils.getConnection方法获取数据库连接，参数就是JdbcTemplate本身的dataSource变量，而DataSourceUtils.getConnection方法后面调用的是DataSourceUtils.doGetConnection方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445public static Connection doGetConnection(DataSource dataSource) throws SQLException &#123; Assert.notNull(dataSource, &quot;No DataSource specified&quot;); ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(dataSource); if (conHolder != null &amp;&amp; (conHolder.hasConnection() || conHolder.isSynchronizedWithTransaction())) &#123; conHolder.requested(); if (!conHolder.hasConnection()) &#123; logger.debug(&quot;Fetching resumed JDBC Connection from DataSource&quot;); conHolder.setConnection(fetchConnection(dataSource)); &#125; return conHolder.getConnection(); &#125; // Else we either got no holder or an empty thread-bound holder here. logger.debug(&quot;Fetching JDBC Connection from DataSource&quot;); Connection con = fetchConnection(dataSource); if (TransactionSynchronizationManager.isSynchronizationActive()) &#123; try &#123; // Use same Connection for further JDBC actions within the transaction. // Thread-bound object will get removed by synchronization at transaction completion. ConnectionHolder holderToUse = conHolder; if (holderToUse == null) &#123; holderToUse = new ConnectionHolder(con); &#125; else &#123; holderToUse.setConnection(con); &#125; holderToUse.requested(); TransactionSynchronizationManager.registerSynchronization( new ConnectionSynchronization(holderToUse, dataSource)); holderToUse.setSynchronizedWithTransaction(true); if (holderToUse != conHolder) &#123; TransactionSynchronizationManager.bindResource(dataSource, holderToUse); &#125; &#125; catch (RuntimeException ex) &#123; // Unexpected exception from external delegation call -&gt; close Connection and rethrow. releaseConnection(con, dataSource); throw ex; &#125; &#125; return con;&#125; 简单梳理一下这个方法的逻辑 尝试获取事务管理器中与当前与dataSource关联的ConnectionHolder，需要注意，这一步不是从dataSource中获取数据库连接 如果获取成功，并且（ConnectionHolder存在数据库连接或者ConnectionHolder与事务同步），那么尝试从ConnectionHolder中获取数据库连接，如果获取失败，则从dataSource中获取数据库连接并且赋给ConnectionHolder，这一步将直接返回数据库连接，不会再往下执行 如果上一个条件不满足，则直接从dataSource获取数据库连接 然后判断事务管理器的同步属性是否处于活动状态（即当前开启了事务） 如果处于活动状态，则将第三步获取的数据库连接构造成ConnectionHolder，并在事务中将dataSource与它关联，这样后面对于该数据源的数据库操作，在获取数据库连接时，则直接获取这里的数据库连接 如果不处于活动状态，则直接返回第三步获取的数据库连接 总的来说，在此方法中，如果当前处于事务，则从事务中获取与dataSource关联的连接，如果没有关联的连接，则从dataSource中获取，并且放到事务中。如果当前不处于事务，则直接从dataSource中获取返回吗 这个方法配合DataSourceTransactionManager实现事务的功能，后者往事务中注册连接，前者从事务中获取连接，这样事务中的数据库操作都是经过一个数据库连接了 总结对于JdbcTemplate来说 在非事务环境下，数据库连接直接从dataSource获取，那么切换数据库连接就非常方便了，通过setDataSource方法即可 在事务环境下，数据库连接需要从事务中获取，其实这里切换数据库连接也很方便，也只需通过setDataSource方法即可，因为事务中与dataSource关联的数据库连接一定是该dataSource创建的。这里需要注意，在事务环境下如果JdbcTemplate设置的是一个没有事务管理器管理的dataSource，那么JdbcTemplate也会将它和它创建的数据库连接放入导事务中，后续涉及到该dataSource的数据库操作，也会使用同一个连接，但是这些操作不会被事务控制，也就是不会有提交、回滚等操作 总的来说，JdbcTemplate数据源切换是很方便的，如果每个dataSource有事务要求，那么需要为每个dataSource配置一个事务管理器，不过这里还涉及到事务管理器的开启、提交、回滚等操作 Mybatis分析1234protected Connection getConnection(Log statementLog) throws SQLException &#123; Connection connection = this.transaction.getConnection(); return statementLog.isDebugEnabled() ? ConnectionLogger.newInstance(connection, statementLog, this.queryStack) : connection;&#125; 这个方法是Mybatis获取数据库连接的通用方法，这里的transaction在Spring环境下是SpringManagedTransaction 1234567public Connection getConnection() throws SQLException &#123; if (this.connection == null) &#123; this.openConnection(); &#125; return this.connection;&#125; 12345678private void openConnection() throws SQLException &#123; this.connection = DataSourceUtils.getConnection(this.dataSource); this.autoCommit = this.connection.getAutoCommit(); this.isConnectionTransactional = DataSourceUtils.isConnectionTransactional(this.connection, this.dataSource); LOGGER.debug(() -&gt; &#123; return &quot;JDBC Connection [&quot; + this.connection + &quot;] will&quot; + (this.isConnectionTransactional ? &quot; &quot; : &quot; not &quot;) + &quot;be managed by Spring&quot;; &#125;);&#125; 可以看到打开数据库连接，和JdbcTemplate一样也是通过DataSourceUtils.getConnection方法获取数据库连接，但是SpringManagedTransaction的dataSource无法切换也无法设置，只能通过DynamicRoutingDataSource的机制切换实际的dataSource，而无法切换DynamicRoutingDataSource 12345678910111213141516171819private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; DefaultSqlSession var8; try &#123; Environment environment = this.configuration.getEnvironment(); TransactionFactory transactionFactory = this.getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); Executor executor = this.configuration.newExecutor(tx, execType); var8 = new DefaultSqlSession(this.configuration, executor, autoCommit); &#125; catch (Exception var12) &#123; this.closeTransaction(tx); throw ExceptionFactory.wrapException(&quot;Error opening session. Cause: &quot; + var12, var12); &#125; finally &#123; ErrorContext.instance().reset(); &#125; return var8;&#125; 这里是创建SqlSession的代码，this.configuration是MybatisConfiguration transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);这一句就是创建SpringManagedTransaction的，可以看到，dataSource是从MybatisConfiguration中获取的，而SqlSessionFactory与MybatisConfiguration都是单例的，生命周期是整个程序运行期间，只会在程序开始运行的时候实例化，所以运行过程中，无法手动切换Mybatis的数据源，只能通过DynamicRoutingDataSource的机制切换实际的dataSource。其实可以通过更改SqlSessionFactory的配置实现切换数据源，但是SqlSessionFactory是单例的，如果在运行期间，尤其高并发的情况下很危险 从这个方法中也可以看到SpringManagedTransaction的生命周期是跟随SqlSession的，也就是说，同一个SqlSession的数据库连接，肯定是一样的 Spring环境中SqlSession是通过SqlSessionTemplate管理的，SqlSessionTemplate是SqlSession的代理类并且它是单例的，生命周期是整个程序运行期间，它通过SqlSessionUtils获取SqlSession实例 12345678910111213141516public static SqlSession getSqlSession(SqlSessionFactory sessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) &#123; Assert.notNull(sessionFactory, &quot;No SqlSessionFactory specified&quot;); Assert.notNull(executorType, &quot;No ExecutorType specified&quot;); SqlSessionHolder holder = (SqlSessionHolder)TransactionSynchronizationManager.getResource(sessionFactory); SqlSession session = sessionHolder(executorType, holder); if (session != null) &#123; return session; &#125; else &#123; LOGGER.debug(() -&gt; &#123; return &quot;Creating a new SqlSession&quot;; &#125;); session = sessionFactory.openSession(executorType); registerSessionHolder(sessionFactory, executorType, exceptionTranslator, session); return session; &#125;&#125; 这里可以看到，获取SqlSession的过程中，会尝试从事务中获取SqlSessionHolder，如果没获取成功，通过SqlSessionFaciory获取SqlSession，并且尝试注册到事务 12345678910111213141516171819202122232425262728private static void registerSessionHolder(SqlSessionFactory sessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator, SqlSession session) &#123; if (TransactionSynchronizationManager.isSynchronizationActive()) &#123; Environment environment = sessionFactory.getConfiguration().getEnvironment(); if (environment.getTransactionFactory() instanceof SpringManagedTransactionFactory) &#123; LOGGER.debug(() -&gt; &#123; return &quot;Registering transaction synchronization for SqlSession [&quot; + session + &quot;]&quot;; &#125;); SqlSessionHolder holder = new SqlSessionHolder(session, executorType, exceptionTranslator); TransactionSynchronizationManager.bindResource(sessionFactory, holder); TransactionSynchronizationManager.registerSynchronization(new SqlSessionSynchronization(holder, sessionFactory)); holder.setSynchronizedWithTransaction(true); holder.requested(); &#125; else &#123; if (TransactionSynchronizationManager.getResource(environment.getDataSource()) != null) &#123; throw new TransientDataAccessResourceException(&quot;SqlSessionFactory must be using a SpringManagedTransactionFactory in order to use Spring transaction synchronization&quot;); &#125; LOGGER.debug(() -&gt; &#123; return &quot;SqlSession [&quot; + session + &quot;] was not registered for synchronization because DataSource is not transactional&quot;; &#125;); &#125; &#125; else &#123; LOGGER.debug(() -&gt; &#123; return &quot;SqlSession [&quot; + session + &quot;] was not registered for synchronization because synchronization is not active&quot;; &#125;); &#125;&#125; 通过这段代码，如果当前是在事务状态 TransactionSynchronizationManager.bindResource(sessionFactory, holder);这条命令是将SqlSessionFactory和SqlSessionHolder关联到事务，以便事务后续操作可以获取到同一个SqlSession TransactionSynchronizationManager.registerSynchronization(new SqlSessionSynchronization(holder, sessionFactory));这条命令是注册事务同步事件，因为使用事务管理SqlSession，那么SqlSession的关闭就不能在SqlSessionTemplate中执行了，而需要在事务结束后关闭，所以需要注册事务同步事件用来关闭SqlSession 总结Mybatis通过SqlSession管理数据库连接，又通过事务管理SqlSession的方式达到事务的目的 在非事务状态下，Mybatis每次执行数据库操作，都会重新获取SqlSession，即同时重新获取数数据库连接，这一步可以通过DynamicRoutingDataSource的机制从不同的数据源种获取数据库连接达到切换数据源的目的 在事务状态下，Mybatis获取的SqlSession是同一个，也就是说在事务状态下，Mybatis无法切换数据源以及数据库连接 所以Mybatis和JdbcTemplate略有不同，像前言中的在一个业务方法（开启事务）中切换数据源，Mybatis是做不到的 总结在一个业务方法（不开启事务）中切换数据源，JdbcTemplate和Mybatis都可以做到，但是不同的是，Mybatis只能在通过DataSource获取数据库连接的时候通过DynamicRoutingDataSource或者类似的机制实现切换数据源的效果，而JdbcTemplate可以直接切换 在一个业务方法（开启事务）中切换数据源，只有JdbcTemplate可以做到，只是得为每个数据源都创建一个事务管理器确保每个数据源的数据库操作都可以提交或者回滚（一个方法中的所有操作，不管多少个数据源，要么同时提交，要么同时回滚），而Spring只能管理一个事务管理器，所以得我们自己来管理，有两种办法，一种是建立拦截器，然后在拦截器中控制事务管理器，这样的话就不需要使用@Transactional，即不需要使用Spring事务管理了，第二种办法，自己实现一个多事务管理器，这种实现就还是使用Spring事务管理 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class MultiTransactionAspect &#123; private final PlatformTransactionManager[] transactionManagers; public MultiTransactionAspect(PlatformTransactionManager[] transactionManagers) &#123; this.transactionManagers = transactionManagers; &#125; @Around(&quot;@annotation(multiTransaction)&quot;) public Object manageMultiTransaction(ProceedingJoinPoint joinPoint, MultiTransaction multiTransaction) throws Throwable &#123; TransactionStatus[] transactionStatuses = new TransactionStatus[transactionManagers.length]; try &#123; // 开启多个事务 for (int i = 0; i &lt; transactionManagers.length; i++) &#123; DefaultTransactionDefinition def = new DefaultTransactionDefinition(TransactionDefinition.PROPAGATION_REQUIRES_NEW); transactionStatuses[i] = transactionManagers[i].getTransaction(def); &#125; // 执行目标方法 Object result = joinPoint.proceed(); // 提交多个事务 for (TransactionStatus status : transactionStatuses) &#123; initSynchronization();//因为一个事务管理提交后，会移除当前事务同步，如果已经当前线程事务同步已经杯移除了，需要先初始化，否则事务提交会报错 transactionManagers[Arrays.asList(transactionStatuses).indexOf(status)].commit(status); &#125; return result; &#125; catch (Exception e) &#123; // 回滚多个事务 for (TransactionStatus status : transactionStatuses) &#123; if (status != null &amp;&amp; !status.isCompleted()) &#123; initSynchronization();//因为一个事务管理提交后，会移除当前事务同步，如果已经当前线程事务同步已经杯移除了，需要先初始化，否则事务提交会报错 transactionManagers[Arrays.asList(transactionStatuses).indexOf(status)].rollback(status); &#125; &#125; throw e; &#125; &#125; private void initSynchronization() &#123; if(!TransactionSynchronizationManager.isSynchronizationActive())&#123; TransactionSynchronizationManager.initSynchronization(); &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class CustomTransactionManager implements PlatformTransactionManager &#123; private final PlatformTransactionManager[] transactionManagers; private final TransactionStatus[] transactionStatuses; public CustomTransactionManager(PlatformTransactionManager[] transactionManagers) &#123; this.transactionManagers = transactionManagers; transactionStatuses = new TransactionStatus[transactionManagers.length]; &#125; @Override public TransactionStatus getTransaction(TransactionDefinition definition) throws TransactionException &#123; for (int i = 0; i &lt; transactionManagers.length; i++) &#123; transactionStatuses[i] = transactionManagers[i].getTransaction(definition); &#125; return transactionStatuses[0]; &#125; @Override public void commit(TransactionStatus status) throws TransactionException &#123; for (int i = 0; i &lt; transactionManagers.length; i++) &#123; initSynchronization();//因为一个事务管理提交后，会移除当前事务同步，如果已经当前线程事务同步已经杯移除了，需要先初始化，否则事务提交会报错 transactionManagers[i].commit(transactionStatuses[i]); &#125; &#125; @Override public void rollback(TransactionStatus status) throws TransactionException &#123; for (int i = 0; i &lt; transactionManagers.length; i++) &#123; initSynchronization();//因为一个事务管理回滚后，会移除当前事务同步，如果已经当前线程事务同步已经杯移除了，需要先初始化，否则事务回滚会报错 if (transactionStatuses[i] != null &amp;&amp; !transactionStatuses[i].isCompleted()) &#123; transactionManagers[i].rollback(transactionStatuses[i]); &#125; &#125; &#125; private void initSynchronization()&#123; if (!TransactionSynchronizationManager.isSynchronizationActive())&#123; TransactionSynchronizationManager.initSynchronization(); &#125; &#125;&#125;","categories":["Spring Boot"]},{"title":"虚拟机网络配置","path":"/2025/01/07/虚拟机网络配置/","content":"linux网卡配置路径在&#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;，具体配置文件名称为ifcfg-网卡名，如eth0网卡的配置文件为&#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0，更改完配置文件后，需使用命令systemctl restart network使配置生效 1234567891011121314151617181920TYPE=&quot;Ethernet&quot;PROXY_METHOD=&quot;none&quot;#BOOTPROTO=&quot;dhcp&quot; #IP获取方式，dhcp代表自动分配ip，与下面的ipaddr等配置冲突，需要注释，或者配置成其他值（none、static）BROWSER_ONLY=&quot;no&quot;BOOTPROTO=&quot;none&quot;DEFROUTE=&quot;yes&quot;IPV4_FAILURE_FATAL=&quot;no&quot;IPV6INIT=&quot;yes&quot;IPV6_AUTOCONF=&quot;yes&quot;IPV6_DEFROUTE=&quot;yes&quot;IPV6_FAILURE_FATAL=&quot;no&quot;IPV6_ADDR_GEN_MODE=&quot;stable-privacy&quot;NAME=&quot;ens33&quot; *#网卡名称*UUID=&quot;14956153-20b4-426e-a344-3149563c50c1&quot; *#网卡MAC地址，不可更改*DEVICE=&quot;ens33&quot;ONBOOT=&quot;yes&quot; *#网卡开关，如果为no则需要修改为yes*IPADDR=&quot;192.168.67.33&quot; *#网卡IP*PREFIX=&quot;24&quot; *#掩码*GATEWAY=&quot;192.168.67.2&quot; *#网关*DNS1=&quot;8.8.8.8&quot; *#DNS域名解析地址，&quot;8.8.8.8&quot;是谷歌提供的公共域名系统（DNS）服务器的IP地址，可以用来访问互联网域名，如www.baidu.com，还有一个常用地址&quot;114.114.114.114&quot;，是中国电信推出的公共DNS服务器地址*","categories":["Linux"]},{"title":"Java类、接口、注解记录","path":"/2025/01/07/Java类、接口、注解记录/","content":"@Configuration和@AutoConfiguration @Configuration属于Spring的内容，作用是代替xml创建Bean，@Configuration需要@ComponentScan注解扫描到才能生效，默认扫描项目启动文件所在目录，Spring Boot项目的@SpringBootApplication注解已经包含了@ComponentScan @AutoConfiguration属于Spring Boot，属于Spring Boot自动配置中的一个注解但是不能单一只考虑这一个注解，自动配置是由Spring Boot众多类、接口、注解共同实现的，其中就包括@AutoConfigureAfter、@AutoConfigureBefore，@AutoConfiguration比上述两个注解出现的晚，并且包含了上述两个注解，另外还包含了@Configuration，由于@AutoConfigureAfter、@AutoConfigureBefore没有引入@Configuration，所以一般情况下他们不能作为配置类，而@AutoConfiguration引入了@Configuration，所以它可以作为配置类 总的来说，配置功能本质还是使用@Configuration，而例如@AutoConfiguration这些注解只是在@Configuration的基础上，实现了更多的功能，而自动配置主要用于Spring Boot和第三方包的整合， org.springframework.boot.autoconfigure.AutoConfiguration.imports文件和spring.factories文件，所配置的类，不需要任何注解也能自动配置 @Valid、@NotBlank配合使用 当一个方法参数或返回值被@Valid注解时，框架会自动调用验证器对这个对象进行验证，如果验证失败，通常会抛出ConstraintViolationException异常。其中所说的验证就是@NotBlank等注解在Spring框架中，@Valid经常与@ModelAttribute或@RequestBody一起使用，以确保控制器接收到的数据符合预定义的约束条件 123456@PostMapping(&quot;/users&quot;)public ResponseEntity&lt;?&gt; createUser(@Valid @RequestBody User user) &#123; userService.save(user); return ResponseEntity.ok().build();&#125;//在这个例子中，如果User对象不符合在类或其属性上定义的验证规则，Spring将不会调用createUser方法，而是直接返回HTTP状态码400和错误详情给客户端。","categories":["知识累积"]},{"title":"Netty实现Http升级Http2服务端","path":"/2025/01/07/Netty实现Http升级Http2服务端/","content":"netty相关概念介绍 Channel：可以抽象的理解为netty中传输数据的管道，但并不对应一个tcp连接，只对应一次数据处理，比如在Http2多路复用的情况下，一个tcp连接就可能存在多个channel，比较常用的是NioSocketChannel，和Java NIO的NioSocketChannel同名，而netty的NioSocketChannel底层正是通过Java NIO的NioSocketChannel实现的，此外还有针对Linux系统的EpollSocketChannel，使用的就是Linux底层非常高效的方法：epoll EventLoop：EventLoop 是Netty中的事件循环，它负责处理网络事件、执行任务和管理相关的资源。每个 EventLoop 都绑定到一个线程，并且在该线程上运行，特殊情况下也可以是多个线程，总之就是处理一组事件。它使用事件循环机制来处理输入和输出的数据，以及执行用户自定义的任务。EventLoop 提供了一种异步执行任务的机制，以避免阻塞IO操作，每个Channel绑定了一个EventLoop EventLoopGroup：EventLoopGroup 是一个线程池，它包含一组 EventLoop。它负责管理和分配 EventLoop，用于处理客户端和服务器端的网络事件。EventLoopGroup 可以理解为一个线程池的集合，每个 EventLoop 都是一个独立的线程，用于处理具体的网络事件。 ChannelPipeline：channel事件处理管道，也可以立即为channel事件处理流程，由多个ChannelHandler组成，当有IO读写事件时，如果是读事件，消息会先到达HeadContext（ChannelPipeline的头部），然后一直往下走，经过各种消息处理器，如果是写事件，当前消息处理器创建消息后，会往上走，到达HeadContext，然后发送出去，如果不是消息处理器创建的消息，而是channel直接创建的消息，就从管道尾部出发（TailContext），即入站消息从上往下，出战消息从下往上 ChannelHandler（通道处理器）：可以理解为消息处理器，有两种：ChannelInboundHandler、ChannelOutboundHandler，前者是入站消息处理，当有读事件时，会生效，后者是出战消息处理，当由写消息时，会生效，此外还有一种特殊的双通道处理：ChannelDuplexHandler，读写事件，它都会生效 Bootstrap：可以立即为启动器或者启动辅助器，用于配置Channel、EventLoopGroup、连接信息、连接参数以及其他相关的参数。 ByteBuf：netty中高效的字节容器，支持内存池和零拷贝 Codec：编解码器，一种特殊的ChannelHandler，因为netty本身只支持ByteBuf，所以需要编解码器将ByteBuf转为我们需要的类型，或者将我们生成的类型数据转为ByteBuf交给netty处理，它有两个主要的方法，decode，encode，前者负责解码，将ByteBuf转为我们需要的类型，后者负责编码，将我们生成的类型数据转为ByteBuf，也可以被单独分为两种，decoder(解码器)和encoder(编码器)，前者具有decode方法，实现ChannelInboundHandler，后者具有encode方法，实现ChannelOutboundHandler 服务端代码依赖12345&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.97.Final&lt;/version&gt;&lt;/dependency&gt; 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127public class Http2UpgradeServer &#123; public static void main(String[] args) throws CertificateException, InterruptedException, SSLException &#123; // Create event loop groups EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; // Create and configure the server bootstrap ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workerGroup)//设置处理客户端连接请求线程组以及处理客户端io（读写）请求线程组 .channel(NioServerSocketChannel.class)//指定服务器使用的网络通道类型,比如Linux系统的话，可以使用EpollSocketChannel网络通道 .option(ChannelOption.SO_BACKLOG, 128) //设置服务端一些属性，如队列最大小，还可以通过此方法设置其他参数值，比如超时时间 .childOption(ChannelOption.SO_KEEPALIVE, true)//设置客户端连接一些属性， //每当有新的客户端连进来时，都是新建一个SocketChannel, 在这里设置SocketChannel初始化处理方法，对新的SocketChannel进行一些处理，主要是加入通道处理程序 .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) &#123; HttpServerCodec httpServerCodec = new HttpServerCodec();//http消息解码以及编码器，由HttpRequestDecoder, HttpResponseEncoder组成 Http2FrameCodec http2FrameCodec = Http2FrameCodecBuilder.forServer().build();//http2帧消息解码以及编码器 ch.pipeline() .addLast(new CleartextHttp2ServerUpgradeHandler( httpServerCodec, new HttpServerUpgradeHandler( httpServerCodec, protocol -&gt; protocol.equals(&quot;h2c&quot;) ? new Http2ServerUpgradeCodec(http2FrameCodec) : null, 1024), http2FrameCodec )) .addLast(new MessageHandler()); &#125; &#125;); // Bind and start the server ChannelFuture future = bootstrap.bind(8080).sync(); System.out.println(&quot;Server started and listening on port 8080&quot;); // Wait until the server socket is closed future.channel().closeFuture().sync(); &#125; finally &#123; // Shut down the event loop groups bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; @ChannelHandler.Sharable static class MessageHandler extends HttpObjectAggregator &#123; public MessageHandler() &#123; super(1024); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof HttpObject) &#123; handleHttpMessage(ctx, (HttpObject) msg); &#125; else if (msg instanceof Http2Frame) &#123; ctx.pipeline().addLast(new Http2MultiplexHandler(new Http2Handler())).remove(this); &#125; &#125; private void handleHttpMessage(ChannelHandlerContext ctx, HttpObject msg) throws Exception &#123; List&lt;Object&gt; out = new ArrayList&lt;&gt;(); super.decode(ctx, msg, out); if (out.isEmpty()) &#123; return; &#125; assert out.size() == 1; FullHttpRequest fullHttpRequest = (FullHttpRequest) out.get(0); String content = fullHttpRequest.content().toString(CharsetUtil.UTF_8); System.out.println(fullHttpRequest.uri() + &quot;:&quot; + content); DefaultFullHttpResponse httpResponse = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK, Unpooled.wrappedBuffer((&quot;success:&quot; + content).getBytes())); httpResponse.headers() .add(&quot;Content-Length&quot;, (&quot;success:&quot; + content).length()) .add(&quot;Content-Type&quot;, &quot;text/html;charset=UTF-8&quot;); ctx.writeAndFlush(httpResponse); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; cause.printStackTrace(); ctx.close(); &#125; &#125; @ChannelHandler.Sharable static class Http2Handler extends ChannelInboundHandlerAdapter&#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof DefaultHttp2HeadersFrame) &#123; ((DefaultHttp2HeadersFrame) msg).headers().forEach(map -&gt; System.out.println(map.getKey() + &quot;:&quot; + map.getValue())); &#125; else if (msg instanceof DefaultHttp2DataFrame) &#123; System.out.println(&quot;----------------------&quot; + ctx.channel().hashCode()); DefaultHttp2DataFrame http2RequestDataFrame = (DefaultHttp2DataFrame) msg; String requestBody = http2RequestDataFrame.content().toString(CharsetUtil.UTF_8); System.out.println(http2RequestDataFrame.stream().id() + &quot;:&quot; + requestBody); String responseBody = &quot;success:&quot; + requestBody; Http2FrameStream requestStream = http2RequestDataFrame.stream(); DefaultHttp2HeadersFrame headersFrame = new DefaultHttp2HeadersFrame( new DefaultHttp2Headers().status(&quot;200&quot;) .set(HttpHeaderNames.CONTENT_TYPE, &quot;text/plain;charset=UTF-8&quot;) .set(HttpHeaderNames.DATE, &quot;Fri, 15 Sep 2023 03:00:01 GMT&quot;) .set(HttpHeaderNames.CONTENT_LENGTH, String.valueOf(responseBody.length())) ).stream(requestStream); DefaultHttp2DataFrame dataFrame = new DefaultHttp2DataFrame(Unpooled.wrappedBuffer(responseBody.getBytes()), true).stream(requestStream); ctx.write(headersFrame); ctx.writeAndFlush(dataFrame); &#125; else if (msg instanceof DefaultHttp2PingFrame) &#123; if (((DefaultHttp2PingFrame) msg).ack()) &#123; DefaultHttp2PingFrame pingFrame = new DefaultHttp2PingFrame(1); ctx.writeAndFlush(pingFrame); &#125; &#125; &#125; &#125;&#125; 代码解释 CleartextHttp2ServerUpgradeHandler：http升级http2处理类，但并不是真正的升级处理类，有三个参数 HttpServerCodec：http编解码器，由HttpRequestDecoder, HttpResponseEncoder组成，解析升级前的http消息，以及发送升级成功或失败后的响应 HttpServerUpgradeHandler：真正的升级处理类，但它不仅能升级http为http2，还可以将http升级为其他协议，有三个参数 SourceCodec：原始编码处理类（即http编码处理类），代码中使用的是HttpServerCodec，和CleartextHttp2ServerUpgradeHandler的是同一个对象，它在HttpServerUpgradeHandler中并没有真正的作用，因为它是为了CleartextHttp2ServerUpgradeHandler专门设计的 UpgradeCodecFactory：升级工厂，生成升级处理编码类-UpgradeCodec的工厂，这里设计成工厂的目的是可以针对不同的升级协议，返回作用不同的升级处理编码类，这里的升级协议，取自upgrade消息头，升级到Http2用的升级处理编码类是Http2ServerUpgradeCodec，它实现了UpgradeCodec maxContentLength：http消息体的最大长度 ChannelHandler：如果客户端发来的协议就是Http2的话，就会直接通过这个类处理，而不再经过上面的HttpServerCodec和HttpServerUpgradeHandler，同样的道理，如果发来的不是Http2协议，那么这个类就不会生效。这里虽然用的是ChannelHandler，除非自己实现Http2处理器，大部分情况下用的都是Http2ConnectionHandler及其子类，一般情况下使用Http2FrameCodec，它可以将消息处理为最方便的理解的各种http2的帧 HttpObjectAggregator：间接继承了MessageToMessageDecoder，也一种编码器，代码中自定义的MessageHandler继承了HttpObjectAggregator，它用于合并消息，因为对于完整的http消息，netty提供的解码器只能将其分成两部分，即消息头和消息体，传到用户自定义的处理器时，也是分两部分的，而HttpObjectAggregator则可以将消息头和消息体合为一个完整的http消息，其只有一个必填的参数，就是最大消息体内容长度，其他参数可不填 Http2Frame：http2帧，还有子类，Http2StreamFrame（stream帧，http2多路复用的关键），HTTP2包含很多不同的帧，有连接层面的帧，比如Setting帧，GoAway帧，也有很多请求层面的帧，用不同的流（stream）区分，比如Header帧，Data帧，连接层面的帧，相同的帧同时只会有一个，而请求层面的帧，同时可以有多个不同stream的相同的帧，而这也就是http2的多路复用 Http2MultiplexHandler：多路复用处理器，虽然http2已经不受限于一个连接同时只能发起一个请求了，但是多个请求还是需要一个channel来处理，而Http2MultiplexHandler会针对不同stream的http2请求，生成Http2MultiplexHandlerStreamChannel，将他注册到父channel的事件处理器中，由生成的streamchannel处理具体的stream的http2请求，但是因为使用的是父channel的事件处理器，而netty一般的事件处理器都是单线程的，所以多个同父channel的stremachannel也是同步执行的，而且它们使用的handler也是同一个对象，所以在简单的使用场景中，似乎并没有太大的用处，可能比较适用于一些特殊或者复杂的场景 流程介绍进入管道后，首先会进入CleartextHttp2ServerUpgradeHandler，它继承了ByteToMessageDecoder，属于解码器，所以生效方法是decode 1234567891011121314151617181920protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; int prefaceLength = CONNECTION_PREFACE.readableBytes(); int bytesRead = Math.min(in.readableBytes(), prefaceLength); if (!ByteBufUtil.equals(CONNECTION_PREFACE, CONNECTION_PREFACE.readerIndex(), in, in.readerIndex(), bytesRead)) &#123; ctx.pipeline().remove(this); &#125; else if (bytesRead == prefaceLength) &#123; // Full h2 preface match, removed source codec, using http2 codec to handle // following network traffic ctx.pipeline() .remove(httpServerCodec) .remove(httpServerUpgradeHandler); ctx.pipeline().addAfter(ctx.name(), null, http2ServerHandler); ctx.pipeline().remove(this); ctx.fireUserEventTriggered(PriorKnowledgeUpgradeEvent.INSTANCE); &#125;&#125; 12345public void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123; ctx.pipeline() .addAfter(ctx.name(), null, httpServerUpgradeHandler) .addAfter(ctx.name(), null, httpServerCodec);&#125; 上面一个是编码器方法，一个是添加到管道触发事件，在handlerAdded方法中，会将http升级处理器和http消息编解码器加入通道，这里需要注意addAfter方法的特性，按照调用顺序，http消息编解码器会在http升级处理器之前，在decode方法中，会先判断是否有http2序言，”PRI * HTTP&#x2F;2.0\\r \\r SM\\r \\r ”，具体参考http2协议，如果有http2序言，证明就是http2请求，无需升级，CleartextHttp2ServerUpgradeHandler会将自己、httpServerCodec和httpServerUpgradeHandler从管道删除，添加一个http2ServerHandler用于处理http2 ByteBuf消息 如果没有http2序言，那么CleartextHttp2ServerUpgradeHandler会将自己从管道中删除，那么当前管道中就只剩httpServerCodec和httpServerUpgradeHandler，按照顺序会先进入httpServerCodec，将ByteBuf消息转为netty中http的消息体，然后httpServerUpgradeHandler接收到http消息体，进行升级处理，它继承了HttpObjectAggregator，也是一种编码器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051protected void decode(ChannelHandlerContext ctx, HttpObject msg, List&lt;Object&gt; out)throws Exception &#123; if (!handlingUpgrade) &#123; // Not handling an upgrade request yet. Check if we received a new upgrade request. if (msg instanceof HttpRequest) &#123; HttpRequest req = (HttpRequest) msg; if (req.headers().contains(HttpHeaderNames.UPGRADE) &amp;&amp; shouldHandleUpgradeRequest(req)) &#123; handlingUpgrade = true; &#125; else &#123; ReferenceCountUtil.retain(msg); ctx.fireChannelRead(msg); return; &#125; &#125; else &#123; ReferenceCountUtil.retain(msg); ctx.fireChannelRead(msg); return; &#125; &#125; FullHttpRequest fullRequest; if (msg instanceof FullHttpRequest) &#123; fullRequest = (FullHttpRequest) msg; ReferenceCountUtil.retain(msg); out.add(msg); &#125; else &#123; // Call the base class to handle the aggregation of the full request. super.decode(ctx, msg, out); if (out.isEmpty()) &#123; // The full request hasn&#x27;t been created yet, still awaiting more data. return; &#125; // Finished aggregating the full request, get it from the output list. assert out.size() == 1; handlingUpgrade = false; fullRequest = (FullHttpRequest) out.get(0); &#125; if (upgrade(ctx, fullRequest)) &#123; // The upgrade was successful, remove the message from the output list // so that it&#x27;s not propagated to the next handler. This request will // be propagated as a user event instead. out.clear(); &#125; // The upgrade did not succeed, just allow the full request to propagate to the // next handler.&#125; 这个方法简单来讲就是通过消息头（upgrade）判断是否需要升级，如果不需要升级，则直接退出，此时的消息是httpServerCodec解码出来的http消息，所以使用CleartextHttp2ServerUpgradeHandler是可以处理http消息的。如果需要升级，则使用父类HttpObjectAggregator的合并功能合并httpServerCodec产生的消息头和消息体，合并为FullHttpRequest，然后调用upgrade方法进行真正的升级处理 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586private boolean upgrade(final ChannelHandlerContext ctx, final FullHttpRequest request) &#123; // Select the best protocol based on those requested in the UPGRADE header. final List&lt;CharSequence&gt; requestedProtocols = splitHeader(request.headers().get(HttpHeaderNames.UPGRADE)); final int numRequestedProtocols = requestedProtocols.size(); UpgradeCodec upgradeCodec = null; CharSequence upgradeProtocol = null; for (int i = 0; i &lt; numRequestedProtocols; i ++) &#123; final CharSequence p = requestedProtocols.get(i); final UpgradeCodec c = upgradeCodecFactory.newUpgradeCodec(p); if (c != null) &#123; upgradeProtocol = p; upgradeCodec = c; break; &#125; &#125; if (upgradeCodec == null) &#123; // None of the requested protocols are supported, don&#x27;t upgrade. return false; &#125; // Make sure the CONNECTION header is present. List&lt;String&gt; connectionHeaderValues = request.headers().getAll(HttpHeaderNames.CONNECTION); if (connectionHeaderValues == null || connectionHeaderValues.isEmpty()) &#123; return false; &#125; final StringBuilder concatenatedConnectionValue = new StringBuilder(connectionHeaderValues.size() * 10); for (CharSequence connectionHeaderValue : connectionHeaderValues) &#123; concatenatedConnectionValue.append(connectionHeaderValue).append(COMMA); &#125; concatenatedConnectionValue.setLength(concatenatedConnectionValue.length() - 1); // Make sure the CONNECTION header contains UPGRADE as well as all protocol-specific headers. Collection&lt;CharSequence&gt; requiredHeaders = upgradeCodec.requiredUpgradeHeaders(); List&lt;CharSequence&gt; values = splitHeader(concatenatedConnectionValue); if (!containsContentEqualsIgnoreCase(values, HttpHeaderNames.UPGRADE) || !containsAllContentEqualsIgnoreCase(values, requiredHeaders)) &#123; return false; &#125; // Ensure that all required protocol-specific headers are found in the request. for (CharSequence requiredHeader : requiredHeaders) &#123; if (!request.headers().contains(requiredHeader)) &#123; return false; &#125; &#125; // Prepare and send the upgrade response. Wait for this write to complete before upgrading, // since we need the old codec in-place to properly encode the response. final FullHttpResponse upgradeResponse = createUpgradeResponse(upgradeProtocol); if (!upgradeCodec.prepareUpgradeResponse(ctx, request, upgradeResponse.headers())) &#123; return false; &#125; // Create the user event to be fired once the upgrade completes. final UpgradeEvent event = new UpgradeEvent(upgradeProtocol, request); // After writing the upgrade response we immediately prepare the // pipeline for the next protocol to avoid a race between completion // of the write future and receiving data before the pipeline is // restructured. try &#123; final ChannelFuture writeComplete = ctx.writeAndFlush(upgradeResponse); // Perform the upgrade to the new protocol. sourceCodec.upgradeFrom(ctx); upgradeCodec.upgradeTo(ctx, request); // Remove this handler from the pipeline. ctx.pipeline().remove(HttpServerUpgradeHandler.this); // Notify that the upgrade has occurred. Retain the event to offset // the release() in the finally block. ctx.fireUserEventTriggered(event.retain()); // Add the listener last to avoid firing upgrade logic after // the channel is already closed since the listener may fire // immediately if the write failed eagerly. writeComplete.addListener(ChannelFutureListener.CLOSE_ON_FAILURE); &#125; finally &#123; // Release the event if the upgrade event wasn&#x27;t fired. event.release(); &#125; return true;&#125; 这个方法简单来说就是先根据upgrade消息头的协议名生成http2升级编解码器，这一步是我们自己实现的，然后检查所需的消息头是否都具备，http升级http2必须的消息头包括HTTP2-Settings，upgrade，而且connection消息头的内容要包括HTTP2-Settings,upgrade，其中upgrade是http升级必须的消息头，而HTTP2-Settings只是http升级http2必须的消息头，检查完消息头后，调用upgradeCodec(Http2ServerUpgradeCodec类)相关方法进行升级，分别调用了upgradeCodec的prepareUpgradeResponse和upgradeTo，前者是根据HTTP2-Settings消息头生成Http2的Setting消息，后者是添加Http2ConnectionHandler，具体参考Http2ServerUpgradeCodec，然后httpServerUpgradeHandler会将自己从管道中删除，那么到这一步，管道中就只剩一个Http2ConnectionHandler了，所以后续客户端只能发送http2请求，否则只能重新建立连接，到这一步就完成升级了 总结CleartextHttp2ServerUpgradeHandler为什么能同时处理http1，http1升级，http2 处理http1：是因为在CleartextHttp2ServerUpgradeHandler的decode方法中，如果发现消息不是http2序言，那么删除掉自己，然后交给http编解码器和升级处理器，如果http中没有升级所需消息头，就会被当作普通http处理 处理http1升级：如果http有升级所需消息头，那么就可以升级 处理http2：是因为在CleartextHttp2ServerUpgradeHandler的decode方法中，如果发现消息是http2序言，那么就会将http编解码器、升级处理器还有自身都从管道中删除，并且添加http2处理器 netty读取和发送netty的读取和发送离不开io.netty.channel.AbstractChannelHandlerContext，像代码中看到的writeAndFlush和channelRead方法，都需要经过此类 12345678910111213141516171819202122private void invokeChannelRead(Object msg) &#123; if (invokeHandler()) &#123; try &#123; // DON&#x27;T CHANGE // Duplex handlers implements both out/in interfaces causing a scalability issue // see https://bugs.openjdk.org/browse/JDK-8180450 final ChannelHandler handler = handler(); final DefaultChannelPipeline.HeadContext headContext = pipeline.head; if (handler == headContext) &#123; headContext.channelRead(this, msg); &#125; else if (handler instanceof ChannelDuplexHandler) &#123; ((ChannelDuplexHandler) handler).channelRead(this, msg); &#125; else &#123; ((ChannelInboundHandler) handler).channelRead(this, msg); &#125; &#125; catch (Throwable t) &#123; invokeExceptionCaught(t); &#125; &#125; else &#123; fireChannelRead(msg); &#125;&#125; AbstractChannelHandlerContext的invokeChannelRead会调用处理器的channelRead方法，将消息提交给处理器处理，这里的channelRead一般是系统默认实现的解码器和自己实现的读取消息代码 123456789101112131415161718private void invokeWrite0(Object msg, ChannelPromise promise) &#123; try &#123; // DON&#x27;T CHANGE // Duplex handlers implements both out/in interfaces causing a scalability issue // see https://bugs.openjdk.org/browse/JDK-8180450 final ChannelHandler handler = handler(); final DefaultChannelPipeline.HeadContext headContext = pipeline.head; if (handler == headContext) &#123; headContext.write(this, msg, promise); &#125; else if (handler instanceof ChannelDuplexHandler) &#123; ((ChannelDuplexHandler) handler).write(this, msg, promise); &#125; else &#123; ((ChannelOutboundHandler) handler).write(this, msg, promise); &#125; &#125; catch (Throwable t) &#123; notifyOutboundHandlerException(t, promise); &#125;&#125; 当我们调用channel或者ctx的write(writeAndFlush)方法，会调用到AbstractChannelHandlerContext的invokeWrite0方法，并且它会调用处理器的write方法，将消息提交给处理器处理，这里的wirte方法一般是系统实现的编码器 另外还有一个比较重要的类，就是io.netty.channel.socket.nio.NioSocketChannel，这个类实在ServerBootstrap配置的，windows系统一般情况就是使用NioSocketChannel，这个类可以来理解为java.nio.channels.SocketChannel的封装类，NioSocketChannel的doWrite方法就是调用SocketChannel的write方法 关于TCP与HTTPhttp是响应式的协议，只能一次请求，一次响应，http2变成同时多次请求，多次响应，但是从tcp协议的层面来看，tcp是传输层的协议，它本身可以交互，但并没有请求和响应的说法，tcp天然就支持http2的多路复用，所以http1.1和http2只是设计上的问题，并不存在网络传输技术的更改，而http2的多路复用，最终也需要导代码层面实现","categories":["Netty"]},{"title":"前后端通过RSA算法传输数据","path":"/2025/01/07/前后端通过RSA算法传输数据/","content":"前言参考文档：https://blog.csdn.net/sinat_40770656&#x2F;article&#x2F;details&#x2F;131225221?spm&#x3D;1001.2014.3001.5501 系统有需求，不能明文传输密码，而系统本身还没有采用https，那么只能自己实现一层加密，像前后端数据传输最安全的办法就是使用非对称加密，这里采用RSA 前端加密前端通过RSA加密可以通过jsrsasign库，官方地址：https://github.com/kjur/jsrsasign 这里只采用传统的html方式使用jsrsasign库，使用公钥进行加密 12345678910&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/jsrsasign/8.0.20/jsrsasign-all-min.js&quot;&gt;&lt;/script&gt;&lt;script&gt;let publicKey = &quot;-----BEGIN PUBLIC KEY----- &quot; + &quot;****************************************&quot; + &quot;-----END PUBLIC KEY-----&quot;;function encrypt(password)&#123; let keyObj = KEYUTIL.getKey(publicKey); return KJUR.crypto.Cipher.encrypt(password, keyObj, &#x27;RSA&#x27;);&#125;&lt;/script&gt; 代码中的KEYUTIL和KJUR都是jsrsasign-all-min.js中定义好的对象，可以直接使用。需要注意KJUR.crypto.Cipher.encrypt方法加密出来的结果是16进制字符串，在后端解密的时候要记得处理一下 后端解密Java似乎默认支持RSA算法，这里引入了bouncycastle以简化代码 12345&lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcpkix-jdk15on&lt;/artifactId&gt; &lt;version&gt;1.70&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728private String privateKey = &quot;-----BEGIN RSA PRIVATE KEY----- &quot; + &quot;*****************************************************&quot; + &quot;-----END RSA PRIVATE KEY-----&quot;;public String decrypt(String password)&#123; try&#123; byte[] bytes = hexStringToByteArray(password); PEMParser pemParser = new PEMParser(new StringReader(privateKey)); PEMKeyPair pemKeyPair = ((PEMKeyPair) pemParser.readObject()); PrivateKeyInfo privateKeyInfo = pemKeyPair.getPrivateKeyInfo(); PrivateKey privateKey = new JcaPEMKeyConverter().getPrivateKey(privateKeyInfo); Cipher cipher = Cipher.getInstance(&quot;RSA/ECB/PKCS1Padding&quot;); cipher.init(Cipher.DECRYPT_MODE, privateKey); byte[] data = cipher.doFinal(bytes); return new String(data); &#125;catch (Exception e)&#123; &#125;&#125;public static byte[] hexStringToByteArray(String s) &#123; int len = s.length(); byte[] data = new byte[len / 2]; for (int i = 0; i &lt; len; i += 2) &#123; data[i / 2] = (byte) ((Character.digit(s.charAt(i), 16) &lt;&lt; 4) + Character.digit(s.charAt(i+1), 16)); &#125; return data;&#125; hexStringToByteArray放是为了将jsrsasign加密出来的16进制字符串转为byte数组","categories":["安全"]},{"title":"Nginx代理Http2","path":"/2025/01/07/Nginx代理Http2/","content":"前言首先理解一下Nginx代理Http2，按照nginx代理http1的逻辑，客户端与nginx使用http&#x2F;1.1进行数据传输，nginx与服务端也使用http&#x2F;1.1进行数据传输，那么代理http2时，应该也是如此，但是实际不太一样，可能出于某些考虑，nginx似乎并不支持反向代理http2，即无法使用http2请求服务端，因为proxy_http_version配置只支持1.0和1.1，所以Nginx代理http2只支持客户端像nginx提交http2请求 配置12345678910111213141516171819202122server &#123; listen 8080 ssl; server_name localhost; http2 on; ssl_certificate certificate.pem; ssl_certificate_key certificate.key; location /activity/servicetime &#123; keepalive_requests 10000; fastcgi_hide_header Access-Control-Allow-Origin; proxy_hide_header Access-Control-Allow-Origin; add_header Access-Control-Allow-Origin *; proxy_pass http://server; proxy_http_version 1.1; proxy_send_timeout 100; proxy_read_timeout 100; proxy_connect_timeout 100; &#125;&#125; 相关配置介绍 http2 on：打开http2，该配置会让Nginx代理Http2的消息，这个配置是在1.25.1版本之后才有的，1.25.1之前的版本需要使用listen 8080 ssl http2 keepalive_requests 10000：这个配置是设置单个tcp连接上最大请求数的，默认是1000，这个参数的目的之一是为了控制tcp连接在合适的时候关闭，而不是一直开着，占用资源。举个例子，在http&#x2F;1.1的情况下，请求数为10000，并发数为10，那么客户端会直接创建10个连接，每个连接会按顺序进行1000个请求的提交，正好全部提交完的情况下，nginx将10个连接全部关闭，同等情况下，换成http2，那么nginx只会创建一个连接，但是一个连接只能进行1000个请求的提交，所以nginx会频繁的关闭连接，但实际上是没有必要的。所以这里设置的10000只是代表相对于http&#x2F;1.1来说，使用http2时，这个值可以设置大一点，并不是代表一定要比默认的1000要大，要考虑实际情况 listen 8080 ssl、ssl_certificate、ssl_certificate_key：这三个配置是设置nginx ssl证书以及开启https，这一步对于http2来说，也不是必要的，只是对于浏览器来说，如果不配置ssl，那么浏览器就无法在握手阶段使用ALPN确定使用的协议，则默认会使用http&#x2F;1.1，所以这一步是为了浏览器能通过http2向nginx发起请求","categories":["Nginx"]},{"title":"Spring Boot整合Kafka","path":"/2025/01/07/Spring Boot整合Kafka/","content":"生产者依赖12345&lt;!-- spring boot包含了此依赖的版本，所以尽量不自定义版本 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;&lt;/dependency&gt; 配置下面是部分配置参考 1234567891011121314151617181920212223242526###########【Kafka集群】############spring.kafka.bootstrap-servers=192.168.255.101:9090,192.168.255.101:9091,192.168.255.101:9092spring.kafka.bootstrap-servers=127.0.0.1:9092###########【初始化生产者配置】############ 重试次数spring.kafka.producer.retries=3# 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)spring.kafka.producer.acks=all# 批量大小spring.kafka.producer.batch-size=16384# 提交延时# 当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka# linger.ms为0表示每接收到一条消息就提交给kafka,这时候batch-size其实就没用了spring.kafka.producer.properties.linger.ms=0#开启事务#spring.kafka.producer.transaction-id-prefix=trans-# 生产端缓冲区大小spring.kafka.producer.buffer-memory = 33554432# Kafka提供的序列化和反序列化类spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializerspring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer# 自定义分区器#spring.kafka.producer.properties.partitioner.class=com.kafka.producer.config.CustomizePartitioner 可通过代码设置Topic 1234567891011121314@Configurationpublic class KafkaConfig &#123; public final static String TEST_TOPIC = &quot;testTopic&quot;; // 创建一个名为testTopic的Topic并设置分区数为4，分区副本数为1 // 如果要修改分区数，只需修改配置值重启项目即可 // 修改分区数并不会导致数据的丢失，但是分区数只能增大不能减小 @Bean public NewTopic initialTopic() &#123; return new NewTopic(TEST_TOPIC, 4, (short) 1); &#125;&#125; 代码1234567891011@Autowiredprivate KafkaTemplate&lt;String, Object&gt; kafkaTemplate;@GetMapping(&quot;/send/&#123;message&#125;&quot;)public void send(@PathVariable String message) &#123; ListenableFuture&lt;SendResult&lt;String, Object&gt;&gt; listenableFuture = kafkaTemplate.send(KafkaConfig.TEST_TOPIC, message); listenableFuture.addCallback( sendResult -&gt; logger.info(&quot;success: partition is &#123;&#125;&quot;, sendResult.getRecordMetadata().partition()), throwable -&gt; logger.info(&quot;failure : message is &#123;&#125;&quot;, throwable.getMessage()) );&#125; spring-kafka只支持普通发送和事务发送 消费者依赖这里依赖和生产者一样 12345&lt;!-- spring boot包含了此依赖的版本，所以尽量不自定义版本 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;&lt;/dependency&gt; 配置以下是部分配置介绍 123456789101112131415161718192021222324252627282930313233343536373839404142# 应用名称spring.application.name=consumer# 应用服务 WEB 访问端口server.port=8090###########【Kafka集群】############spring.kafka.bootstrap-servers=192.168.255.101:9090,192.168.255.101:9091,192.168.255.101:9092spring.kafka.bootstrap-servers=127.0.0.1:9092###########【初始化消费者配置】############ 默认的消费组IDspring.kafka.consumer.properties.group.id=defaultConsumerGroup# 是否自动提交offsetspring.kafka.consumer.enable-auto-commit=false# 提交offset延时(接收到消息后多久提交offset)#spring.kafka.consumer.auto-commit-interval=1000# 当kafka中没有初始offset或offset超出范围时将自动重置offset# earliest:重置为分区中最小的offset;# latest:重置为分区中最新的offset(消费分区中新产生的数据);# none:只要有一个分区不存在已提交的offset,就抛出异常;spring.kafka.consumer.auto-offset-reset=latest# 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)spring.kafka.consumer.properties.session.timeout.ms=12000# 消费请求超时时间spring.kafka.consumer.properties.request.timeout.ms=60000# 将consumer隔离级别设置成提交读spring.kafka.consumer.properties.isolation.level=read_committed# Kafka提供的序列化和反序列化类spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializerspring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer# 消费端监听的topic不存在时，项目启动会报错(关掉)#spring.kafka.listener.missing-topics-fatal=false## 设置批量消费#spring.kafka.listener.type=batch## 批量消费每次最多消费多少条消息(可以配合生产者延时批量提交消息测试)#spring.kafka.consumer.max-poll-records=50#日志logging.level.org.apache.kafka.clients.consumer.ConsumerConfig= warn 代码1234567891011@Slf4j@Componentpublic class OneTopicReceiver&#123; @KafkaListener(topics = &#123;&quot;twoTopic&quot;&#125;, errorHandler = &quot;consumerAwareErrorHandler&quot;, concurrency = &quot;4&quot;, containerFactory = &quot;filterContainerFactory&quot;) public void onReceive(Message message, Acknowledgment ack)&#123; log.info(&quot;&#123;&#125;:&#123;&#125;&quot;,message.getHeaders().get(&quot;kafka_receivedPartitionId&quot;), message.getPayload()); ack.acknowledge(); &#125;&#125; 消费者通过@KafkaListener注解开启监听，主要属性包括主题（可以监听多个主题），配置工厂，消费者组，消费并发数等 事务开启事务修改application.properties配置文件 12//这里可以随意设置spring.kafka.producer.transaction-id-prefix=trans- 1234//通过带代码可以看出，只要transaction-id-prefix配置不为null，就会开启事务public boolean transactionCapable() &#123; return this.transactionIdPrefix != null;&#125; 设置消费者隔离级别12# 将consumer隔离级别设置成提交读(默认read_uncommitted)spring.kafka.consumer.properties.isolation.level=read_committed 如果不设置隔离级别，默认会是读未提交（read_uncommitted），即使生产者端因为报错没有调用producer.commitTransaction()，而是调用的producer.abortTransaction()，但是消费者仍然可以消费到这些没提交的信息，所以需要将隔离级别设置成读已提交（read_committed） 使用方法使用executeInTransaction方法1234567kafkaTemplate.executeInTransaction(operations -&gt; &#123; for (int i = 0; i &lt; 100; i++) &#123; ListenableFuture&lt;SendResult&lt;String, Object&gt;&gt; listenableFuture = operations.send(&quot;twoTopic&quot;, String.valueOf(i)); listenableFuture.addCallback(sendResult -&gt; logger.info(&quot;success: partition is &#123;&#125;&quot;, sendResult.getRecordMetadata().partition()), throwable -&gt; logger.info(&quot;failure : message is &#123;&#125;&quot;,throwable.getMessage())); &#125; return &quot;&quot;;&#125;); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public &lt;T&gt; T executeInTransaction(OperationsCallback&lt;K, V, T&gt; callback) &#123; Assert.notNull(callback, &quot;&#x27;callback&#x27; cannot be null&quot;); Assert.state(this.transactional, &quot;Producer factory does not support transactions&quot;); Producer&lt;K, V&gt; producer = (Producer)this.producers.get(); Assert.state(producer == null, &quot;Nested calls to &#x27;executeInTransaction&#x27; are not allowed&quot;); String transactionIdSuffix; if (this.producerFactory.isProducerPerConsumerPartition()) &#123; transactionIdSuffix = TransactionSupport.getTransactionIdSuffix(); TransactionSupport.clearTransactionIdSuffix(); &#125; else &#123; transactionIdSuffix = null; &#125; producer = this.producerFactory.createProducer(); try &#123; //开始事务 producer.beginTransaction(); &#125; catch (Exception var15) &#123; this.closeProducer(producer, false); throw var15; &#125; this.producers.set(producer); Object var5; try &#123; //真正进行的操作，即上面的发送100条消息 Object result = callback.doInOperations(this); try &#123; //提交事务 producer.commitTransaction(); &#125; catch (Exception var12) &#123; throw new KafkaTemplate.SkipAbortException(var12); &#125; var5 = result; &#125; catch (KafkaTemplate.SkipAbortException var13) &#123; throw (RuntimeException)var13.getCause(); &#125; catch (Exception var14) &#123; //放弃事务，类似于回滚 producer.abortTransaction(); throw var14; &#125; finally &#123; if (transactionIdSuffix != null) &#123; TransactionSupport.setTransactionIdSuffix(transactionIdSuffix); &#125; this.producers.remove(); this.closeProducer(producer, false); &#125; return var5;&#125; 使用Transactional注解12345678@GetMapping(&quot;/sendTransaction/&#123;message&#125;&quot;)@Transactionalpublic void sendTransaction(@PathVariable String message) &#123; for (int i = 0; i &lt; 100; i++) &#123; ListenableFuture&lt;SendResult&lt;String, Object&gt;&gt; listenableFuture = kafkaTemplate.send(&quot;twoTopic&quot;, String.valueOf(i)); listenableFuture.addCallback(sendResult -&gt; logger.info(&quot;success: partition is &#123;&#125;&quot;, sendResult.getRecordMetadata().partition()), throwable -&gt; logger.info(&quot;failure : message is &#123;&#125;&quot;, throwable.getMessage())); &#125;&#125; 1234567891011121314151617181920212223242526protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, TransactionAspectSupport.InvocationCallback invocation) throws Throwable &#123; TransactionAttributeSource tas = this.getTransactionAttributeSource(); TransactionAttribute txAttr = tas != null ? tas.getTransactionAttribute(method, targetClass) : null; PlatformTransactionManager tm = this.determineTransactionManager(txAttr); String joinpointIdentification = this.methodIdentification(method, targetClass, txAttr); Object result; if (txAttr != null &amp;&amp; tm instanceof CallbackPreferringPlatformTransactionManager) &#123; //该部分代码比较复杂，没有贴出，可以自行查看，其实就是我没看懂，所以没贴 &#125; else &#123; TransactionAspectSupport.TransactionInfo txInfo = this.createTransactionIfNecessary(tm, txAttr, joinpointIdentification); try &#123; //这里代表我们实际的方法，即加上@Transactional注解的方法，spring在注册bean时，会扫描包含@Transactional注解的方法，然后生成代理方法，即aop拦截 result = invocation.proceedWithInvocation(); &#125; catch (Throwable var17) &#123; //如果发生了报错，则回滚，调用PlatformTransactionManager的rollback()，最终调用producer.abortTransaction(); this.completeTransactionAfterThrowing(txInfo, var17); throw var17; &#125; finally &#123; this.cleanupTransactionInfo(txInfo); &#125; //如果执行成功，则提交，调用PlatformTransactionManager的commit()，最终调用producer.commitTransaction(); this.commitTransactionAfterReturning(txInfo); return result; &#125;&#125; 总结 如果采用@Transactional注解的方式，相当于采用的spring申明式事务 如果采用executeInTransaction方法，相当于是单独实现了一套事务 本质还是kafka的五个方法，类似于数据库以及RabbitMQ的事务 **initTransactions（）**方法用来初始化事务，这个方法能够执行的前提是配置了transactionalId，如果没有则会报出IllegalStateException： **beginTransaction（）**方法用来开启事务； **sendOffsetsToTransaction（）**方法为消费者提供在事务内的位移提交的操作； **commitTransaction（）**方法用来提交事务； **abortTransaction（）**方法用来中止事务，类似于事务回滚。","categories":["kafka"]},{"title":"Nginx知识记录","path":"/2025/01/07/Nginx知识记录/","content":"官方文档nginx documentation root和alias区别 作用范围：root可以存在于server、http和location中，而alias仅能作用在location中。 路径处理：root会将定义路径与URI叠加，即 rootpath + &#x2F;uri；而alias只取定义路径，即 alias + 请求的文件路径。 “root” 指令用于指定请求的 URI 对应的文件在服务器文件系统中的根目录。 如果请求的 URI 是 “&#x2F;images&#x2F;photo.jpg”，并且在配置中指定了 “root &#x2F;var&#x2F;www&#x2F;html”，那么 Nginx 将会在文件系统中寻找文件 “&#x2F;var&#x2F;www&#x2F;html&#x2F;images&#x2F;photo.jpg” 来提供服务。 “root” 指令会将请求的 URI 与指定目录路径进行拼接来确定文件的实际路径。 “alias” 指令用于将请求的 URI 中特定部分映射到服务器文件系统中的指定路径。 如果请求的 URI 是 “&#x2F;images&#x2F;photo.jpg”，并且在配置中指定了 “alias &#x2F;var&#x2F;www&#x2F;images”，那么 Nginx 将会在文件系统中寻找文件 “&#x2F;var&#x2F;www&#x2F;images&#x2F;photo.jpg” 来提供服务。 “alias” 指令会将请求的 URI 中指定部分替换为指定目录路径来确定文件的实际路径。 路径结束：alias后面必须要用“&#x2F;”结束，否则会找不到文件；而root则对“&#x2F;”可有可无。 使用限制：alias在使用正则匹配时，必须捕捉要匹配的内容并在指定的内容处使用；而root则没有这个限制3。综上所述，root和alias在功能、使用和配置上都有所不同，选择使用哪个应根据实际需求和场景来决定。 超时时间以下都设设计到代理服务的超时时间，如果nginx同时设置了upstream负载，那么如果达到了超时时间，则本次请求nginx会切换到下一个代理服务器，从而实现故障切换而不影响客户端 proxy_read_timeout：http, server, location，定义从代理服务器读取响应的超时。超时仅在两个连续读取操作之间设置，不用于传输整个响应。如果代理服务器在此时间内没有传输任何内容，则连接将关闭。个人理解，在Nginx一整个Http响应接收过程中，可能因为响应体大小等原因导致服务端不是一次性发送，会被分成多次发送，Nginx也就需要多次才能接收完成，而这个配置就是多次接收的最大间隔时间，如果间隔时间超过了这个时间，就会超时，但是需要注意，当Nginx发送完请求后，就会开始计算这个时间，可能是因为当Nginx发送完请求后，服务端会回复一个tcp消息，然后从这个tcp消息开始就计算时间 proxy_send_timeout：http, server, location，设置将请求传输到代理服务器的超时。超时仅在两个连续写入操作之间设置，不用于传输整个请求。如果代理服务器在此时间内没有接收到任何内容，则连接将关闭。个人理解，在Nginx一整个Http请求发送过程中，可能因为请求大小等原因导致不是一次性发送，会被分成多次发送，而这个配置就是多次发送的最大间隔时间，如果间隔时间超过这个时间，就会超时 proxy_timeout：stream, server，设置客户端或代理服务器连接上两个连续读取或写入操作之间的超时。如果在此时间内没有传输任何数据，则连接将关闭。个人理解，就是连续两次的写入或者读取之间的间隔时间，因为stream模块没有Http的概念，所以相对好理解 代理规则 如果proxy_pass路径最后面有”&#x2F;“，那么代理路径为：proxy_pass+实际路径在匹配路径之后的地址，例如 12345location /activity/ &#123; proxy_pass http://houtai/;&#125;请求路径：/activity/servicetime代理路径：/servicetime（/+servicetime） 如果proxy_pass路径最后面没有”&#x2F;“，就需要考虑两种情况，就是proxy_pass中是否包含请求路径 不包含请求路径，那么代理路径为：实际请求路径，例如 12345location /activity/ &#123; proxy_pass http://houtai;&#125;请求路径：/activity/servicetime代理路径：/activity/servicetime（/activity/servicetime） 2. 包含请求路径，那么代理路径为：proxy_pass+实际路径在匹配路径之后的地址，例如 12345location /activity/ &#123; proxy_pass http://houtai/activity;&#125;请求路径：/activity/servicetime代理路径：/activityservicetime（/activity+servicetime） 重要配置 **add_header：**添加响应头返回给客户端，但有一个限制需要注意，仅当服务端返回以下状态码时，才会添加：200, 201 (1.3.10), 204, 206, 301, 302, 303, 304, 307 (1.1.16, 1.0.13), or 308 (1.13.0)，**不过可以通过在后面加上always取消此限制，**例如：add_header Access-Control-Allow-Origin * always **server_name：**电脑一般情况下都会有多个网卡IP，这个配置设置匹配的域名或者ip，一般情况我们都只会设置成localhost或者127.0.0.1，但如果需要对同一个端口在不同ip下实现不同的逻辑，那么就需要这个配置了，比如电脑有一个192.168.10.10的ip，那么就可以对发生在127.0.0.1和192.168.10.10上的请求做出不同的处理，而server_name的实现也好理解，比如我们通过Java的ServerSocket编写一个服务端，也可以对发生不同IP的请求做出不同的处理 12345678ServerSocket serverSocket = new ServerSocket(8080);Socket accept = serverSocket.accept();String hostAddress = accept.getLocalAddress().getHostAddress();if (&quot;127.0.0.1&quot;.equals(hostAddress))&#123; System.out.println(&quot;请求的是127.0.0.1&quot;);&#125;else if (&quot;192.168.79.223&quot;.equals(hostAddress))&#123; System.out.println(&quot;请求的是192.168.79.223&quot;);&#125; **listen [::]:8080：**这种写法可以使nginx监听ipv6，如果想只监听ipv6的地址，可以在后面加上ipv6only on，比如listen [::]:8080 ipv6only on","categories":["Nginx"]},{"title":"Http相关知识","path":"/2025/01/07/Http相关知识/","content":"Http必须的请求头 Host： HTTP&#x2F;1.0 不强制要求&lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;Host&lt;/font&gt;头字段，因为在HTTP&#x2F;1.0中默认假设所有请求都是针对连接建立时的IP地址指向的主机，不过也可能有Web服务器处理HTTP&#x2F;1.0请求时，会强制判断Host请求头 根据HTTP&#x2F;1.1规范（RFC 2616），&lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;Host&lt;/font&gt;头字段是必需的，如果请求URI中没有包含主机名，则必须提供&lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;Host&lt;/font&gt;头字段。这是因为HTTP&#x2F;1.1请求中的&lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;Host&lt;/font&gt;头字段用于指定被请求资源的Internet主机和端口号，这对于确定服务器上的哪个虚拟主机应该处理该请求至关重要，大部分Web服务器在处理HTTP&#x2F;1.1请求时，一般都会强制要求Host请求头 Content-Length：在有请求体的情况下，Content-Length字段是必须的 Content-Type：在有请求体的情况下，Content-Type是必须的，比如请求体是json，表单等格式 Connection请求头在HTTP&#x2F;1.0和HTTP&#x2F;1.1版本中，Connection头部字段的区别 HTTP&#x2F;1.0： 默认情况下，HTTP&#x2F;1.0中的每个请求都建立一个新的TCP连接，并且在发送完响应后会关闭这个连接。 在HTTP&#x2F;1.0中，虽然可以通过在请求头或响应头中设置 Connection: Keep-Alive 来尝试请求持久连接（即复用同一个TCP连接处理多个HTTP请求），但这并不是标准默认行为，需要客户端和服务端都支持并同意。 HTTP&#x2F;1.1： HTTP&#x2F;1.1默认开启了持久连接（Keep-Alive），也就是说，除非明确指定了 Connection: close，否则服务器会在处理完一个请求后保持TCP连接打开以等待后续请求。 在HTTP&#x2F;1.1中，Connection头部字段通常用于关闭连接或者与代理服务器协商特定的连接选项。由于默认已启用持久连接，因此通常不需要显式指定 Connection: Keep-Alive。 预检请求参考文档：https://developer.mozilla.org/zh-CN/docs/Glossary/Preflight_request 预检请求不属于http规范中，是浏览器在进行跨域请求时的一种保护机制，但是依赖于http规范，和http密切相关。这里需要注意预检请求不会在每次跨域请求时都会触发，但是即使没有触发预检请求，不代表可以进行跨域请求，因为即使请求完成了，但是浏览器发现响应头中的信息不支持跨越，浏览器也会拦截掉不会展示给用户 请求内容 预检请求使用Option方法进行请求，会带上相关特殊的请求头，主要是浏览器将请求中包含的Origin，Method，Header等信息在预检请求中发送给服务端，以确认服务器是否支持这些内容，包括以下请求头 Origin：发起跨域请求所在的域，ip加端口或者域名加端口 Access-Control-Request-Method：跨域请求的方法，比如get&#x2F;post Access-Control-Request-Headers：跨域请求包含的所有请求头 响应内容 服务器收到Option请求后，根据约定好的策略返回响应，而响应中一般包含这几个响应头，告诉浏览器支持哪些Origin，Method，Header跨越，这些响应头为 Access-Control-Allow-Origin：告诉浏览器，服务端支持哪些Origin跨越请求 Access-Control-Allow-Methods：告诉浏览器，服务端支持哪些Method跨越请求 Access-Control-Allow-Headers：告诉浏览器，服务端支持哪些Header跨越请求 以上响应头必须同时支持才能发起正常发起跨越请求，如果服务器需要允许跨越，三个响应头都需要设置 何时请求 在非简单请求下，会触发预检请求 在部分浏览器定义中，对于 Accept、Accept-Language 和 Content-Language 标头字段的值添加了额外的限制。如果这些标头字段的值是“非标准”的，那么也会认为是非简单请求（该段内容参考”简单请求”文档中的备注部分） Http缓存参考文档：https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Caching Http缓存最主要的Header就是Cache-Control（http&#x2F;1.1） 这里仅介绍一下几种不同的情况，下面提到的缓存验证以及其他具体内容请查看参考文档 响应头中设置Cache-Control为no-cache或者max-age&#x3D;0：表示要先验证再考虑是否继续使用缓存 请求头中设置Cache-Control为max-age&#x3D;0：和上面一样，表示要先验证再考虑是否继续使用缓存 请求头中设置Cache-Control为no-cache：表示不验证直接弃用缓存重新获取，浏览器会放弃缓存并重新加载，谷歌浏览器控制台的停用缓存功能用的就是这种方式","categories":["知识累积"]},{"title":"Java 各种数字类型存储格式","path":"/2025/01/07/Java 各种数字类型存储格式/","content":"long：64位（8字节），取值范围为 -2^63 到 2^63 - 1，即 -9,223,372,036,854,775,808 到 9,223,372,036,854,775,807，规则为64位二进制数字，64位二进制最大为2^64 - 1，但是第一位代表正负，所以最大为2^63 - 1，最小为-2^63，具体负数的规则为取反，参考byte int：32位（4字节），取值范围为 -2^31 到 2^31 - 1，即 -2,147,483,648 到 2,147,483,647，规则为32位二进制数字，64位二进制最大为2^32 - 1，但是第一位代表正负，所以最大为2^31 - 1，最小为-2^31，具体负数的规则为取反，参考byte short：16位（2字节），取值范围为 -2^15 到 2^15 - 1，即 -32,768 到 32,767，规则为16位二进制数字，16位二进制最大为2^16 - 1，但是第一位代表正负，所以最大为2^15 - 1，最小为-2^15，具体负数的规则为取反，参考byte byte：8位（1字节），取值范围为 -2^7 到 2^7 - 1，即 -128 到 127，规则为8位二进制数字，8位二进制最大为2^8 - 1，但是第一位代表正负，所以最大为2^7 - 1，最小为-2^7，具体负数的规则为取反，例如(byte)5的二进制表示为00000101，那么-5表示为11111010 float：32位（4字节），相对特殊，不是简单的二进制转换形式，使用科学计数法存储，即一个浮点数有2部分组成：底数m和指数e，而指数e前面还有一位bit位是符号位，即代表了正负。 符号位: 1位,表示负数,0表示正数 指数位: 8位,表示指数,可表示数据范围(00000000-11111111,对应的十进制为0-255) 因为指数可以是正数也可以是负数,IEEE754标准规定:指数减去127才是实际的指数(这是规定) float的指数表示范围是-127到128; 3. &lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;底数位:只存储23位，最大值为2^23=8388607(7位数),由于我们输入的是十进制，因此对应十进制数为7位，故该float 型的精度为7~8位有效数字(有的编译器为7位，有的为8位)&lt;/font&gt; double：64位（8字节），和float一样，使用科学计数法存储，即一个浮点数有2部分组成：底数m和指数e，而指数e前面还有一位bit位是符号位，即代表了正负。 符号位: 1位,表示负数,0表示正数 指数位: 11位,表示指数,可表示数据范围(00000000000-11111111111,对应的十进制为0-2047) 因为指数可以是正数也可以是负数,IEEE754标准规定:指数减去1023才是实际的指数(这是规定) double的指数表示范围是-1023到1024; 3. &lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;底数位:只存储52位，最大值为2^52=4503599627370496(16位数),由于我们输入的是十进制，因此对应十进制数为16位，故该double型的精度为16~17位有效数字(有的编译器为16位，有的为17位)&lt;/font&gt; float和double参考文章：https://blog.csdn.net/m0_74097410&#x2F;article&#x2F;details&#x2F;131533077","categories":["Java基础"]},{"title":"Spring Cloud OpenFeign","path":"/2025/01/07/Spring Cloud OpenFeign/","content":"依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 代码**需要feign生效，需要在配置类上加上@EnableFeignClients，**然后就是针对不同服务进行编码 123456789101112//name这里可以自定义，但是最好为服务名（url默认为http://&lt;name&gt;），如果自定义name的话，则需要配置url，path可以理解为路径通用前缀@FeignClient(name = &quot;user-center&quot;, path=&quot;/user&quot;)public interface UserCenterFeignClient &#123; @GetMapping(&quot;/getPort&quot;) String getUserCenterPort(); @GetMapping(&quot;/findById/&#123;id&#125;&quot;) UserDTO findById(@PathVariable(&quot;id&quot;) String id); @PostMapping(&quot;/modifyBonusById&quot;) UserDTO modifyBonusById(@RequestBody UserModifyBonusMsgDTO userModifyBonusMsgDTO);&#125; @FeignClient本质就是通过feign.Feign类生成一个代理类，具体是通过feign.Feign#newInstance方法生成代理类 负载均衡feign使用的负载均衡也是spring cloud commons下面的loadbalancer，具体参考RetryableFeignBlockingLoadBalancerClient类，RetryableFeignBlockingLoadBalancerClient实现了Client，但是Client不止有这一个实现类，只是这一个实现类整合了spring重试的功能 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public Response execute(Request request, Request.Options options) throws IOException &#123; URI originalUri = URI.create(request.url()); String serviceId = originalUri.getHost(); Assert.state(serviceId != null, &quot;Request URI does not contain a valid hostname: &quot; + originalUri); LoadBalancedRetryPolicy retryPolicy = this.loadBalancedRetryFactory.createRetryPolicy(serviceId, this.loadBalancerClient); RetryTemplate retryTemplate = this.buildRetryTemplate(serviceId, request, retryPolicy); return (Response)retryTemplate.execute((context) -&gt; &#123; Request feignRequest = null; ServiceInstance retrievedServiceInstance = null; Set&lt;LoadBalancerLifecycle&gt; supportedLifecycleProcessors = LoadBalancerLifecycleValidator.getSupportedLifecycleProcessors(this.loadBalancerClientFactory.getInstances(serviceId, LoadBalancerLifecycle.class), RetryableRequestContext.class, ResponseData.class, ServiceInstance.class); String hint = this.getHint(serviceId); DefaultRequest&lt;RetryableRequestContext&gt; lbRequest = new DefaultRequest(new RetryableRequestContext((ServiceInstance)null, LoadBalancerUtils.buildRequestData(request), hint)); if (context instanceof LoadBalancedRetryContext) &#123; LoadBalancedRetryContext lbContext = (LoadBalancedRetryContext)context; retrievedServiceInstance = lbContext.getServiceInstance(); if (retrievedServiceInstance == null) &#123; if (LOG.isDebugEnabled()) &#123; LOG.debug(&quot;Service instance retrieved from LoadBalancedRetryContext: was null. Reattempting service instance selection&quot;); &#125; ServiceInstance previousServiceInstance = lbContext.getPreviousServiceInstance(); ((RetryableRequestContext)lbRequest.getContext()).setPreviousServiceInstance(previousServiceInstance); supportedLifecycleProcessors.forEach((lifecycle) -&gt; &#123; lifecycle.onStart(lbRequest); &#125;); retrievedServiceInstance = this.loadBalancerClient.choose(serviceId, lbRequest); if (LOG.isDebugEnabled()) &#123; LOG.debug(String.format(&quot;Selected service instance: %s&quot;, retrievedServiceInstance)); &#125; lbContext.setServiceInstance(retrievedServiceInstance); &#125; if (retrievedServiceInstance == null) &#123; if (LOG.isWarnEnabled()) &#123; LOG.warn(&quot;Service instance was not resolved, executing the original request&quot;); &#125; org.springframework.cloud.client.loadbalancer.Response&lt;ServiceInstance&gt; lbResponsex = new DefaultResponse(retrievedServiceInstance); supportedLifecycleProcessors.forEach((lifecycle) -&gt; &#123; lifecycle.onComplete(new CompletionContext(Status.DISCARD, lbRequest, lbResponsex)); &#125;); feignRequest = request; &#125; else &#123; if (LOG.isDebugEnabled()) &#123; LOG.debug(String.format(&quot;Using service instance from LoadBalancedRetryContext: %s&quot;, retrievedServiceInstance)); &#125; String reconstructedUrl = this.loadBalancerClient.reconstructURI(retrievedServiceInstance, originalUri).toString(); feignRequest = this.buildRequest(request, reconstructedUrl); &#125; &#125; org.springframework.cloud.client.loadbalancer.Response&lt;ServiceInstance&gt; lbResponse = new DefaultResponse(retrievedServiceInstance); LoadBalancerProperties loadBalancerProperties = this.loadBalancerClientFactory.getProperties(serviceId); Response response = LoadBalancerUtils.executeWithLoadBalancerLifecycleProcessing(this.delegate, options, feignRequest, lbRequest, lbResponse, supportedLifecycleProcessors, retrievedServiceInstance != null, loadBalancerProperties.isUseRawStatusCodeInResponseData()); int responseStatus = response.status(); if (retryPolicy != null &amp;&amp; retryPolicy.retryableStatusCode(responseStatus)) &#123; if (LOG.isDebugEnabled()) &#123; LOG.debug(String.format(&quot;Retrying on status code: %d&quot;, responseStatus)); &#125; byte[] byteArray = response.body() == null ? new byte[0] : StreamUtils.copyToByteArray(response.body().asInputStream()); response.close(); throw new LoadBalancerResponseStatusCodeException(serviceId, response, byteArray, URI.create(request.url())); &#125; else &#123; return response; &#125; &#125;, new LoadBalancedRecoveryCallback&lt;Response, Response&gt;() &#123; protected Response createResponse(Response response, URI uri) &#123; return response; &#125; &#125;);&#125; execute方法中retrievedServiceInstance &#x3D; this.loadBalancerClient.choose(serviceId, lbRequest);这一行代码就是通过负载获取服务，其中loadBalancerClient就是spring cloud commons下面loadbalancer包中的类，org.springframework.cloud.client.loadbalancer.LoadBalancerClient，RestTemplate使用的也是这个类，所以feign和RestTemplate的负载逻辑差不多，既可以使用ribbon，也可以使用loadBalancer 更换http客户端feign默认使用的是HttpUrlConnection进行http通信，但是feign也可以整合apache httpclient和okhttp，上面提到的RetryableFeignBlockingLoadBalancerClient有一个delegate变量，它就是feign的http客户端，从代码层面来讲，它和RetryableFeignBlockingLoadBalancerClient一样实现了Client，从某种意义上来讲，Client本身就是http客户端，只不过RetryableFeignBlockingLoadBalancerClient没有直接实现http客户端的功能，而是实现了其他的功能，通过delegate变量实现的http客户端，我认为这也是一种装饰模式，delegate默认情况下是feign.Client.Default类，而Default使用的就是HttpUrlConnection 整合apache httpclient需要引入依赖 依赖1234&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt;&lt;/dependency&gt; 配置12345678feign: httpclient: #设置feign访问方式 enabled: false #feign最大连接数 max-connections: 200 #feign单个路劲最大连接数 max-connections-per-route: 50 通过引入依赖和配置，RetryableFeignBlockingLoadBalancerClient的delegate变成了feign.httpclient.ApacheHttpClient，而ApacheHttpClient使用的就是apache httpclient 如何生效的具体生效主要是通过HttpClientFeignLoadBalancerConfiguration 12345678910111213141516171819202122232425262728293031323334353637383940@Configuration( proxyBeanMethods = false)@ConditionalOnClass(&#123;ApacheHttpClient.class&#125;)@ConditionalOnBean(&#123;LoadBalancerClient.class, LoadBalancerClientFactory.class&#125;)@ConditionalOnProperty( value = &#123;&quot;feign.httpclient.enabled&quot;&#125;, matchIfMissing = true)@Conditional(&#123;HttpClient5DisabledConditions.class&#125;)@Import(&#123;HttpClientFeignConfiguration.class&#125;)@EnableConfigurationProperties(&#123;LoadBalancerClientsProperties.class&#125;)class HttpClientFeignLoadBalancerConfiguration &#123; HttpClientFeignLoadBalancerConfiguration() &#123; &#125; @Bean @ConditionalOnMissingBean @Conditional(&#123;OnRetryNotEnabledCondition.class&#125;) public Client feignClient(LoadBalancerClient loadBalancerClient, HttpClient httpClient, LoadBalancerClientFactory loadBalancerClientFactory) &#123; ApacheHttpClient delegate = new ApacheHttpClient(httpClient); return new FeignBlockingLoadBalancerClient(delegate, loadBalancerClient, loadBalancerClientFactory); &#125; @Bean @ConditionalOnMissingBean @ConditionalOnClass( name = &#123;&quot;org.springframework.retry.support.RetryTemplate&quot;&#125; ) @ConditionalOnBean(&#123;LoadBalancedRetryFactory.class&#125;) @ConditionalOnProperty( value = &#123;&quot;spring.cloud.loadbalancer.retry.enabled&quot;&#125;, havingValue = &quot;true&quot;, matchIfMissing = true ) public Client feignRetryClient(LoadBalancerClient loadBalancerClient, HttpClient httpClient, LoadBalancedRetryFactory loadBalancedRetryFactory, LoadBalancerClientFactory loadBalancerClientFactory) &#123; ApacheHttpClient delegate = new ApacheHttpClient(httpClient); return new RetryableFeignBlockingLoadBalancerClient(delegate, loadBalancerClient, loadBalancedRetryFactory, loadBalancerClientFactory); &#125;&#125; 从代码中可以看出，feign.httpclient.enabled配置就是在HttpClientFeignLoadBalancerConfiguration类中起作用的，而RetryableFeignBlockingLoadBalancerClient的delegate变成ApacheHttpClient是因为HttpClientFeignLoadBalancerConfiguration向spring注册了一个新的RetryableFeignBlockingLoadBalancerClient，而这个RetryableFeignBlockingLoadBalancerClient的delegate被HttpClientFeignLoadBalancerConfiguration配置成了ApacheHttpClient，而ApacheHttpClient构造函数的参数就是apache httpclient的HttpClient类，这里ApacheHttpClient的HttpClient参数使用的是spring的bean，所以我们可以通过向spring注册一个新的apache HttpClient，达到我们想要的一些配置 自定义http客户端参考上面的HttpClientFeignLoadBalancerConfiguration我们也可以自己配置使用何种http客户端，配置http客户端主要就是通过注册新的RetryableFeignBlockingLoadBalancerClient（甚至直接注册新的feign Client，但是这样会导致失去RetryableFeignBlockingLoadBalancerClient的功能），也需要解决两个问题，就是将feign的请求转为我们自己客户端的请求，并且将我们自己客户端的响应转为feign的响应，这两步我们暂时直接使用feign-httpclient的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192@Configurationclass HttpClientFeignLoadBalancerConfiguration &#123; HttpClientFeignLoadBalancerConfiguration() &#123; &#125; @Bean @ConditionalOnMissingBean public Client feignRetryClient(LoadBalancerClient loadBalancerClient, LoadBalancedRetryFactory loadBalancedRetryFactory, LoadBalancerClientFactory loadBalancerClientFactory) &#123; MyHttpClient delegate = new MyHttpClient(HttpClients.createDefault()); return new RetryableFeignBlockingLoadBalancerClient(delegate, loadBalancerClient, loadBalancedRetryFactory, loadBalancerClientFactory); &#125; public class MyHttpClient implements Client &#123; private final HttpClient httpClient; public MyHttpClient(HttpClient httpClient) &#123; this.httpClient = httpClient; &#125; @Override public Response execute(Request request, Request.Options options) throws IOException &#123; HttpUriRequest httpUriRequest = null; try &#123; httpUriRequest = toHttpUriRequest(request, options); &#125; catch (URISyntaxException e) &#123; throw new RuntimeException(e); &#125; HttpResponse httpResponse = httpClient.execute(httpUriRequest); return toFeignResponse(httpResponse, request); &#125; HttpUriRequest toHttpUriRequest(Request request, Request.Options options) throws URISyntaxException &#123; RequestBuilder requestBuilder = RequestBuilder.create(request.httpMethod().name()); // per request timeouts RequestConfig requestConfig = (httpClient instanceof Configurable ? RequestConfig.copy(((Configurable) httpClient).getConfig()) : RequestConfig.custom()) .setConnectTimeout(options.connectTimeoutMillis()) .setSocketTimeout(options.readTimeoutMillis()) .build(); requestBuilder.setConfig(requestConfig); URI uri = new URIBuilder(request.url()).build(); requestBuilder.setUri(uri.getScheme() + &quot;://&quot; + uri.getAuthority() + uri.getRawPath()); // request query params List&lt;NameValuePair&gt; queryParams = URLEncodedUtils.parse(uri, requestBuilder.getCharset()); for (NameValuePair queryParam : queryParams) &#123; requestBuilder.addParameter(queryParam); &#125; // request headers boolean hasAcceptHeader = false; for (Map.Entry&lt;String, Collection&lt;String&gt;&gt; headerEntry : request.headers().entrySet()) &#123; String headerName = headerEntry.getKey(); if (headerName.equalsIgnoreCase(&quot;Accept&quot;)) &#123; hasAcceptHeader = true; &#125; if (headerName.equalsIgnoreCase(Util.CONTENT_LENGTH)) &#123; // The &#x27;Content-Length&#x27; header is always set by the Apache client and it // doesn&#x27;t like us to set it as well. continue; &#125; for (String headerValue : headerEntry.getValue()) &#123; requestBuilder.addHeader(headerName, headerValue); &#125; &#125; // some servers choke on the default accept string, so we&#x27;ll set it to anything if (!hasAcceptHeader) &#123; requestBuilder.addHeader(&quot;Accept&quot;, &quot;*/*&quot;); &#125; // request body if (request.body() != null) &#123; HttpEntity entity = null; if (request.charset() != null) &#123; ContentType contentType = getContentType(request); String content = new String(request.body(), request.charset()); entity = new StringEntity(content, contentType); &#125; else &#123; entity = new ByteArrayEntity(request.body()); &#125; requestBuilder.setEntity(entity); &#125; else &#123; requestBuilder.setEntity(new ByteArrayEntity(new byte[0])); &#125; return requestBuilder.build(); &#125; private ContentType getContentType(Request request) &#123; ContentType contentType = null; for (Map.Entry&lt;String, Collection&lt;String&gt;&gt; entry : request.headers().entrySet()) if (entry.getKey().equalsIgnoreCase(&quot;Content-Type&quot;)) &#123; Collection&lt;String&gt; values = entry.getValue(); if (values != null &amp;&amp; !values.isEmpty()) &#123; contentType = ContentType.parse(values.iterator().next()); if (contentType.getCharset() == null) &#123; contentType = contentType.withCharset(request.charset()); &#125; break; &#125; &#125; return contentType; &#125; Response toFeignResponse(HttpResponse httpResponse, Request request) throws IOException &#123; StatusLine statusLine = httpResponse.getStatusLine(); int statusCode = statusLine.getStatusCode(); String reason = statusLine.getReasonPhrase(); Map&lt;String, Collection&lt;String&gt;&gt; headers = new HashMap&lt;String, Collection&lt;String&gt;&gt;(); for (Header header : httpResponse.getAllHeaders()) &#123; String name = header.getName(); String value = header.getValue(); Collection&lt;String&gt; headerValues = headers.get(name); if (headerValues == null) &#123; headerValues = new ArrayList&lt;String&gt;(); headers.put(name, headerValues); &#125; headerValues.add(value); &#125; return Response.builder() .status(statusCode) .reason(reason) .headers(headers) .request(request) .body(toFeignBody(httpResponse)) .build(); &#125; Response.Body toFeignBody(HttpResponse httpResponse) &#123; final HttpEntity entity = httpResponse.getEntity(); if (entity == null) &#123; return null; &#125; return new Response.Body() &#123; @Override public Integer length() &#123; return entity.getContentLength() &gt;= 0 &amp;&amp; entity.getContentLength() &lt;= Integer.MAX_VALUE ? (int) entity.getContentLength() : null; &#125; @Override public boolean isRepeatable() &#123; return entity.isRepeatable(); &#125; @Override public InputStream asInputStream() throws IOException &#123; return entity.getContent(); &#125; @SuppressWarnings(&quot;deprecation&quot;) @Override public Reader asReader() throws IOException &#123; return new InputStreamReader(asInputStream(), UTF_8); &#125; @Override public Reader asReader(Charset charset) throws IOException &#123; Util.checkNotNull(charset, &quot;charset should not be null&quot;); return new InputStreamReader(asInputStream(), charset); &#125; @Override public void close() throws IOException &#123; EntityUtils.consume(entity); try &#123; EntityUtils.consume(entity); &#125; finally &#123; if (httpResponse instanceof CloseableHttpResponse) ((CloseableHttpResponse) httpResponse).close(); &#125; &#125; &#125;; &#125; &#125;&#125; 通过以上代码，就可以将我们自己的配置的RetryableFeignBlockingLoadBalancerClient注册到spring，并且feign就会使用我们配置的RetryableFeignBlockingLoadBalancerClient 拦截器代码最上面有提到，@FeignClient的本质就是feign.Feign生成代理类，而在生成代理类的时候，feign有一个配置拦截器的过程（具体参考feign.Feign类），feign拦截器需要实现feign.RequestInterceptor类 1234567891011121314public class FeignHeaderInterceptor implements RequestInterceptor &#123; @Override public void apply(RequestTemplate requestTemplate) &#123; //下面三句话为springboot获取request的通用方法 RequestAttributes requestAttributes = RequestContextHolder.getRequestAttributes(); ServletRequestAttributes attributes = (ServletRequestAttributes) requestAttributes; HttpServletRequest request = attributes.getRequest(); String token = request.getHeader(&quot;X-Token&quot;); if (token != null) &#123; requestTemplate.header(&quot;X-Token&quot;, token); &#125; &#125;&#125; feign使拦截器生效有三种方式 全局配置全局配置就是将拦截器注册到spring，这样的话，feign在构建任何一个feignclient的代理类时都会将这个拦截器配置进去，也就是对所有的feignclient都有效 12345678@Configurationpublic class FeignConfiguration &#123; @Bean public RequestInterceptor feignHeaderInterceptor()&#123; return new FeignHeaderInterceptor(); &#125;&#125; 局部配置配置文件方式spring cloud feign提供了配置文件的方式配置拦截器 1234567feign: client: config: user-center: #该项可填写@feignclient的name，若填写为default，则为全局配置 #配置feign拦截器 requestInterceptors: - com.pengtong.contentcenter.feignclient.interceptor.FeignHeaderInterceptor 而配置文件的方式主要就是通过org.springframework.cloud.openfeign.FeignClientProperties类完成的，FeignClientProperties有一个config变量，config变量是一个Map&lt;String, FeignClientConfiguration&gt;对象，key就是配置的feign-name，FeignClientConfiguration就是feign的一些配置，所以这种方式不一定只是配置拦截器，具体参考org.springframework.cloud.openfeign.FeignClientProperties.FeignClientConfiguration类，当key是“default”时，就是全局配置 代码方式上面提到了@FeignClient注解，这个注解有一个configuration属性，这个属性就是对该feign进行一些配置，而具体的配置类就是使用@Bean对需要配置的属性进行设置，但是不使用@Configuration（不使用@Configuration代表不注册到spring），fegin会读取这个配置类中的使用了@Bean类进行配置，属于spring的一种机制。这里也不限制于拦截器，具体可以配置哪些属性可以参考FeignClientConfiguration类 1@FeignClient(name = &quot;user-center&quot;, configuration = &#123;UserCenterConfig.class&#125;) 12345678public class UserCenterConfig &#123; @Bean public RequestInterceptor requestInterceptor()&#123; return new FeignHeaderInterceptor(); &#125;&#125; 这种方式主要就是靠org.springframework.context.annotation.AnnotationConfigApplicationContext，它继承了org.springframework.beans.factory.BeanFactory，举个例子 1234567891011121314public class UserCenterConfig &#123; @Bean public RequestInterceptor requestInterceptor()&#123; return new FeignHeaderInterceptor(); &#125; public static void main(String[] args) &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(UserCenterConfig.class); Map&lt;String, RequestInterceptor&gt; requestInterceptorMap = BeanFactoryUtils.beansOfTypeIncludingAncestors(context, RequestInterceptor.class); System.out.println(requestInterceptorMap); &#125;&#125;","categories":["Spring Cloud"]},{"title":"文件系统相关概念","path":"/2025/01/07/文件系统相关概念/","content":"磁盘 是物理存储设备。 磁盘分区 是磁盘上的逻辑部分，可以独立使用。 块设备 是以块为单位进行读写的设备，包括磁盘和分区。 物理卷 (PV) 是经过初始化后的块设备，是LVM的基本单元，通常是一个磁盘分区或整个磁盘。 卷组 (VG) 是由一个或多个物理卷组成的容器，用于创建逻辑卷。 逻辑卷 (LV) 是从卷组中分配的空间，可以像普通分区一样使用，并且可以根据需要动态调整大小。 相关命令lsblk：命令显示所有块设备的信息 df -h：命令报告文件系统的磁盘空间使用情况，而 &lt;font style=&quot;color:rgb(44, 44, 54);&quot;&gt;-h&lt;/font&gt; 选项（human-readable）使得输出更易于人类阅读，以 KB、MB、GB 等单位表示大小","categories":["Linux"]}]